{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjHutCKMX0zd+3da3K6m0j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahtesham519/Genrative_Deep_learning_v2_2023/blob/main/Autoencoder_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSGCURLW62AS"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from tensorflow.keras import(\n",
        "    layers,\n",
        "    models,\n",
        "    callbacks,\n",
        "    utils,\n",
        "    metrics,\n",
        "    losses,\n",
        "    optimizers,\n",
        ")\n",
        "\n",
        "from scipy.stats import norm\n",
        "import pandas as pd\n",
        "\n",
        "from vae_utils import get_vector_from_label , add_vector_to_images, morph_faces"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0. Parameters"
      ],
      "metadata": {
        "id": "R9LqX7se-7kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 32\n",
        "CHANNELS = 3\n",
        "BATCH_SIZE = 128\n",
        "NUM_FEATURES = 128\n",
        "Z_DIM = 200\n",
        "LEARNING_RATE = 0.0005\n",
        "EPOCHS = 10\n",
        "BETA = 2000\n",
        "LOAD_MODEL = False\n"
      ],
      "metadata": {
        "id": "5XF0vCkY-6eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Prepare the data"
      ],
      "metadata": {
        "id": "p489TnFc_LM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data\n",
        "train_data = utils.image_dataset_from_directory(\n",
        "    \"/app/data/celeba-dataset/img_align_celeba/img_align_celeba\",\n",
        "    labels = None,\n",
        "    color_mode = \"rgb\",\n",
        "    image_size = (IMAGE_SIZE , IMAGE_SIZE),\n",
        "    batch_size = BATCH_SIZE ,\n",
        "    shuffle = True,\n",
        "    seed = 42,\n",
        "    interpolation = \"bilinear\",\n",
        ")"
      ],
      "metadata": {
        "id": "Wn0oX7ax_KSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocess the data\n",
        "def preprocess(img):\n",
        "  img = tf.cast(img, \"float32\") / 255.0\n",
        "  return img\n",
        "\n",
        "train = train_data.map(lambda x: preprocess(x))"
      ],
      "metadata": {
        "id": "s1AHb8C0_tJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample = sample_batch(train)"
      ],
      "metadata": {
        "id": "Su6A0X_J_4aF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show some faces from the training set\n"
      ],
      "metadata": {
        "id": "BX8pUaw7_7go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Bulid hte varaitional autoencoder"
      ],
      "metadata": {
        "id": "UpA4vi7o__4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(layers.Layer):\n",
        "  def call(self, inputs):\n",
        "    z_mean , z_log_var = inputs\n",
        "    batch = tf.shape(z_mean)[0]\n",
        "    dim = tf.shape(z_mean)[1]\n",
        "    epsilion = K.random_normal(shape = (batch , dim))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
      ],
      "metadata": {
        "id": "La3lEh-x_-PB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encoder\n",
        "encoder_input = layers.Input(\n",
        "    shape = (IMAGE_SIZE , IMAGE_SIZE , CHANNELS), name = \"encoder_input\"\n",
        ")\n",
        "x = layers.Conv2D(NUM_FEATURES , kernel_size = 3 , strides = 2, padding = \"same\")(\n",
        "    encoder_input\n",
        ")\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LEakyReLU()(x)\n",
        "x = layers.Conv2D(NUM_FEATURES, kernel_size = 3 , strides = 2, padding = \"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(NUM_FEATURES , kernel_size = 3, strides = 2, padding = \"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(NUM_FEATURES , kernel_size = 3, strides = 2, padding =\"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "shape_before_flattening = K.int_shape(x)[1:]\n",
        "\n",
        "x = layers..Flattening()(x)\n",
        "z_mean = layers.Dense(Z_DIM , name = \"z_mean\")(x)\n",
        "z_log_var = layers.Dense(Z_DIM , name = \"z_log_var\")(x)\n",
        "z = Sampling()([z_mean , z_log_var])\n",
        "\n",
        "encoder = models.Model(encoder_input , [z_mean , z_log_var, z], name = \"encoder\")\n",
        "encoder.summary()"
      ],
      "metadata": {
        "id": "YcNwf4ifAX-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#decoder\n",
        "decoder_input = layers.Input(shape =(Z_DIM,), name = \"decoder_input\")\n",
        "x = layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Reshape(shape_before_flattening)(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    NUM_FEATURES , kernel_size = 3, strides = 2, padding = \"same\"\n",
        ")\n",
        "\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    NUM_FEATURES , kernel_size = 3, strides = 2, padding = \"same\"\n",
        ")(x)\n",
        "\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    NUM_FEATURES , kernel_size = 3, strides = 2, padding = \"same\"\n",
        ")(x)\n",
        "\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    NUM_FEATURES , kernel_size = 3, strides = 2, padding = \"same\"\n",
        ")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "decoder_ouput = layers.Conv2DTranspose(\n",
        "    CHANNELS , kernel_size = 3 , strides = 1, activation = \"sigmoid\" , padding = \"same\"\n",
        ")(x)\n",
        "decoder = models.Model(decoder_input, decoder_output)\n",
        "decoder.summary()"
      ],
      "metadata": {
        "id": "Zlomm_SVCRJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(models.Model):\n",
        "  def __init__(self, encoder, decoder, **kwargs):\n",
        "    super(VAE, self).__init__(**kwargs)\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.total_loss_tracker = metrics.Mean(name = \"total_loss\")\n",
        "    self.reconstruction_loss_tracker = metrics.Mean(\n",
        "        name = \"reconstruction_loss\"\n",
        "    )\n",
        "    self.kl_loss_tracker = metrics.Mean(name= \"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "      return [\n",
        "          self.total_loss_tracker,\n",
        "          self.reconstruction_loss_tracker,\n",
        "          self.kl_loss_tracker,\n",
        "      ]\n",
        "\n",
        "    def call(self, inputs):\n",
        "      \"\"\" Call the model on a particular input.\"\"\"\n",
        "      z_mean , z_log_var , z = encoder(inputs)\n",
        "      reconstruction = decoder(z)\n",
        "      return z_mean , z_log_var , reconstruction\n",
        "\n",
        "    def train_step(self, data):\n",
        "      \"\"\"Step run during training\"\"\"\n",
        "      with tf.GradientTape() as tape:\n",
        "        z_mean , z_log_var , reconstruction = self(data, training = True)\n",
        "        reconstruction_loss = tf.reduce_mean(\n",
        "            BETA * losses.mean_squared_error(data, reconstruction)\n",
        "        )\n",
        "        kl_loss = tf.reduce_mean(\n",
        "            tf.reduce_sum(\n",
        "                -0.5,\n",
        "                * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)),\n",
        "                axis = 1,\n",
        "            )\n",
        "        )\n",
        "        total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "      grads = tape.gradient(total_loss , self.trainable_wights)\n",
        "      self.optimizer.apply_gradients(zip(grads , self.trainable_weights))\n",
        "\n",
        "      self.total_loss_tracker.update_state(total_loss)\n",
        "      self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "      self.kl_loss_tracker.update_state(kl_loss)\n",
        "\n",
        "\n",
        "      return {\n",
        "          \"loss\" : self.total_loss_tracker.result(),\n",
        "          \"reconstruction_loss\": self.reconstruciton_loss_tracker.result(),\n",
        "          \"kl_loss\": self.kl_loss_tracker,.result(),\n",
        "      }\n",
        "\n",
        "    def test_step(self, data):\n",
        "      \"\"\"Step run during validation\"\"\"\n",
        "\n",
        "      if isinstance(data, tuple):\n",
        "        data = data[0]\n",
        "\n",
        "      z_mean , z_log_var, reconstruction = self(data)\n",
        "      reconstruction_loss = tf.reduce_mean(\n",
        "          BETA * losses.mean_squared_error(data, reconstruction)\n",
        "      )\n",
        "      kl_loss = tf.reduce_mean(\n",
        "          tf.reduce_sum(\n",
        "              -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)),\n",
        "              axis = 1,\n",
        "          )\n",
        "      )\n",
        "      total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "      return{\n",
        "          \"loss\": total_loss,\n",
        "          \"reconstruction_loss\" : reconstruction_loss,\n",
        "          \"kl_loss\": kl_loss,\n",
        "      }\n"
      ],
      "metadata": {
        "id": "9PX8llWsELoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a varational autoencoder\n",
        "vae = VAE(encoder, decoder)"
      ],
      "metadata": {
        "id": "_2zo7oSvH8F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Train the variational autoencoder"
      ],
      "metadata": {
        "id": "lBaEscRAIBcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#compile the varational encoder\n",
        "optimizer = optimizers.Adam(learning_rate  = LEARNING_RATE)\n",
        "vae.compile(optimizer = optimizer)"
      ],
      "metadata": {
        "id": "k30sVxAAIAc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a model save checkpoint\n",
        "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
        "    filepath = \"./checkpoint\",\n",
        "    save_weight_only = False,\n",
        "    save_freq = \"epoch\",\n",
        "    monitor = \"loss\",\n",
        "    mode = \"min\",\n",
        "    save_best_only = True,\n",
        "    verbose = 0,\n",
        ")\n",
        "\n",
        "\n",
        "tensorboard_callback = callbacks.TensorBoard(log_dir = \"./logs\")\n",
        "\n",
        "class ImageGenerator(callbacks.Callback):\n",
        "  def __init__(self, num_img, latent_dim):\n",
        "    self.num_img = num_img\n",
        "    self.latent_dim = latent_dim\n",
        "\n",
        "  def on_epoch_end(self, epoch , logs = None):\n",
        "    random_latent_vectors = tf.random.normal(\n",
        "        shape = (self.num_img , self.latent_dim)\n",
        "    )\n",
        "    generated_images = self.model.decoder(random_latent_vectors)\n",
        "    generated_images *= 255\n",
        "    generated_images.numpy()\n",
        "    for i in range(self.num_img):\n",
        "      img = utils.array_to_img(generated_images[i])\n",
        "      img.save(\"./output/generated_img_%03d_%d.png\" % (epoch , i))"
      ],
      "metadata": {
        "id": "OAr0-kIHITuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load old weights if required\n",
        "if LOAD_MODEL:\n",
        "  vae.load_weights(\"./models/vae\")\n",
        "  tmp = vae.predict(train.take(1))"
      ],
      "metadata": {
        "id": "PO2Wz106LDOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.fit(\n",
        "    train,\n",
        "    epochs = EPOCHS,\n",
        "    callbacks = [\n",
        "        model_checkpoint_callback,\n",
        "        tensorboard_callback,\n",
        "        ImageGenerator(num_img = 10, latent_dim = Z_DIM),\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "LTjf3QVmLa4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save the final models\n",
        "vae.save(\"./models/vae\")\n",
        "encoder.save(\"./models/encoder\")\n",
        "decoder.save(\"./models/decoder\")"
      ],
      "metadata": {
        "id": "mYDl70EDLm72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Reconstruciton using the variational autoencoder"
      ],
      "metadata": {
        "id": "02WOvRc6LxV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Select a subset of the test set\n",
        "batched_to_predict = 1\n",
        "example_images = np.array(\n",
        "    list(train.take(batches_to_predict).get_single_element())\n",
        ")"
      ],
      "metadata": {
        "id": "gFc0LLf1LwDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create autoencoder predictions and display\n",
        "z_mean , z_log_var , reconstructions = vae.predict(example_images)\n",
        "print(\"Example real faces\")\n",
        "display(example_images)\n",
        "print(\"Reconstructions\")\n",
        "display(reconstructions)"
      ],
      "metadata": {
        "id": "SJRYu0PbMFPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Latent space distribution"
      ],
      "metadata": {
        "id": "LqEOGEyYMZVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, _, z  =vae.encoder.predict(example_images)\n",
        "\n",
        "x = np.linspace(-3, 3, 100)\n",
        "\n",
        "fig = plt.figure(figsize = ( 20 , 5))\n",
        "fig.subplots_adjust(hspace = 0.6 , wspace = 0.4)\n",
        "\n",
        "for i in range(50):\n",
        "  ax = fig.add_subplots(5, 10 , i + 1)\n",
        "  ax.hist(z[:, i], density = True, bins = 20)\n",
        "  ax.axis(\"off\")\n",
        "  ax.text(\n",
        "      0.5, -0.35, str(i) , fontsize = 10 , ha = \"center\" , transform = ax.transAxes\n",
        "  )\n",
        "  ax.plot(x, norm.pdf(x))\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GqxrU86vMYdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Generate new faces"
      ],
      "metadata": {
        "id": "jVgLXpEqNRw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sampling some points in the latent space ,from the standard normal distribution\n",
        "grid_width , grid_height = (10 , 3)\n",
        "z_sample = np.random.normal(size = (grid_width * grid_height , Z_DIM))\n"
      ],
      "metadata": {
        "id": "oAznqzLkNQlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#decode the smaples points\n",
        "reconstrucitons = decoder.predict(z_sample)"
      ],
      "metadata": {
        "id": "LktPCBzhNjzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Draw a plot of decoder images\n",
        "fig = plt.figure(figsize = (18, 5))\n",
        "fig.subplots_adjust(hspace = 0.4 , wspace = 0.4)\n",
        "\n",
        "#output the grid of faces\n",
        "for i in range(grid_width * grid_height):\n",
        "  ax = fig.add_subplots(grid_height , grid_weight, i + 1)\n",
        "  ax.axis(\"off\")\n",
        "  ax.imshow(reconstructions[i , : , :])"
      ],
      "metadata": {
        "id": "qwxpWRM2Nqq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Manipulate the images"
      ],
      "metadata": {
        "id": "zz0EbmKJIiKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load the label dataset\n",
        "\n",
        "attributes = pd.read_csv(\"./app/data/celeba-dataset/list_attr_celeba.csv\")\n",
        "print(attributes.columns)\n",
        "attributes.head()"
      ],
      "metadata": {
        "id": "q0UTHLAvIhOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the face data with label attached\n",
        "LABEL = \"BLOND_Hair\"\n",
        "labelled_test = utils.image_dataset_from_directory(\n",
        "    \"./app/data/celeba-dataset/img_align_celeba\",\n",
        "    labels = attributes[LABEL].tolist(),\n",
        "    color_mode = \"rgb\",\n",
        "    image_size = (IMAGE_SIZE , IMAGE_SIZE),\n",
        "    batch_size = BATCH_SIZE ,\n",
        "    shuffle = True,\n",
        "    seed = 42,\n",
        "    validation_split = 0.2,\n",
        "    subset = \"validation\",\n",
        "    interpolation = \"bilinear\",\n",
        ")\n",
        "\n",
        "labelled = labelled_test.map(lambda x, y : (preprocess(x), y))"
      ],
      "metadata": {
        "id": "B1wNPs-zIv46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the attributes vector\n",
        "attrubute_vec = get_vector_from_label(labelled, vae, Z_DIM, LABEL)\n"
      ],
      "metadata": {
        "id": "-OYfAi0JJZkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add vector to images\n",
        "add_vector_to_images(labelled , vae , attribute_vec)"
      ],
      "metadata": {
        "id": "eTduE6fnJimu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "morph_faces(labelled , vae)"
      ],
      "metadata": {
        "id": "jML4OlNXJoxF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}