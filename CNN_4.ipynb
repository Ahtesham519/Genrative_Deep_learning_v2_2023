{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPeCYb6hHgy0IgHHWle2dIo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahtesham519/Genrative_Deep_learning_v2_2023/blob/main/CNN_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UX1X_LpMXJJ3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras import layers, models, optimizers, utils , datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0. Parameters"
      ],
      "metadata": {
        "id": "V3kQIm6gXVY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 10\n"
      ],
      "metadata": {
        "id": "qA_wdlZtXUto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Prepare the data"
      ],
      "metadata": {
        "id": "VzN-BKgmXaP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train , y_train ) , (x_test, y_test) = datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "sHd6QuxZXZPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "y_train = utils.to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = utils.to_categorical(y_test, NUM_CLASSES)"
      ],
      "metadata": {
        "id": "rnqQ0SeQXjkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Build the model"
      ],
      "metadata": {
        "id": "BZEDu5_pX2Me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = layers.Input((32,32,3))\n",
        "\n",
        "x = layers.Conv2D(filters = 32, kernel_size = 3, strides = 1, padding = \"same\")(\n",
        "    input_layer\n",
        ")\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Conv2D(filters = 32 , kernel_size = 3, strides = 2, padding = \"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Conv2D(filters = 64 , kernel_size = 3, strides = 1 , padding = \"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Conv2D(filters = 64 , kernel_size = 3, strides = 2, padding = \"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "\n",
        "x = layers.Dense(128)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Dropout(rate = 0.5)(x)\n",
        "\n",
        "x = layers.Dense(NUM_CLASSES)(x)\n",
        "output_layer = layers.Activation(\"softmax\")(x)\n",
        "\n",
        "model = models.Model(input_layer, output_layer)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "BanPH1GEX1K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Train the model"
      ],
      "metadata": {
        "id": "m8jYk3eEZMCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = optimizers.Adam(learning_rate = 0.0005)\n",
        "model.compile(\n",
        "    loss = \"categorical_crossentropy\" , optimizer = opt  ,metrics = [\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "Ny6jB9fkZKVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    x_train,\n",
        "    y_train ,\n",
        "    batch_Size = 32,\n",
        "    epochs = 10,\n",
        "    shuffle = True,\n",
        "    validation_data = (x_test, y_test)\n",
        ")"
      ],
      "metadata": {
        "id": "32WbnVl8ZsEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Evaluation"
      ],
      "metadata": {
        "id": "fdren0AcZ7Xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test , y_test , batch_size = 1000)"
      ],
      "metadata": {
        "id": "2KM3b0gyZ0_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSES = np.array(\n",
        "    [\n",
        "        \"airplane\" ,\n",
        "        \"automobile\",\n",
        "        \"bird\",\n",
        "        \"cat\",\n",
        "        \"deer\",\n",
        "        \"dog\",\n",
        "        \"frog\",\n",
        "        \"horse\",\n",
        "        \"ship\",\n",
        "        \"truck\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "preds = model.predict(x_test)\n",
        "preds_single = CLASSES[np.argmax(preds, axis = -1)]\n",
        "actual_single = CLASSES[np.argmax(y_test, axis = -1)]"
      ],
      "metadata": {
        "id": "rJKSVT66aCbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n_to_show = 10\n",
        "indices = np.random.choice(range(len(x_test)), n_to_show)\n",
        "\n",
        "fig = plt.figure(figsize = (15, 3))\n",
        "fig.subplots_adjust(hspace = 0.4 , wspace = 0.4)\n",
        "\n",
        "\n",
        "for i , idx in enumerate(indices):\n",
        "  img = x_test[idx]\n",
        "  ax = fig.add_subplot(1, n_to_show, i + 1)\n",
        "  ax.axis(\"off\")\n",
        "  ax.test(\n",
        "      0.5,\n",
        "      -0.35,\n",
        "      \"pred = \" + str(preds_single[idx]),\n",
        "      fontsize = 10,\n",
        "      ha = \"center\",\n",
        "      transform = ax.transAxes,\n",
        "  )\n",
        "  ax.text(\n",
        "      0.5,\n",
        "      -0.7,\n",
        "      \"act = \" + str(actual_single[idx]),\n",
        "      fontsize = 10,\n",
        "      ha = \"center\",\n",
        "      transform = ax.transAxes,\n",
        "  )\n",
        "  ax.imshow(img)"
      ],
      "metadata": {
        "id": "pJ3wpcP3af5b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}