{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0u2sF+W/7J6ZHZ6wlHTmG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahtesham519/Genrative_Deep_learning_v2_2023/blob/main/DCGAN_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGi0HGwViKjZ"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import(\n",
        "    layers,\n",
        "    models,\n",
        "    callbacks,\n",
        "    losses,\n",
        "    utils ,\n",
        "    metrics ,\n",
        "    optimizers,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0. Parameters"
      ],
      "metadata": {
        "id": "4h3_mRRHipNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 64\n",
        "CHANNELS = 1\n",
        "BATCH_SIZE = 128\n",
        "Z_DIM = 100\n",
        "EPOCHS = 300\n",
        "LOAD_MODEL = False\n",
        "ADAM_BETA_1 = 0.5\n",
        "ADAM_BETA_2 = 0.999\n",
        "LEARNING_RATE = 0.0002\n",
        "NOISE_PARAM = 0.1"
      ],
      "metadata": {
        "id": "K69y-3WQiofW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Prepare the data"
      ],
      "metadata": {
        "id": "5FlOu7vji-Yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dat = utils.image_dataset_from_directory(\n",
        "    \"/app/data/lego-brick-images/dataset/\",\n",
        "    labels = None,\n",
        "    color_mode = \"grayscale\",\n",
        "    image_size = (IMAGE_SIZE  , IMAGE_SIZE),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = True,\n",
        "    seed = 42,\n",
        "    interpolation = \"bilinear\",\n",
        ")"
      ],
      "metadata": {
        "id": "G7H5IesCi9pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(img):\n",
        "  \"\"\"\n",
        "  Normalize and reshape the images\n",
        "  \"\"\"\n",
        "  img = (tf.cast(img , \"float32\") - 127.5)/ 127.5\n",
        "  return img\n",
        "\n",
        "train = train_data.map(lambda x: preprocess(x))"
      ],
      "metadata": {
        "id": "YHb9smA0jZAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample = sample_batch(train)"
      ],
      "metadata": {
        "id": "LI3Ip0zMjj4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Build the GAN"
      ],
      "metadata": {
        "id": "PquJJJGPjuS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator_input = layers.Input(shape = (IMAGE_SIZE , IMAGE_SIZE , CHANNELS))\n",
        "x = layers.Conv2D(64, kernel_size = 4, strides=2 , padding = \"same\" , use_bais = False)(\n",
        "    discriminator_input\n",
        ")\n",
        "x = layers.LeakyRelu(0.2)(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Conv2D(\n",
        "    128, kernel_size = 4, strides = 2, padding = \"same\", use_bais = False\n",
        ")(x)\n",
        "x = layers.BatchNormalization(momentum = 0.9)(x)\n",
        "x = layers.LeakyReLU(0.2)(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Conv2D(\n",
        "    256, kernel_size = 4, strides = 2 , padding = \"same\", use_bias = False\n",
        ")(x)\n",
        "x = layers.BatchNormalization(momentum = 0.9)(x)\n",
        "x = layers.LeakyReLU(0.2)(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Conv2D(\n",
        "    512, kernel_size = 4 , strides = 2, padding = \"same\" , use_bias = False\n",
        ")(x)\n",
        "x = layers.BatchNormalization(momentum = 0.9)(x)\n",
        "x = layers.LeakyReLU(0.2)(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Conv2D(\n",
        "    1,\n",
        "    kernel_size = 4,\n",
        "    strides = 1,\n",
        "    padding = \"valid\",\n",
        "    use_bias = False,\n",
        "    activation = \"sigmoid\",\n",
        ")(x)\n",
        "discriminator_output = layers.Flatten()(x)\n",
        "\n",
        "discriminator = models.Model(discriminator_input, discriminator_output)\n",
        "discriminator.summary()\n"
      ],
      "metadata": {
        "id": "qCpUQGEajsq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_input = layers.Input(shape = (Z_DIM,))\n",
        "x = layers.Reshape((1,1,Z_DIM ))(generator_input)\n",
        "x = layers.Conv2DTranspose(\n",
        "    512, kernel_size = 4, strides = 1, padding = \"valid\", use_bias = False\n",
        ")(x)\n",
        "x = layers.BatchNormalization(momentum = 0.9)(x)\n",
        "x = layers.LeakyReLU(0.2)(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    256, kernel_size = 4 , strides = 2, padding = \"same\", use_bias = False\n",
        ")(x)\n",
        "x = layers.BatchNormalization(momentum  = 0.9)(x)\n",
        "x = layers.LeakyReLU(0.2)(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    128, kernel_size = 4, strides = 2, padding = \"same\", use_bias = False\n",
        ")(x)\n",
        "x = layers.BatchNormalization(momentum = 0.9)(x)\n",
        "x = layers.LeakyReLU(0.2)(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    64 , kernel_size = 4, strides = 2, padding = \"same\", use_bias = False\n",
        ")(x)\n",
        "x = layers.BatchNormalization(momentum = 0.9)(x)\n",
        "x = layers.LeakyReLU(0.2)(x)\n",
        "generator_output = layers.Conv2DTranspose(\n",
        "    CHANNELS,\n",
        "    kernel_size = 4,\n",
        "    strides = 2,\n",
        "    padding = \"same\",\n",
        "    use_bias = False,\n",
        "    activation = \"tanh\",\n",
        ")(x)\n",
        "generator = models.Model(generator_input, generator_output)\n",
        "generator.summary()"
      ],
      "metadata": {
        "id": "MVaxcoenlZoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DCGAN(models.Model):\n",
        "  def __init__(self, discriminator , generator, latent_dim):\n",
        "    super(DCGAN, self).__init__()\n",
        "    self.discriminator = discriminator\n",
        "    self.generator = generator\n",
        "    self.latent_dim = latent_dim\n",
        "\n",
        "  def compile(self, d_optimizer , g_optimizer):\n",
        "    super(DCGAN, self).compile()\n",
        "    self.loss_fn = losses.BinaryCrossentropy()\n",
        "    self.d_optimizer = d_optimizer\n",
        "    self.g_optimizer = g_optimizer\n",
        "    self.d_loss_metric = metrics.Mean(name = \"d_loss\")\n",
        "    self.d_real_acc_metric = metrics.BinaryAccuracy(name = \"d_real_acc\")\n",
        "    self.d_fake_acc_metric = metrics.BinaryAccuracy(name = \"d_fake_acc\")\n",
        "    self.d_acc_metric = metrics.BinaryAccuracy(name = \"d_acc\")\n",
        "    self.g_loss_metric = metrics.Mean(name = \"g_loss\")\n",
        "    self.g_acc_metric = metrics.BinaryAccuracy(name = \"g_acc\")\n",
        "\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return [\n",
        "        self.d_loss_metric,\n",
        "        self.d_real_acc_metric,\n",
        "        self.d_fake_acc_metric,\n",
        "        self.d_acc_metric,\n",
        "        self.g_loss_metric,\n",
        "        self.g_acc_metric,\n",
        "    ]\n",
        "\n",
        "  def train_step(self, real_images):\n",
        "    batch_size = tf.shape(real_images)[0]\n",
        "    random_latent_vectors = tf.random.normal(\n",
        "        shape = (batch_size , self.latent_dim)\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = self.generator(\n",
        "          random_latent_vectors , training = True\n",
        "      )\n",
        "      real_predictions = self.discriminator(real_images, training = True)\n",
        "      fake_predictions = self.discriminator(\n",
        "          generated_images , training = True\n",
        "      )\n",
        "\n",
        "      real_labels = tf.ones_like(real_predictions)\n",
        "      real_noisy_labels = real_labels + NOISE_PARAM * tf.random.uniform(\n",
        "          tf.shape(real_predictions)\n",
        "      )\n",
        "      fake_labels = tf.zeros_like(fake_predictions)\n",
        "      fake_noisy_labels = fake_labels - NOISE_PARAM * tf.random.uniform(\n",
        "          tf.shape(fake_predictions)\n",
        "      )\n",
        "\n",
        "      d_real_loss = self.loss_fn(real_noisy_labels , real_predictions)\n",
        "      d_fake_loss = self.loss_fn(fake_noisy_labels , fake_predictions)\n",
        "      d_loss = (d_real_loss + d_fake_loss) / 2.0\n",
        "\n",
        "      g_loss = self.loss_fn(real_labels , fake_predictions)\n",
        "\n",
        "  gradients_of_discriminator = disc_tape.gradient(\n",
        "      d_loss, self.discriminator.trainable_variables\n",
        "  )\n",
        "  gradients_of_generator = gen_tape.gradient(\n",
        "      g_loss , self.generator.trainable_variables\n",
        "  )\n",
        "\n",
        "  self.d_optimizer.apply_gradients(\n",
        "      zip(gradients_of_discriminator, discriminator.trainable_variables)\n",
        "  )\n",
        "  self.g_optimizer.apply_gradients(\n",
        "      zip(gradients_of_generator , generator.trainable_variables)\n",
        "  )\n",
        "\n",
        "  self.d_loss_metric.update_state(d_loss)\n",
        "  self.d_real_acc_metric.update_state(real_labels, real_predictions)\n",
        "  self.d_fake_acc_metric.update_state(fake_labels, fake_predictions)\n",
        "  self.d_acc_metric.update_state(\n",
        "      [real_labels, fake_labels] , [real_predictions, fake_predictions]\n",
        "  )\n",
        "  self.g_loss_metric.update_state(g_loss)\n",
        "  self.g_acc_metric.upadte_state(real_labels, fake_predictions)\n",
        "\n",
        "\n",
        "  return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "HnZpJFCInEtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a DCGAN\n",
        "dcgan = DCGAN(\n",
        "    discriminator = discriminator, generator = generator , latent_dim = Z_DIM\n",
        ")"
      ],
      "metadata": {
        "id": "is-P-AmKry-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if LOAD_MODEL:\n",
        "  dcgan.load_weights(\"./checkpoint/checkpoint.ckpt\")"
      ],
      "metadata": {
        "id": "KhFRj7DLr-SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Train the GAN"
      ],
      "metadata": {
        "id": "WqIOJuHFsEuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dcgan.compile(\n",
        "    d_optimizer = optimizers.Adam(\n",
        "        learning_rate = LEARNING_RATE, beta_1 = ADAM_BETA_1 , beta_2 = ADAM_BETA_2\n",
        "    ),\n",
        "    g_optimizers = optimizers.Adam(\n",
        "        learning_rate = LEARNING_RATE , beta_1 = ADAM_BETA_1 , beta_2 = ADAM_BETA_2\n",
        "    ),\n",
        ")\n"
      ],
      "metadata": {
        "id": "_1zAs0CTsEA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a model save checkpoint\n",
        "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
        "    filepath = \"./checkpoint.ckpt\",\n",
        "    save_weights_only = True,\n",
        "    save_freq = \"epoch\",\n",
        "    verbose = 0,\n",
        ")\n",
        "\n",
        "tensorboard_callback = callbacks.TensorBoard(log_dir = \"./logs\")\n",
        "\n",
        "\n",
        "class ImageGenerator(callbacks.Callback):\n",
        "  def __init__(self, num_img , latent_dim):\n",
        "    self.num_img = num_img\n",
        "    self.latent_dim  = latent_dim\n",
        "\n",
        "  def on_epoch_end(self, epoch , logs = None):\n",
        "    random_latent_vectors = tf.random.normal(\n",
        "        shape = (self.num_img , self.latent_dim)\n",
        "    )\n",
        "    generated_images = self.model.generator(random_latent_vectors)\n",
        "    generated_images = generated_images * 127.5 + 127.5\n",
        "    generated_images = generated_images.numpy()\n",
        "    display(\n",
        "        generated_images,\n",
        "        save_to = \"./ouput.generated_img_%03d.png\" % (epoch)\n",
        "    )\n",
        ""
      ],
      "metadata": {
        "id": "2EUCmXFSsqVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dcgan.fit(\n",
        "    train,\n",
        "    epochs = EPOCHS ,\n",
        "    callbacks = [\n",
        "        model_checkpoint_callback,\n",
        "        tensorboard_callback,\n",
        "        ImageGenerator(num_img = 10, latent_dim = Z_DIM),\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "FudlMldEtuX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the final models\n",
        "generator.save(\"./models/generator\")\n",
        "discriminator.save(\"./models/discriminator\")\n"
      ],
      "metadata": {
        "id": "c6hfEPyNt8kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Generate new images"
      ],
      "metadata": {
        "id": "RrUj2toJuHBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sample some points in the latent space , from the stadrads normal distributation\n",
        "grid_width , grid_height = ( 10 , 3)\n",
        "z_sample = np.random.normal(size =(grid_width * grid_height  , Z_DIM))\n",
        "z_sample = np.random.normal(size = (grid_width * grid_height , Z_DIM))\n"
      ],
      "metadata": {
        "id": "2pxWxnWquGCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decode the sampled points\n",
        "reconstructions = generator.predict(z_sample)"
      ],
      "metadata": {
        "id": "VzILz_nhuqv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Draw a plot of decoded images\n",
        "fig = plt.figure(figsize = (18, 5))\n",
        "fig.subplots_adjust(hspace = 0.4, wspace = 0.4)\n",
        "\n",
        "#output the grid of faces\n",
        "for i in range(grid_width * grid_height):\n",
        "  ax = fig.add_subplot(grid_height , grid_width , i + 1)\n",
        "  ax.axis(\"off\")\n",
        "  ax.imshow(reconstructions[i, : , :] , cmap = \"Greys\")\n",
        ""
      ],
      "metadata": {
        "id": "HXcgGCCgvXgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_images(img1, img2):\n",
        "  return np.mean(np.abs(img1 - img2))"
      ],
      "metadata": {
        "id": "d1MagEIlzu4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = []\n",
        "for i in train.as_numpy_iterator():\n",
        "  all_data.extend(i)\n",
        "all_data = np.arry(all_data)"
      ],
      "metadata": {
        "id": "8RVffxubz1-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r, c = 3, 5\n",
        "fig, axs = plt.subplots(r, c, figsize = (10, 6))\n",
        "fig.suptitle(\"Generated images\", frontsize = 20)\n",
        "\n",
        "noise = np.random.normal(size = ( r * c, Z_DIM))\n",
        "gen_imgs = generator.predict(noise)\n",
        "\n",
        "cnt = 0\n",
        "for i in range(r):\n",
        "  for j in range(c):\n",
        "    axs[i, j].imshow(gen_imgs[cnt] . cmap = \"gray_r\")\n",
        "    axs[i, j].axis(\"off\")\n",
        "    cnt += 1\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1EQp7J3h0ASj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(r, c, figsize = (10, 6))\n",
        "fig.suptitle(\"Closet images in the training set\" , fontsize = 20)\n",
        "\n",
        "cnt = 0\n",
        "for i in range(r):\n",
        "  for j in range(c):\n",
        "    c_diff = 99999\n",
        "    c_img = None\n",
        "    for k_idx , k in enumerate(all_data):\n",
        "      diff = compare_images(gen_imgs[cnt] , k)\n",
        "      if diff < c_diff:\n",
        "        c_img = np.copy(k)\n",
        "        c_diff = diff\n",
        "    axs[i, j].imshow(c_img , cmap = \"gray_r\")\n",
        "    axs[i, j].axis(\"off\")\n",
        "    cnt += 1\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w_-wMsyt0hth"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}