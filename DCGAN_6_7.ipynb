{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7wNuXBbtd8sXY3Px+/64a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahtesham519/Genrative_Deep_learning_v2_2023/blob/main/DCGAN_6_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkkD0pA1h93R"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import(\n",
        "    layers,\n",
        "    models,\n",
        "    callbacks,\n",
        "    losses,\n",
        "    utils,\n",
        "    metrics,\n",
        "    optimizers,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0. Parameters"
      ],
      "metadata": {
        "id": "rRiTY0C7iVSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 64\n",
        "CHANNELS = 1\n",
        "BATCH_SIZE = 128\n",
        "Z_DIM = 100\n",
        "EPOCHS = 300\n",
        "LOAD_MODEL = False\n",
        "ADAM_BETA_1 = 0.5\n",
        "ADAM_BETA_2 = 0.999\n",
        "LEANING_RATE = 0.0002\n",
        "NOISE_PARAM = 0.1\n"
      ],
      "metadata": {
        "id": "yVI6h77IiT31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Prepare the data\n"
      ],
      "metadata": {
        "id": "Q-0geoHriqn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = utils.image_dataset_from_directory(\n",
        "    \"/app/data/lego-brick-images/dataset/\",\n",
        "    labels = None,\n",
        "    color_mode = \"grayscale\",\n",
        "    image_size = (IMAGE_SIZE , IMAGE_SIZE),\n",
        "    batch_size = BATCH_SIZE ,\n",
        "    shuffle = True,\n",
        "    seed = 42,\n",
        "    interpolation = \"bilinear\",\n",
        ")"
      ],
      "metadata": {
        "id": "LJ-1jKX8ipy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(img):\n",
        "  \"\"\"\n",
        "  Normalize and reshape the images\n",
        "  \"\"\"\n",
        "  img = (tf.cast(img , \"float32\") - 127.5) / 127.5\n",
        "  return img\n",
        "\n",
        "train = train_data.map(lambda x: preprocess(x))"
      ],
      "metadata": {
        "id": "mTew2XWojFtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample = sample_batch(train)"
      ],
      "metadata": {
        "id": "xvWCtZMZjVus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Bulid the GAN"
      ],
      "metadata": {
        "id": "CFSrjXjqjajM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "discriminatoe_input = layers.Input(shape = (IMAGE_SIZE , IMAGE_SIZE , CHANNELS))\n",
        "x = layers.Conv2D(64, kernel_size = 4, stides = 2, padding = \"same\", use_bais = False)(\n",
        "    discriminator_input\n",
        ")\n",
        "x =layers.LeakyReLU(0.2)(x)\n",
        " x= layers.Dropout(0.3)(x)\n",
        " x = layers.Conv2D(\n",
        "     128, kernel_size  = 4 ,strides = 2, padding = \"same\", use_bias = False\n",
        " )(x)\n",
        " x = layers.BatchNormalization(momentum = 0.9)(x)\n",
        " x = layers.LeakyReLU(0.2)(x)\n",
        " x = layers.Dropout(0.3)(x)\n",
        " x = layers.Conv2D(\n",
        "     256, kernel_size = 4 , strides = 2, padding = \"same\", use_bias = False\n",
        " )(x)\n",
        " x = layers.BatchNormalization(momentum = 0.9)(x)\n",
        " x = layers.LeakyReLU(0.2)(x)\n",
        " x = layers.Dropout(0.3)(x)\n",
        " x = layers.Conv2D(\n",
        "     512, kernel_size= 4 , strides = 2, padding = \"same\", use_bias = False\n",
        " )(x)\n",
        " x = layers.BatchNormalization(momentum = 0.9)(x)\n",
        " x = layers.LeakyReLU(0.2)(x)\n",
        " x = layers.Dropout(0.3)(x)\n",
        " x = layers.Conv2D(\n",
        "     1,\n",
        "     kernel_size = 4,\n",
        "     strides = 1 ,\n",
        "     padding = \"valid\",\n",
        "     use_bias = False,\n",
        "     activation = \"sigmoid\",\n",
        " )(x)\n",
        " discrminitor_output = layers.Flatten()(x)\n",
        "\n",
        " discriminator = models.Model(dicriminator_input, discriminator_output)\n",
        " discriminator.summary()\n"
      ],
      "metadata": {
        "id": "HG82n35CjYB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_input = layers.Input(shape= (Z_DIM,))\n",
        "x = layers.Reshape((1, 1, Z_DIM))(generator_input)\n",
        "x = layers.Conv2DTranspose(\n",
        "    512, kernel_size = 4, strides =1, padding = \"valid\", use_bias = False\n",
        ")(x)\n",
        "x = layers.BatchNormalization(momentum = 0.9)(x)\n",
        "x = layers.LeakyReLU(0.2)(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    256, kernel_size = 4 , strides = 2, padding = \"same\", use_bias = False\n",
        ")(x)\n",
        "x = layers.BatchNormalization(momentum = 0.9)(x)\n",
        "x = layers.LeakyReLU(0.2)(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    128, kernel_size = 4 , strides = 2 , padding = \"same\", use_bias = False\n",
        ")(x)\n",
        "x = layers.BatchNormalization(momentum = 0.9)(x)\n",
        "x = layers.LeakyReLU(0.2)(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    64, kernel_size = 4, strides = 2, padding = \"same\", use_bias = False\n",
        ")(x)\n",
        "x = layers.BatchNormalization(momentum = 0.9)(x)\n",
        "x = layers.LeakyReLU(0.2)(x)\n",
        "generator_output = layers.Conv2DTranspose(\n",
        "    CHANNELS ,\n",
        "    kernel_size = 4,\n",
        "    strides = 2,\n",
        "    padding = \"same\",\n",
        "    use_bias = False,\n",
        "    activation = \"tanh\",\n",
        ")(x)\n",
        "generator = models.Model(generator_input , generator_output)\n",
        "generator.summary()"
      ],
      "metadata": {
        "id": "JDSxUzzQlCPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DCGAN(mdoels.Model):\n",
        "  def __init__(self.discriminator , generator, latent_dim):\n",
        "    super(DCGAN , self).__init__()\n",
        "    self.discriminator = discriminator\n",
        "    self.generator = generator\n",
        "    self.latent_dim = latent_dim\n",
        "\n",
        "  def compile(self, d_optimizer, g_optimizer):\n",
        "    super(DCGAN, self).compile()\n",
        "    self.loss_fn = losses.compile()\n",
        "    self.d_optimizer = d_optimizer\n",
        "    self.g_optimizer = g_optimizer\n",
        "    self.d_loss_metric = metrics.Mean(name = \"d_loss\")\n",
        "    self.d_real_acc_metric = metrics.BinaryAccuracy(name = \"d_real_acc\")\n",
        "    self.d_fake_acc_metric = metrics.BinaryAccuracy(name = \"d_fake_acc\")\n",
        "    self.d_acc_metric = metrics.BinaryAccuracy(name = \"d_acc\")\n",
        "    self.g_loss_metric = metric.BinaryAccuracy(name = \"g_acc\")\n",
        "\n",
        "\n",
        "  @property\n",
        "\n",
        "  def metrics(self):\n",
        "    return[\n",
        "        self.d_loss_metric,\n",
        "        self.d_real_acc_metric,\n",
        "        self.d_fake_acc_metric,\n",
        "        self.d_acc_metric,\n",
        "        self.g_loss_metric,\n",
        "        self.g_acc_metric,\n",
        "    ]\n",
        "\n",
        "  def train_step(self, real_images):\n",
        "    #sample random points in the latent space\n",
        "    batch_size = tf.shape(real_images)[0]\n",
        "    random_latent_vecotrs = tf.random.normal(\n",
        "        shape = (batch_size, self.latent_dim)\n",
        "    )\n",
        "\n",
        "    #Train the discriminator on fake images\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = self.generator(\n",
        "          random_latent_vectors , trianing = True\n",
        "      )\n",
        "      real_predictions = self.discriminator(real_images , training = True)\n",
        "      fake_predictions = self.discriminator(\n",
        "          generated_images , training  = True\n",
        "      )\n",
        "\n",
        "      real_labels = tf.ones_like(real_predictions)\n",
        "      real_noisy_labels = real_labels + NOISE_PARAM * tf.random.uniform(\n",
        "          tf.shape(ral_predictions)\n",
        "      )\n",
        "      fake_labels = tf.zeros_like(fake_predictions)\n",
        "      fake_noisy_labels = fake_labels - NOISE_PARAM * tf.random.uniform(\n",
        "          tf.shape(fake_predictions)\n",
        "      )\n",
        "\n",
        "      d_real_loss = self.loss_fn(real_noisy_labels , real_predictions)\n",
        "      d_fake_loss = self.loss_fn(fake_noisy_labels, fake_predictions)\n",
        "      d_loss = (d_real_loss + d_fake_loss) / 2.0\n",
        "\n",
        "      g_loss = self.loss_fn(real_labels , fake_predictions)\n",
        "\n",
        "    gradient_of_discriminator = disc_tape.gradient(\n",
        "        d_loss , self.discriminator.trainable_variables\n",
        "    )\n",
        "    gradients_of_generator = gen_tape.gradient(\n",
        "        g_loss, self.generator.trainable_variables\n",
        "    )\n",
        "\n",
        "    self.d_optimizer.apply_gradients(\n",
        "        zip(gradients_of_discriminator, discriminator.trainable_variables)\n",
        "    )\n",
        "    self.g_optimizer.apply_gradients(\n",
        "        zip(gradients_of_genrator, generator.trainable_varaibles)\n",
        "    )\n",
        "\n",
        "    #Update metrics\n",
        "    self.d_loss_metric.update_state(d_loss)\n",
        "    self.d_real_acc_metric.update_state(real_labels , real_predictions)\n",
        "    self.d_fake_acc_metric.update_state(fake_labels, fake_predictions)\n",
        "    self.d_acc_metric.update_state(\n",
        "        [real_labels, fake_labels] , [real_predictions, fake_predictions]\n",
        "    )\n",
        "    self.g_loss_metric.update_state(g_loss)\n",
        "    self.g_acc_metric.update_state(real_labels, fake_predictions)\n",
        "\n",
        "    return {m.name :m.result()  for m in self.metrics}"
      ],
      "metadata": {
        "id": "At4yv6o2mpmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a DCGAN\n",
        "dcgan = DCGAN(\n",
        "    discriminator = discriminator, generator = generator, latent_dim = Z_DIM\n",
        ")"
      ],
      "metadata": {
        "id": "eaB8y3TIUNKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if LOAD_MODEL:\n",
        "  dcgan.load_weights(\"./checkpoint/checkpoint.ckpt\")"
      ],
      "metadata": {
        "id": "J8spyOrXUVAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Train the GAN\n"
      ],
      "metadata": {
        "id": "VKQQ3kmbUcn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dcgan.compile(\n",
        "    d_optimizer = optimizers.Adam(\n",
        "        learning_rate = LEARNING_RATE , beta_1 = ADAM_BETA_1 , beta_2 = ADAM_BETA_2\n",
        "    ),\n",
        "    g_optimizer = optimizers.Adam(\n",
        "        learning_rate = LEARNING_RATE , beta_1 = ADAM_BETA_1, beta_2 = ADAM_BETA_2\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "id": "bor_MpP5Ubfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a model save checkpoint\n",
        "model_checkpoint_Callback = callbacks.ModelChekcpoint(\n",
        "    filepath = \"./checkpoint/checkpoint.ckpt\",\n",
        "    save_weights_only = True,\n",
        "    save_freq = \"epoch\",\n",
        "    verbose = 0,\n",
        ")\n",
        "\n",
        "tensorboard_callback = callbacks.Tensorboard(log_dir = \"./logs\")\n",
        "\n",
        "class ImageGenerator(callbacks.Callback):\n",
        "  def __init__(self, num_img , latent_dim):\n",
        "    self.num_img = num_img\n",
        "    self.latent_dim = latent_dim\n",
        "\n",
        "  def on_epoch_end(self, epoch , logs = None):\n",
        "    random_latent_vectors = tf.random.normal(\n",
        "        shape = (self.num_log , self.latent_dim)\n",
        "    )\n",
        "    generated_images = self.model.generator(random_latent_vectors)\n",
        "    generated_images = generated_images * 127.5 + 127.5\n",
        "    generated_images = generated_images.numpy()\n",
        "    display(\n",
        "        generated_images ,\n",
        "        save_to= \"./output/generated_img_%03d.png\" % (epoch)\n",
        "    )\n",
        ""
      ],
      "metadata": {
        "id": "5ByCSadpUz68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dcgan.fit(\n",
        "    train,\n",
        "    epochs = EPOCHS,\n",
        "    callbacks = [\n",
        "        model_checkpoint_callback,\n",
        "        tensorboard_callback,\n",
        "        ImageGenerator(num_img = 10 , latent_dim = Z_DIM),\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "TvAUa7tQVxli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator.save(\"./models/generator\")\n",
        "dicriminator.save(\"./models/discriminator\")"
      ],
      "metadata": {
        "id": "GwM5fSOUV-0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Generate new images"
      ],
      "metadata": {
        "id": "GLaNoUmCWOWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sample some points in the latent space , form the standrad noraml distribution\n",
        "grid_width , grid_height = (10, 3)\n",
        "z_sample = np.random.normal(size = (grid_width * grid_height , Z_DIM))\n"
      ],
      "metadata": {
        "id": "jEEpgA0mWG6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decode the sampled points\n",
        "reconstructions = generator.predict(z_sample)"
      ],
      "metadata": {
        "id": "8hdIxTO8WhGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Draw a plot of decoded images\n",
        "fig = plt.figure(figsize = (18, 5))\n",
        "fig.subplots.adjust(hspace = 0.4 , wspace = 0.4)\n",
        "\n",
        "#output the grid of faces\n",
        "for i in range(grid_width  * grid_height):\n",
        "  ax = fig.add_subplots(grid_height , grid_width , i+ 1)\n",
        "  ax.axis(\"off\")\n",
        "  ax.imshow(reconstructions[1, : , :] , cmap = \"Greys\")"
      ],
      "metadata": {
        "id": "hdkicP_KXEW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_images(img1  , img2):\n",
        "  return np.mean(np.abs(img1  - img2))"
      ],
      "metadata": {
        "id": "gBogy2AMXlVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = []\n",
        "for i in  train.as_numpy_iterator():\n",
        "  all_data.extend(i)\n",
        "all_data = np.array(all_data)"
      ],
      "metadata": {
        "id": "OMdQY4QjXsqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r, c = 3, 5\n",
        "fig, axs = plt.subplots(r,c,figsize = (10, 5) )\n",
        "fig.subtitle(\"Generated images\", fontsize = 20)\n",
        "\n",
        "noise = np.random.noraml(size = (r * c, Z_DIM))\n",
        "gen_imgs = generator.predict(noise)\n",
        "\n",
        "cnt = 0\n",
        "for i in range(r):\n",
        "  for j in range(c):\n",
        "    axs[i , j].imshow(gen_imgs[cnt] , cmap = \"gray_r\")\n",
        "    axs[i, j ].axis(\"off\")\n",
        "    cnt += 1\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eYgugDEeX1UG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig , axs = plt.subplots(r, c, figsize = (10, 6))\n",
        "fig.subplots(\"Closest images in the training set\" , fontsize = 20)\n",
        "\n",
        "cnt = 0\n",
        "for i in range(r):\n",
        "  for j in range(c):\n",
        "    c_diff = 99999\n",
        "    c_img = None\n",
        "    for k_idx, k in enumerate(all_data):\n",
        "      diff = compare_images(gen_imgs[cnt] , k)\n",
        "      if diff < c_diff:\n",
        "        c_img = np.copy(k)\n",
        "        c_diff = diff\n",
        "    axs[i , j].imshow(c_img, cmap = \"gray_r\")\n",
        "    axs[i, j].axis(\"off\")\n",
        "    cnt += 1\n",
        "\n",
        "plt.show()\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "ghSA5VopYdeL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}