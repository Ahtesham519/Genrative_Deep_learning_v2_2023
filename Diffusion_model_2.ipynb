{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7RNLF//UDIHfKfloIc58I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahtesham519/Genrative_Deep_learning_v2_2023/blob/main/Diffusion_model_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Diffusion model"
      ],
      "metadata": {
        "id": "T-hrV4CVIR7X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2E4c4-ZINxs"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8-colorblind\")\n",
        "\n",
        "import math\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import(\n",
        "    layers,\n",
        "    models,\n",
        "    optimizers,\n",
        "    utils,\n",
        "    callbacks,\n",
        "    metrics,\n",
        "    losses,\n",
        "    activation,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0. Parameters"
      ],
      "metadata": {
        "id": "1hSu7GcII0TT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 64\n",
        "BATCH_SIZE = 64\n",
        "DATASET_REPETITIONS = 5\n",
        "LOAD_MODEL = False\n",
        "\n",
        "NOISE_EMBEDDING_SIZE = 32\n",
        "PLOT_DIFFUSION_STEPS = 20\n",
        "\n",
        "#optimization\n",
        "EMA = 0.999\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "EPOCHS = 50"
      ],
      "metadata": {
        "id": "RJic91T1IyTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Prepare the data"
      ],
      "metadata": {
        "id": "_N4O7uvaJPaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load the data\n",
        "train_data = utils.image_dataset_from_directory(\n",
        "    \"/app/data/pytorch-challange-flower-dataset/dataset\",\n",
        "    labels = None,\n",
        "    image_size = (IMAGE_SIZE , IMAGE_SIZE),\n",
        "    batch_size = None,\n",
        "    shuffle = True,\n",
        "    seed = 42,\n",
        "    interpolation = \"bilibear\",\n",
        ")"
      ],
      "metadata": {
        "id": "W3hqD5ICJONq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare the data\n",
        "def preprocess(img):\n",
        "  img = tf.cast(img, \"float32\") / 255.0\n",
        "  return img\n",
        "\n",
        "train = train_data.map(lambda x: preprocess(x))\n",
        "train = train.repeat(DATASET_REPETITIONS)\n",
        "train = train.batch(BATCH_SIZE, drop_remainder = True)"
      ],
      "metadata": {
        "id": "8OUKX9sGJnSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show some items of clothing from the training set\n",
        "train_sample = sample_batch(train)\n",
        "display(train_sample)"
      ],
      "metadata": {
        "id": "iA8hts7OJ7DE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.1 Diffusion schedules"
      ],
      "metadata": {
        "id": "huoa8C_XOHXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_diffusion_schedule(diffusion_times):\n",
        "  min_rate = 0.0001\n",
        "  max_rate = 0.02\n",
        "  betas = min_rate + diffusion_times_ * (max_rate - min_rate)\n",
        "  alphas = 1 - betas\n",
        "  alpha_bars = tf.math.cumprod(alphas)\n",
        "  signal_rate = tf.sqrt(alpha_bars)\n",
        "  noise_rate = tf.sqrt(1 - alpha_bars)\n",
        "  return noise_rates  , signal_rates"
      ],
      "metadata": {
        "id": "CXoRKViiOGsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_diffusion_schedule(diffsuion_times):\n",
        "  signal_rate = tf.cos(diffusion_times * math.pi / 2)\n",
        "  noise_rates = tf.sin(diffusion_times * math.pi / 2)\n",
        "  return noise_rates , signal_rates\n"
      ],
      "metadata": {
        "id": "WdICNi5jPV_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def offset_cosine_diffusion_schedule(diffusion_times):\n",
        "  min_signal_rate = 0.02\n",
        "  max_signal_rate = 0.95\n",
        "  start_angle = tf.acos(max_signal_rate)\n",
        "  end_angle = tf.acos(min_signal_rate)\n",
        "\n",
        "  diffusion_angles = start_angle + diffusion_times * (end_angle -start_angle)\n",
        "\n",
        "  signal_rates = tf.cos(diffusion_angles)\n",
        "  noise_rates = tf.sin(diffusion_angles)\n",
        "\n",
        "  return noise_rates , signal_rates"
      ],
      "metadata": {
        "id": "x5o9kTFWPnoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Rz6o93uQOyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T = 1000\n",
        "diffusion_times = tf.convert_to_tensor([x /T for x in range(T)])\n",
        "linear_noise_rates , linear_signal_rates = linear_diffusion_schedule(\n",
        "    diffusion_times\n",
        ")\n",
        "cosine_noise_rates , cosine_signal_rates = cosine_diffusion_schedule(\n",
        "    diffusion_times\n",
        ")\n",
        "(\n",
        "    offset_cosine_noise_rates ,\n",
        "    offset_cosine_signal_rates ,\n",
        ") = offset_cosine_diffusion_schedule(diffusion_times)"
      ],
      "metadata": {
        "id": "T0UByzsbQG8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(\n",
        "    diffusion_times , linear_signal_rates ** 2 , linewidth = 1.5, label = \"linear\"\n",
        ")\n",
        "plt.plot(\n",
        "    diffusion_times , cosine_signal_rates ** 2 , linewidth = 1.5, label = \"cosine\"\n",
        ")\n",
        "plt.plot(\n",
        "    diffusion_times ,\n",
        "    offset_cosine_signal_rates ** 2,\n",
        "    linewidth = 1.5,\n",
        "    label = \"offset_cosine\",\n",
        ")\n",
        "\n",
        "plt.xlabel(\"t/T\" , fontsize = 12)\n",
        "plt.ylabel(r\"$\\bar{\\alpha_t}$ (signal)\", fontsize = 12)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j1EhhuBmQrjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(\n",
        "    difffusion_times , linear_noise_rates ** 2, linearwidth = 1.5, label = \"linear\"\n",
        ")\n",
        "plt.plot(\n",
        "    diffusion_times , cosine_noise_rates ** 2, linewidth = 1.5 , label = \"cosine\"\n",
        ")\n",
        "plt.plot(\n",
        "    diffusion_times ,\n",
        "    offset_cosine_noise_rates ** 2,\n",
        "    linewidth = 1.5,\n",
        "    label = \"offset_cosine\",\n",
        ")\n",
        "\n",
        "plt.xlabel(\"t/T\" , fontsize = 12)\n",
        "plt.ylabel(r\"$1 -\\bar{\\alpha_t}$ (noise)\" , fontsize = 12)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4I8QOTyuRSND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Build the model"
      ],
      "metadata": {
        "id": "ADaiCPi4R-39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sinusoidal_embedding(x):\n",
        "  frequencies = tf.exp(\n",
        "      tf.linspace(\n",
        "          tf.math.log(1.0),\n",
        "          tf.math.log(1000, 0),\n",
        "          NOISE_EMBEDDING_SIZE // 2,\n",
        "      )\n",
        "  )\n",
        "  angular_speeds = 2.0 * math.pi * frequencies\n",
        "  embeddings = tf.concat(\n",
        "      [tf.sin(angular_speeds * x) , tf.cos(angular_speeds * x)], axis = 3\n",
        "  )\n",
        "  return embeddings\n"
      ],
      "metadata": {
        "id": "5AGCK93IR9fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_list = []\n",
        "for y in np.arange(0,1,0.01):\n",
        "  embedding_list.append(sinusoidal_embedding(np.array([[[[y]]]]))[0][0][0])\n",
        "embedding_array = np.array(np.transpose(embedding_list))\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_xticks(\n",
        "    np.arange(0, 100 , 10), labels = np.round(np.arange(0.0, 1.0, 0.1), 1)\n",
        ")\n",
        "ax.set_ylabel(\"embedding dimension\" , fontsize = 8)\n",
        "ax.set_xlabel(\"noise variance\" , fontsize = 8)\n",
        "plt.pcolor(embedding_array , cmap= \"coolwarm\")\n",
        "plt.colorbar(orientation = \"horizontal\" , label = \"embedding value\")\n",
        "ax.imshow(embedding_array, inerpolation = \"nearest\" , origin = \"lower\")\n",
        "plt.shoe()\n"
      ],
      "metadata": {
        "id": "fMqbkyHmSkZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResidualBlock(width):\n",
        "  def apply(x):\n",
        "    input_width = x.shape[3]\n",
        "    if input_width == width:\n",
        "      residual = x\n",
        "    else:\n",
        "      residual = layers.Conv2D(width, kernel_size = 1)(x)\n",
        "    x = layers.BatchNormalization(center = False, scale = False)(x)\n",
        "    x = layers.Conv2D(\n",
        "        width , kernel_size = 3, padding = \"same\" , activation = activations.swish\n",
        "    )(x)\n",
        "    x = layers.Conv2D(width , kernel_size = 3 , padding = \"same\")(x)\n",
        "    x = layers.Add()([x, residual])\n",
        "    return x\n",
        "  return apply\n",
        "\n",
        "\n",
        "def DownBlock(width , block_depth):\n",
        "  def apply(x):\n",
        "    x , skips = x\n",
        "    for _ in range(block_depth):\n",
        "      x = ResidualBlock(width)(x)\n",
        "      skips.append(x)\n",
        "    x = layers.AveragePooling2D(pool_size = 2)(x)\n",
        "    return x\n",
        "  return apply\n",
        "\n",
        "def UpBlock(width , block_depth):\n",
        "  def apply(x):\n",
        "    x , skips = x\n",
        "    x = layers.UpSampling2D(size = 2, interpolation = \"bilinear\")(x)\n",
        "    for _ in range(block_depth):\n",
        "      x = layers.Concatenate()([x, skips.pop()])\n",
        "      x = ResidualBlock(width)(x)\n",
        "    return x\n",
        "\n",
        "  return apply\n",
        "\n"
      ],
      "metadata": {
        "id": "hwwcwHqn7skN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build the U- NET\n",
        "\n",
        "noisy_images = layers.Input(shape = (IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "x = layers.Conv2D(32, kernel_size = 1)(noisy_images)\n",
        "\n",
        "noise_varaiance = layers.Input(shape = (1, 1, 1))\n",
        "noise_embedding = layers.Lambda(sinusoidal_embedding)(noise_varaiance)\n",
        "noise_embedding = layers.UpSampling2D(size = IMAGE_SIZE , interpolation = \"nearest\")(\n",
        "    noise_embedding\n",
        ")\n",
        "\n",
        "x = layers.Concatenate()([x, noise_embedding])\n",
        "\n",
        "skips = []\n",
        "\n",
        "x = DownBlock(32, block_depth = 2)([x, skips])\n",
        "x = DownBlock(64, block_depth = 2)([x , skips])\n",
        "x = DownBlock(96, block_depth = 2)([x , skips])\n",
        "\n",
        "x = ResidualBlock(128)(x)\n",
        "x = ResidualBlock(128)(x)\n",
        "\n",
        "x = UpBlock(96, block_depth = 2)([x , skips])\n",
        "x = UpBlock(64, block_depth = 2)([x , skips])\n",
        "x = UpBlock(32, block_depth = 2)([x , skips])\n",
        "\n",
        "x = layers.Conv2D(3, kernel_size = 1, kernel_initializer = \"zeros\")(x)\n",
        "\n",
        "unet = models.Model([noisy_images , noise_varaiance] , x , name=\"unet\")"
      ],
      "metadata": {
        "id": "gupjxNZX8zoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class"
      ],
      "metadata": {
        "id": "JimPg-Lj-2Zc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}