{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN87ymVwtaTP+GkttlAO78p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahtesham519/Genrative_Deep_learning_v2_2023/blob/main/EnergyBasedModels_EBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9SzaxI0qE96",
        "outputId": "13a18fc7-df44-4a2b-e4ca-3352084abcec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import(\n",
        "    datasets,\n",
        "    layers,\n",
        "    models,\n",
        "    optimizers,\n",
        "    activations,\n",
        "    metrics,\n",
        "    callbacks,\n",
        ")\n",
        "\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0. Parameters"
      ],
      "metadata": {
        "id": "389M2zarqg6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 32\n",
        "CHANNELS = 1\n",
        "STEP_SIZE = 10\n",
        "STEPS  = 60\n",
        "NOISE = 0.005\n",
        "ALPHA = 0.1\n",
        "GRADIENT_CLIP = 0.03\n",
        "BATCH_SIZE = 8192\n",
        "LEARNING_RATE = 0.0001\n",
        "EPOCHS = 60\n",
        "LOAD_MODEL = False"
      ],
      "metadata": {
        "id": "DT0Dy52TqfOP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data\n",
        "(x_train, _), (x_test, _) = datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCXFJDIrq3bs",
        "outputId": "358f6687-e20c-4ede-b167-d8f9f012df3f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess the data\n",
        "\n",
        "def preprocess(imgs):\n",
        "  \"\"\"\n",
        "  Normalise and reshape the images\n",
        "  \"\"\"\n",
        "\n",
        "  imgs = (imgs.astype(\"float32\")- 127.5 ) / 127.5\n",
        "  imgs = np.pad(imgs , ((0,0) , (2,2) , (2,2)) , constant_values = -1.0)\n",
        "  imgs = np.expand_dims(imgs, -1)\n",
        "  return imgs\n",
        "\n",
        "\n",
        "x_train = preprocess(x_train)\n",
        "x_test = preprocess(x_test)"
      ],
      "metadata": {
        "id": "YjRCeyt7q_ba"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = tf.data.Dataset.from_tensor_slices(x_train).batch(BATCH_SIZE)\n",
        "x_test = tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "jJHl1EBNrfaw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show some items of clothings from training set\n",
        "train_sample = sample_batch(x_train)\n",
        "display(train_sample)"
      ],
      "metadata": {
        "id": "Bshq18TrruuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Build the EBM network"
      ],
      "metadata": {
        "id": "YGspBqG4rTsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ebm_input = layers.Input(shape = (IMAGE_SIZE , IMAGE_SIZE , CHANNELS))\n",
        "x = layers.Conv2D(\n",
        "    16, kernel_size = 5, strides = 2, padding = \"same\" , activation = activations.swish\n",
        ")(ebm_input)\n",
        "x = layers.Conv2D(\n",
        "    32 , kernel_size = 3, strides = 2, padding = \"same\" , activation = activations.swish\n",
        ")(x)\n",
        "x = layers.Conv2D(\n",
        "    64, kernel_size = 3, strides = 2, padding = \"same\" , activation = activations.swish\n",
        ")(x)\n",
        "x = layers.Conv2D(\n",
        "    64, kernel_size = 3 , strides = 2, padding = \"same\" , activation = activations.swish\n",
        ")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(64, activation = activations.swish)(x)\n",
        "ebm_output = layers.Dense(1)(x)\n",
        "model = models.Model(ebm_input, ebm_output)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "1yo9KIwPrSkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if LOAD_MODEL:\n",
        "  model.load_weights(\"./models/model/h5\")"
      ],
      "metadata": {
        "id": "OftixEhbsRxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Set up a Langevin sampler function"
      ],
      "metadata": {
        "id": "ysMM3YlVsZJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#function to generate samples using Langevin Dynamics\n",
        "def generate_sample(\n",
        "    model , inp_imgs, steps, step_size , noise , return_img_per_step = False):\n",
        "  imgs_per_step = []\n",
        "  for _ in range(steps):\n",
        "    inp_imgs += tf.random.normal(inp_imgs.shape, mean = 0 , stddev = noise )\n",
        "    inp_imgs = tf.clip_by_value(inp_imgs , -1.0 , 1.0)\n",
        "    with tf.GradientTape() as tape:\n",
        "      tape.watch(inp_imgs)\n",
        "      out_score = model(inp_imgs)\n",
        "    grads = tape.gradient(out_score, inp_imgs)\n",
        "    grads = tf.clip_by_value(grads, -GRADIENT_CLIP , GRADIENT_CLIP)\n",
        "    inp_imgs += step_size * grads\n",
        "    inp_imgs = tf.clip_value(inp_imgs , -1.0, 1.0)\n",
        "    if return_img_per_step:\n",
        "      imgs_per_step.append(inp_imgs)\n",
        "  if return_img_per_step:\n",
        "    return tf.stack(imgs_per_step , axis  = 0)\n",
        "  else:\n",
        "    return inp_imgs"
      ],
      "metadata": {
        "id": "--BP_uuPsW39"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set up a buffer to store example"
      ],
      "metadata": {
        "id": "i5xVJdr3twQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Buffer:\n",
        "  def __init__(self, model):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "    self.examples = [\n",
        "        tf.random.uniform(shape =(1, IMAGE_SIZE , IMAGE_SIZE , CHANNELS)) * 2\n",
        "        -1\n",
        "        for _ in range(BATCH_SIZE)\n",
        "    ]\n",
        "\n",
        "  def sample_new_exmps(self, steps, step_size , noise):\n",
        "    n_new = np.random.binomial(BATCH_SIZE, 0.05)\n",
        "    rand_imgs =  (\n",
        "        tf.random.uniform((n_new , IMAGE_SIZE , IMAGE_SIZE , CHANNELS)) * 2 - 1\n",
        "    )\n",
        "    old_imgs = tf.concat(\n",
        "        random.choices(self.examples, k = BATCH_SIZE - n_new) , axis = 0\n",
        "    )\n",
        "    inp_imgs = tf.concat([rand_imgs , old_imgs , axis = 0])\n",
        "    inp_imgs = generate_samples(\n",
        "        self.model, inp_imgs , steps = steps , step_size = step_size , noise = noise\n",
        "    )\n",
        "    self.examples = tf.split(inp_imgs , BATCH_SIZE , axis = 0) + self.examples\n",
        "    self.examples = self.examples[:BUFFER_SIZE]\n",
        "    return inp_imgs\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "F25T7DCbtrcG",
        "outputId": "f9d29f9b-de75-48c5-b91b-579ed330041c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-919dc2ecb360>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    inp_imgs = tf.concat([rand_imgs , old_imgs , axis = 0])\u001b[0m\n\u001b[0m                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Maybe you meant '==' or ':=' instead of '='?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EBM(models.Model):\n",
        "  def __init__(self):\n",
        "    super(EBM, self).__init__()\n",
        "    self.model = model\n",
        "    self.buffer = Buffer(self.model)\n",
        "    self.alpha = ALPHA\n",
        "    self.loss_metric = metrics.Mean(name = \"loss\")\n",
        "    self.reg_loss_metric = metrics.Mean(name = \"reg\")\n",
        "    self.cdiv_loss_metric = metrics.Mean(name = \"cdiv\")\n",
        "    self.real_out_metric = metrics.Mean(name = \"real\")\n",
        "    self.fake_out_metric = metrics.Mean(name = \"fake\")\n",
        "\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return[\n",
        "        self.loss_metric,\n",
        "        self.reg_loss_metric,\n",
        "        self.cdiv_loss_metric,\n",
        "        self.real_out_metric,\n",
        "        self.fake_out_metric,\n",
        "    ]\n",
        "\n",
        "  def train_step(self, real_imgs):\n",
        "    real_imgs += tf.random.noraml(\n",
        "        shape = tf.shape(real_imgs), mean = 0  ,stddev = NOISE\n",
        "    )\n",
        "    real_imgs = tf.clip_by_value(real_imgs , -1.0 , 1.0)\n",
        "    fake_imgs = self.buffer.sample_new_exmps(\n",
        "        steps = STEPS, step_size = STEP_SIZE , noise = NOISE\n",
        "    )\n",
        "    inp_imgs = tf.concat([real_imgs , fake_imgs , axis = 0])\n",
        "    with tf.GradientTape() as training_tape:\n",
        "      real_out , fake_out = tf.split(self.model(inp_imgs) , 2 , axis = 0)\n",
        "      cdiv_loss = tf.reduce_mean(fake_out , axis = 0) - tf.reduce_mean(\n",
        "          real_out , axis = 0\n",
        "      )\n",
        "      reg_loss = self.alpha * tf.reduce_mean(\n",
        "          real_out ** 2 + fake_out**2  , axis = 0\n",
        "      )\n",
        "      loss = cdiv_loss + reg_loss\n",
        "    grads = training_tape.gradient(loss , self.model.trainable_variables)\n",
        "    self.optimizer.apply_gradients(\n",
        "        zip(grads , self.model.trainable_variables)\n",
        "    )\n",
        "    self.loss_metric.update_state(loss)\n",
        "    self.reg_loss_metric.update_state(reg_loss)\n",
        "    self.cdiv_loss_metric.update_state(cdiv_loss)\n",
        "    self.real_out_metric.update_state(tf.reduce_mean(real_out, axis = 0))\n",
        "    self.fake_out_metric.update_state(tf.reduce_mean(fake_out , axis = 0))\n",
        "    return {m.name: m.result() for m in self.metrics}\n",
        "    S"
      ],
      "metadata": {
        "id": "uB2REXZdvCX0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}