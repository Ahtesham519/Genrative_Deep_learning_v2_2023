{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNg+CEpSpboU83ODfqnZy0A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahtesham519/Genrative_Deep_learning_v2_2023/blob/main/EnergyBasedModels_EBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9SzaxI0qE96"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import(\n",
        "    datasets,\n",
        "    layers,\n",
        "    models,\n",
        "    optimizers,\n",
        "    activations,\n",
        "    metrics,\n",
        "    callbacks,\n",
        ")\n",
        "\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0. Parameters"
      ],
      "metadata": {
        "id": "389M2zarqg6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 32\n",
        "CHANNELS = 1\n",
        "STEP_SIZE = 10\n",
        "STEPS  = 60\n",
        "NOISE = 0.005\n",
        "ALPHA = 0.1\n",
        "GRADIENT_CLIP = 0.03\n",
        "BATCH_SIZE = 8192\n",
        "LEARNING_RATE = 0.0001\n",
        "EPOCHS = 60\n",
        "LOAD_MODEL = False"
      ],
      "metadata": {
        "id": "DT0Dy52TqfOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data\n",
        "(x_train, _), (x_test, _) = datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "DCXFJDIrq3bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess the data\n",
        "\n",
        "def preprocess(imgs):\n",
        "  \"\"\"\n",
        "  Normalise and reshape the images\n",
        "  \"\"\"\n",
        "\n",
        "  imgs = (imgs.astype(\"float32\")- 127.5 ) / 127.5\n",
        "  imgs = np.pad(imgs , ((0,0) , (2,2) , (2,2)) , constant_values = -1.0)\n",
        "  imgs = np.expand_dims(imgs, -1)\n",
        "  return imgs\n",
        "\n",
        "\n",
        "x_train = preprocess(x_train)\n",
        "x_test = preprocess(x_test)"
      ],
      "metadata": {
        "id": "YjRCeyt7q_ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = tf.data.Dataset.from_tensor_slices(x_train).batch(BATCH_SIZE)\n",
        "x_test = tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "jJHl1EBNrfaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show some items of clothings from training set\n",
        "train_sample = sample_batch(x_train)\n",
        "display(train_sample)"
      ],
      "metadata": {
        "id": "Bshq18TrruuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Build the EBM network"
      ],
      "metadata": {
        "id": "YGspBqG4rTsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ebm_input = layers.Input(shape = (IMAGE_SIZE , IMAGE_SIZE , CHANNELS))\n",
        "x = layers.Conv2D(\n",
        "    16, kernel_size = 5, strides = 2, padding = \"same\" , activation = activations.swish\n",
        ")(ebm_input)\n",
        "x = layers.Conv2D(\n",
        "    32 , kernel_size = 3, strides = 2, padding = \"same\" , activation = activations.swish\n",
        ")(x)\n",
        "x = layers.Conv2D(\n",
        "    64, kernel_size = 3, strides = 2, padding = \"same\" , activation = activations.swish\n",
        ")(x)\n",
        "x = layers.Conv2D(\n",
        "    64, kernel_size = 3 , strides = 2, padding = \"same\" , activation = activations.swish\n",
        ")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(64, activation = activations.swish)(x)\n",
        "ebm_output = layers.Dense(1)(x)\n",
        "model = models.Model(ebm_input, ebm_output)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "1yo9KIwPrSkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if LOAD_MODEL:\n",
        "  model.load_weights(\"./models/model/h5\")"
      ],
      "metadata": {
        "id": "OftixEhbsRxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Set up a Langevin sampler function"
      ],
      "metadata": {
        "id": "ysMM3YlVsZJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#function to generate samples using Langevin Dynamics\n",
        "def generate_sample(\n",
        "    model , inp_imgs, steps, step_size , noise , return_img_per_step = False):\n",
        "  imgs_per_step = []\n",
        "  for _ in range(steps):\n",
        "    inp_imgs += tf.random.normal(inp_imgs.shape, mean = 0 , stddev = noise )\n",
        "    inp_imgs = tf.clip_by_value(inp_imgs , -1.0 , 1.0)\n",
        "    with tf.GradientTape() as tape:\n",
        "      tape.watch(inp_imgs)\n",
        "      out_score = model(inp_imgs)\n",
        "    grads = tape.gradient(out_score, inp_imgs)\n",
        "    grads = tf.clip_by_value(grads, -GRADIENT_CLIP , GRADIENT_CLIP)\n",
        "    inp_imgs += step_size * grads\n",
        "    inp_imgs = tf.clip_value(inp_imgs , -1.0, 1.0)\n",
        "    if return_img_per_step:\n",
        "      imgs_per_step.append(inp_imgs)\n",
        "  if return_img_per_step:\n",
        "    return tf.stack(imgs_per_step , axis  = 0)\n",
        "  else:\n",
        "    return inp_imgs"
      ],
      "metadata": {
        "id": "--BP_uuPsW39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set up a buffer to store example"
      ],
      "metadata": {
        "id": "i5xVJdr3twQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Buffer:\n",
        "  def __init__(self, model):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "    self.examples = [\n",
        "        tf.random.uniform(shape =(1, IMAGE_SIZE , IMAGE_SIZE , CHANNELS)) * 2\n",
        "        -1\n",
        "        for _ in range(BATCH_SIZE)\n",
        "    ]\n",
        "\n",
        "  def sample_new_exmps(self, steps, step_size , noise):\n",
        "    n_new = np.random.binomial(BATCH_SIZE, 0.05)\n",
        "    rand_imgs =  (\n",
        "        tf.random.uniform((n_new , IMAGE_SIZE , IMAGE_SIZE , CHANNELS)) * 2 - 1\n",
        "    )\n",
        "    old_imgs = tf.concat(\n",
        "        random.choices(self.examples, k = BATCH_SIZE - n_new) , axis = 0\n",
        "    )\n",
        "    inp_imgs = tf.concat([rand_imgs , old_imgs , axis = 0])\n",
        "    inp_imgs = generate_samples(\n",
        "        self.model, inp_imgs , steps = steps , step_size = step_size , noise = noise\n",
        "    )\n",
        "    self.examples = tf.split(inp_imgs , BATCH_SIZE , axis = 0) + self.examples\n",
        "    self.examples = self.examples[:BUFFER_SIZE]\n",
        "    return inp_imgs\n",
        ""
      ],
      "metadata": {
        "id": "F25T7DCbtrcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EBM(models.Model):\n",
        "  def __init__(self):\n",
        "    super(EBM, self).__init__()\n",
        "    self.model = model\n",
        "    self.buffer = Buffer(self.model)\n",
        "    self.alpha = ALPHA\n",
        "    self.loss_metric = metrics.Mean(name = \"loss\")\n",
        "    self.reg_loss_metric = metrics.Mean(name = \"reg\")\n",
        "    self.cdiv_loss_metric = metrics.Mean(name = \"cdiv\")\n",
        "    self.real_out_metric = metrics.Mean(name = \"real\")\n",
        "    self.fake_out_metric = metrics.Mean(name = \"fake\")\n",
        "\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return[\n",
        "        self.loss_metric,\n",
        "        self.reg_loss_metric,\n",
        "        self.cdiv_loss_metric,\n",
        "        self.real_out_metric,\n",
        "        self.fake_out_metric,\n",
        "    ]\n",
        "\n",
        "  def train_step(self, real_imgs):\n",
        "    real_imgs += tf.random.noraml(\n",
        "        shape = tf.shape(real_imgs), mean = 0  ,stddev = NOISE\n",
        "    )\n",
        "    real_imgs = tf.clip_by_value(real_imgs , -1.0 , 1.0)\n",
        "    fake_imgs = self.buffer.sample_new_exmps(\n",
        "        steps = STEPS, step_size = STEP_SIZE , noise = NOISE\n",
        "    )\n",
        "    inp_imgs = tf.concat([real_imgs , fake_imgs , axis = 0])\n",
        "    with tf.GradientTape() as training_tape:\n",
        "      real_out , fake_out = tf.split(self.model(inp_imgs) , 2 , axis = 0)\n",
        "      cdiv_loss = tf.reduce_mean(fake_out , axis = 0) - tf.reduce_mean(\n",
        "          real_out , axis = 0\n",
        "      )\n",
        "      reg_loss = self.alpha * tf.reduce_mean(\n",
        "          real_out ** 2 + fake_out**2  , axis = 0\n",
        "      )\n",
        "      loss = cdiv_loss + reg_loss\n",
        "    grads = training_tape.gradient(loss , self.model.trainable_variables)\n",
        "    self.optimizer.apply_gradients(\n",
        "        zip(grads , self.model.trainable_variables)\n",
        "    )\n",
        "    self.loss_metric.update_state(loss)\n",
        "    self.reg_loss_metric.update_state(reg_loss)\n",
        "    self.cdiv_loss_metric.update_state(cdiv_loss)\n",
        "    self.real_out_metric.update_state(tf.reduce_mean(real_out, axis = 0))\n",
        "    self.fake_out_metric.update_state(tf.reduce_mean(fake_out , axis = 0))\n",
        "    return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "  def test_step(self, real_imgs):\n",
        "    batch_size = real_imgs.shape[0]\n",
        "    fake_imgs = (\n",
        "        tf.random.uniform((batch_size, IMAGE_SIZE, IMAGE_SIZE, CHANNELS))\n",
        "        * 2\n",
        "        - 1\n",
        "    )\n",
        "    inp_imgs = tf.concat([real_imgs, fake_imgs], axis = 0)\n",
        "    real_out , fake_out = tf.split(self.model(inp_imgs), 2, axis = 0)\n",
        "    cdiv = tf.reduce_mean(fake_out , axis = 0) - tf.reduce_mean(\n",
        "        real_out , axis = 0\n",
        "    )\n",
        "    self.cdiv_loss_metirc.update_state(cdiv)\n",
        "    self.real_out_metric.update_state(tf.reduce_mean(real_out, axis = 0))\n",
        "    self.fake_out_metric.update_state(tf.reduce_mean(fake_out, axis = 0))\n",
        "    return {m.name : m.result() for m in self.metrics[2:]}\n",
        ""
      ],
      "metadata": {
        "id": "uB2REXZdvCX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ebm = EBM()"
      ],
      "metadata": {
        "id": "4ErPIUzz9qeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train the EBM network"
      ],
      "metadata": {
        "id": "BwNhP6qf9uu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#compile and train the model\n",
        "ebm.compile(\n",
        "    optimizer = optimizers.Adam(learning_rate = LEARNING_RATE) , run_eagerly =True\n",
        ")"
      ],
      "metadata": {
        "id": "o037Ip-O9sMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard_callback = callbacks.Tensorboard(log_dir = \"./logs\")\n",
        "\n",
        "class ImageGenerator(callbacks.Callback):\n",
        "  def __init__(self, num_img):\n",
        "    self.num_img = num_img\n",
        "\n",
        "  def on_epoch_end(self, epoch , logs = None):\n",
        "    start_imgs = (\n",
        "        np.random.uniform(\n",
        "            size = (self.num_img , IMAGE_SIZE , IMAGE_SIZE , CHANNELS)\n",
        "        )\n",
        "        * 2\n",
        "        - 1\n",
        "    )\n",
        "    generated_images = generate_sample(\n",
        "        ebm.model,\n",
        "        start_imgs,\n",
        "        steps = 1000,\n",
        "        step_size = STEP_SIZE ,\n",
        "        noise = NOISE ,\n",
        "        return_img_per_step = False,\n",
        "    )\n",
        "    generated_images = generated_images.numpy()\n",
        "    display(\n",
        "        generated_images,\n",
        "        save_to = \"./output/generated_img_%03d.png\" %(epoch),\n",
        "    )\n",
        "\n",
        "    example_images = tf.concat(\n",
        "        random.choices(ebm.buffer.examples, k = 10) , axis = 0\n",
        "    )\n",
        "    example_images = example_images.numpy()\n",
        "    display(\n",
        "        example_images , save_to = \"./output/example_img_%03d.png\" % (epoch)\n",
        "    )\n",
        "\n",
        "image_generator_callback = ImageGenerator(num_img = 10)\n"
      ],
      "metadata": {
        "id": "gmt45zqH98Rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SaveModel(callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch , logs = None):\n",
        "    model.save_weights(\"./models/model.h5\")\n",
        "\n",
        "\n",
        "save_model_callback = SaveModel()"
      ],
      "metadata": {
        "id": "slQkFMRr_TrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ebm.fit(\n",
        "    x_train,\n",
        "    shuffle = True,\n",
        "    epochs = 60 ,\n",
        "    validation_data = x_test,\n",
        "    callbacks = [\n",
        "        save_model_callback,\n",
        "        tensorboard_callback,\n",
        "        image_generator_callback,\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "2zimEHIv_lc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.Generate images"
      ],
      "metadata": {
        "id": "rvtLuYrK__5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_imgs = (\n",
        "    np.random.uniform(size = (10 , IMAGE_SIZE , IMAGE_SIZE , CHANNELS) * 2 -1)\n",
        ")"
      ],
      "metadata": {
        "id": "UEF7i1uC_3iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(start_imgs)"
      ],
      "metadata": {
        "id": "Eh94jFoQAMs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_img = generate_samples(\n",
        "    ebm.model,\n",
        "    start_imgs ,\n",
        "    steps = 1000,\n",
        "    step_size = STEP_SIZE ,\n",
        "    noise = NOISE ,\n",
        "    return_img_per_step = True,\n",
        ")"
      ],
      "metadata": {
        "id": "Ut2hCORuAOcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(gen_img[-1].numpy())"
      ],
      "metadata": {
        "id": "bU7jJn3BAaXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs = []\n",
        "for i in [0,1,3,5,10,30,50,100,300,999]:\n",
        "  imgs.append(gen_img[i].numpy()[6])\n",
        "\n",
        "display(np.array(imgs))"
      ],
      "metadata": {
        "id": "FpSaoRcvAeze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rnHbJAa7Aqp2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}