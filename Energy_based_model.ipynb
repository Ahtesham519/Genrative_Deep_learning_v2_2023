{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPV8CguCTFm7jS3p4JzE11V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahtesham519/Genrative_Deep_learning_v2_2023/blob/main/Energy_based_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import (\n",
        "    layers,\n",
        "    models,\n",
        "    regularizers,\n",
        "    metrics,\n",
        "    optimizers,\n",
        "    callbacks,\n",
        ")\n",
        "\n",
        "import tensorflow_probability as tfp"
      ],
      "metadata": {
        "id": "mAT3rVJwbXun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0.Parameters"
      ],
      "metadata": {
        "id": "hLNxoVvsbxSE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJRNQ9ahbINq"
      },
      "outputs": [],
      "source": [
        "COUPLING_DIM = 256\n",
        "COUPLING_LAYERS = 2\n",
        "INPUT_DIM = 2\n",
        "REGULARIZATION = 0.01\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 300\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load the data\n",
        "data = datasets.make_moons(30000, noise = 0.05)[0].astype(\"float32\")\n",
        "norm = layers.Normalization()\n",
        "norm.adapt(data)\n",
        "normalized_data = norm(data)\n",
        "plt.scatter(\n",
        "    normalized_data.numpy()[:, 0] , normalized_data.numpy()[:, 1], c = \"green\"\n",
        ")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M1XQX9Jsb82R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Build the RealNVP network"
      ],
      "metadata": {
        "id": "kSTiNwG5cV9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Coupling(input_dim, coupling_dim, reg):\n",
        "  input_layer = layers.Input(shape = input_dim)\n",
        "\n",
        "  s_layer_1 = layers.Dense(\n",
        "      coupling_dim , activation = \"relu\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(input_layer)\n",
        "  s_layer_2 = layers.Dense(\n",
        "      coupling_dim , activation = \"relu\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(s_layer_1)\n",
        "  s_layer_3 = layers.Dense(\n",
        "      coupling_dim , activation = \"relu\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(s_layer_2)\n",
        "  s_layer_4 = layers.Dense(\n",
        "      coupling_dim , activation = \"relu\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(s_layer_3)\n",
        "  s_layer_5 = layers.Dense(\n",
        "      input_dim , activation = \"tanh\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(s_layer_4)\n",
        "\n",
        "  t_layer_1 = layers.Dense(\n",
        "      coupling_dim , activation = \"relu\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(input_layer)\n",
        "  t_layer_2 = layers.Dense(\n",
        "      coupling_dim , acitvation = \"relu\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(t_layer_1)\n",
        "  t_layer_3 = layers.Dense(\n",
        "      coupling_dim , activation = \"relu\" ,kernel_regularizer = regularizers.l2(reg)\n",
        "  )(t_layer_2)\n",
        "  t_layer_4 = layers.Dense(\n",
        "      coupling_dim , activation = \"relu\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(t_layer_3)\n",
        "  t_layer_5 = layers.Dense(\n",
        "      input_dim , activation = \"linear\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(t_layer_4)\n",
        "\n",
        "  return models.Model(inputs = input_layer , outputs = [s_layer_5 , t_layer_5])"
      ],
      "metadata": {
        "id": "hjLoxfAccVGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RealNVP(models.Model):\n",
        "  def __init__(\n",
        "      self, input_dim , coupling_layers, coupling_dim , regularization\n",
        "  ):\n",
        "      super(RealNVP, self).__init__()\n",
        "      self.coupling_layers = coupling_layers\n",
        "      self.distributtion = tfp.distributions.MultivariateNormalDiag(\n",
        "          loc = [0.0 , 0.0] , scale_diag = [ 1.0 , 1.0]\n",
        "      )\n",
        "      self.masks = np.array(\n",
        "          [[0,1] , [1,0] * (coupling_layers // 2) , dtype = \"float32\"]\n",
        "      )\n",
        "      self.loss_tracker = metrics.Mean(name = \"loss\")\n",
        "      self.layers.list = [\n",
        "          Coupling(input_dim , coupling_dim , regularization)\n",
        "          for i in range(coupling_layers)\n",
        "      ]\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return[self.loss_tracker]\n",
        "\n",
        "  def call(self, x, training = True):\n",
        "    log_det_inv = 0\n",
        "    direction = 1\n",
        "    if training :\n",
        "      direction = -1\n",
        "    for i in range(self.coupling_layers)[::direction]:\n",
        "      x_masked = x * self.masks[i]\n",
        "      reversed_mask = 1 - self.masks[i]\n",
        "      s, t = self.layers_list[i](x_masked)\n",
        "      s *= reversed_mask\n",
        "      t *= reversed_mask\n",
        "      gate = (direction - 1) / 2\n",
        "      x = (\n",
        "          reversed_mask\n",
        "          * ( x * tf.exp(direction * s) + direction * t * tf.exp(gate * s))\n",
        "          + x_masked\n",
        "      )\n",
        "      log_det_inv += gate * tf.reduce_sum(s, axis = 1)\n",
        "    return x , log_det_inv\n",
        "\n",
        "  def log_loss(self, x):\n",
        "    y , logdet = self(x)\n",
        "    log_likelihood = self.distribution.log_prob(y) + logdet\n",
        "    return -tf.reduce_mean(log_likelihood)\n",
        "\n",
        "  def train_step(self, data):\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss = self.log_loss(data)\n",
        "    g = tape.gradient(loss , self.trainable_variables)\n",
        "    self.optimizer.apply_gradients(zip(g, self.trainable_variables))\n",
        "    self.loss_tracker.update_state(loss)\n",
        "    return { \"loss\" : self.loss_tracker.result()}\n",
        "\n",
        "  def test_step(self, data):\n",
        "    loss = self.log_loss(data)\n",
        "    self.loss_tracker.update_state(loss)\n",
        "    return {\"loss\": self.loss_tracker.result()}\n",
        "\n",
        "model = RealNVP(\n",
        "    input_dim = INPUT_DIM,\n",
        "    coupling_layers = COUPLING_LAYERS,\n",
        "    coupling_dim = COUPLING_DIM ,\n",
        "    regularization = REGULARIZATION,\n",
        ")"
      ],
      "metadata": {
        "id": "q3zZijdneymz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3 Train the RealNVP network"
      ],
      "metadata": {
        "id": "VlF9JTWWFEJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#compile and train the model\n",
        "model.compile(optimizer = optimizers.Adam(learning_rate = 0.0001))"
      ],
      "metadata": {
        "id": "FO2rYgENFCt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboad_callback = callbacks.TensorBoard(log_dir = \"./logs\")\n",
        "\n",
        "class ImageGenerator(callbacks.Callback):\n",
        "  def __init__(self, num_samples):\n",
        "    self.num_samples = num_samples\n",
        "\n",
        "  def generate(self):\n",
        "    #From data to latent space\n",
        "    z, _ = model(normalized_data)\n",
        "\n",
        "    #From latent space to data\n",
        "    samples = model.distribution.sample(self.num_samples)\n",
        "    x, _ = model.predict(samples, verbose = 0)\n",
        "\n",
        "    return x, z , samples\n",
        "\n",
        "  def display(self, x , z, samples , save_to = None):\n",
        "    f , axes  = plt.subplots(2,2)\n",
        "    f.set_size_inches(8,5)\n",
        "\n",
        "    axes[0,0].scatter(\n",
        "        normalized_data[: , 0], normalized_data[:, 1] , color = \"r\" , s = 1\n",
        "    )\n",
        "    axes[0,0].set(title=\"Data space X\" , xlabel = x_1, ylabel = \"x_2\")\n",
        "    axes[0,0].set_xlim([-2, 2])\n",
        "    axes[0,0].set_ylim([-2, 2])\n",
        "    axes[0,1].scatter(z[:, 0] , z[:,1] , color = \"r\" , s = 1)\n",
        "    axes[0,1].set(title=\"f(X)\" , xlabel = \"z_1\" , ylabel = \"z_2\")\n",
        "    axes[0,1].set_xlim([-2, 2])\n",
        "    axes[0,1].set_ylim([-2,2])\n",
        "    axes[1,0].scatter(samples[:,0] , samples[:, 1] , color = \"g\", s = 1)\n",
        "    axes[1,0].set(title=\"Latent space Z\" , xlabel=\"z_1\" , ylabel= \"z_2\")\n",
        "    axes[1,0].set_xlim([-2, 2])\n",
        "    axes[1,0].set_ylim([-2, 2])\n",
        "    axes[1,1].scatter(x[:, 0] , x[: , 1] , color = \"g\" , s = 1)\n",
        "    axes[1,1].set(title = \"g(Z)\", xlabel = \"x_1\", ylabel = \"x_2\")\n",
        "    axes[1,1].set_xlim([-2, 2])\n",
        "    axes[1,1].set_ylim([-2,2])\n",
        "\n",
        "    plt.subplots_adjust(wspace = 0.3 , hspace = 0.6)\n",
        "    if save_to:\n",
        "      plt.savefig(save_to)\n",
        "      print(f\"\\nSaved to {save_to}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs = None):\n",
        "    if epoch % 10 == 0:\n",
        "      x, z,samples = self.generate()\n",
        "      self.display(\n",
        "          x,\n",
        "          z,\n",
        "          samples,\n",
        "          save_to = \"./output/generated_img_%03d.png\" % (epoch),\n",
        "      )\n",
        "\n",
        "img_generator_callback = ImageGenerator(num_samples = 3000)"
      ],
      "metadata": {
        "id": "4UEem7F4FTkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    normalized_data,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    epochs = EPOCHS,\n",
        "    callbacks = [tensorboard_callback, img_generator_callback],\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "MbSpdGEKIQRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Generate images"
      ],
      "metadata": {
        "id": "hPz6K2HjIqjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x,z,samples = img_generator_callback.generate()"
      ],
      "metadata": {
        "id": "i5N9JSV1IoF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_generator_callback.display(x,z,samples)"
      ],
      "metadata": {
        "id": "7nITMMF_Iwhn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}