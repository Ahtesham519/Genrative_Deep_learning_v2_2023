{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRuYoENWUANE/qDpA44NJu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahtesham519/Genrative_Deep_learning_v2_2023/blob/main/Energy_based_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import (\n",
        "    layers,\n",
        "    models,\n",
        "    regularizers,\n",
        "    metrics,\n",
        "    optimizers,\n",
        "    callbacks,\n",
        ")\n",
        "\n",
        "import tensorflow_probability as tfp"
      ],
      "metadata": {
        "id": "mAT3rVJwbXun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0.Parameters"
      ],
      "metadata": {
        "id": "hLNxoVvsbxSE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJRNQ9ahbINq"
      },
      "outputs": [],
      "source": [
        "COUPLING_DIM = 256\n",
        "COUPLING_LAYERS = 2\n",
        "INPUT_DIM = 2\n",
        "REGULARIZATION = 0.01\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 300\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load the data\n",
        "data = datasets.make_moons(30000, noise = 0.05)[0].astype(\"float32\")\n",
        "norm = layers.Normalization()\n",
        "norm.adapt(data)\n",
        "normalized_data = norm(data)\n",
        "plt.scatter(\n",
        "    normalized_data.numpy()[:, 0] , normalized_data.numpy()[:, 1], c = \"green\"\n",
        ")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M1XQX9Jsb82R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Build the RealNVP network"
      ],
      "metadata": {
        "id": "kSTiNwG5cV9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Coupling(input_dim, coupling_dim, reg):\n",
        "  input_layer = layers.Input(shape = input_dim)\n",
        "\n",
        "  s_layer_1 = layers.Dense(\n",
        "      coupling_dim , activation = \"relu\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(input_layer)\n",
        "  s_layer_2 = layers.Dense(\n",
        "      coupling_dim , activation = \"relu\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(s_layer_1)\n",
        "  s_layer_3 = layers.Dense(\n",
        "      coupling_dim , activation = \"relu\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(s_layer_2)\n",
        "  s_layer_4 = layers.Dense(\n",
        "      coupling_dim , activation = \"relu\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(s_layer_3)\n",
        "  s_layer_5 = layers.Dense(\n",
        "      input_dim , activation = \"tanh\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(s_layer_4)\n",
        "\n",
        "  t_layer_1 = layers.Dense(\n",
        "      coupling_dim , activation = \"relu\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(input_layer)\n",
        "  t_layer_2 = layers.Dense(\n",
        "      coupling_dim , acitvation = \"relu\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(t_layer_1)\n",
        "  t_layer_3 = layers.Dense(\n",
        "      coupling_dim , activation = \"relu\" ,kernel_regularizer = regularizers.l2(reg)\n",
        "  )(t_layer_2)\n",
        "  t_layer_4 = layers.Dense(\n",
        "      coupling_dim , activation = \"relu\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(t_layer_3)\n",
        "  t_layer_5 = layers.Dense(\n",
        "      input_dim , activation = \"linear\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(t_layer_4)\n",
        "\n",
        "  return models.Model(inputs = input_layer , outputs = [s_layer_5 , t_layer_5])"
      ],
      "metadata": {
        "id": "hjLoxfAccVGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RealNVP(models.Model):\n",
        "  def __init__(\n",
        "      self, input_dim , coupling_layers, coupling_dim , regularization\n",
        "  ):\n",
        "      super(RealNVP, self).__init__()\n",
        "      self.coupling_layers = coupling_layers\n",
        "      self.distributtion = tfp.distributions.MultivariateNormalDiag(\n",
        "          loc = [0.0 , 0.0] , scale_diag = [ 1.0 , 1.0]\n",
        "      )\n",
        "      self.masks = np.array(\n",
        "          [[0,1] , [1,0] * (coupling_layers // 2) , dtype = \"float32\"]\n",
        "      )\n",
        "      self.loss_tracker = metrics.Mean(name = \"loss\")\n",
        "      self.layers.list = [\n",
        "          Coupling(input_dim , coupling_dim , regularization)\n",
        "          for i in range(coupling_layers)\n",
        "      ]\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return[self.loss_tracker]\n",
        "\n",
        "  def call(self, x, training = True):\n",
        "    log_det_inv = 0\n",
        "    direction = 1\n",
        "    if training :\n",
        "      direction = -1\n",
        "    for i in range(self.coupling_layers)[::direction]:\n",
        "      x_masked = x * self.masks[i]\n",
        "      reversed_mask = 1 - self.masks[i]\n",
        "      s, t = self.layers_list[i](x_masked)\n",
        "      s *= reversed_mask\n",
        "      t *= reversed_mask\n",
        "      gate = (direction - 1) / 2\n",
        "      x = (\n",
        "          reversed_mask\n",
        "          * ( x * tf.exp(direction * s) + direction * t * tf.exp(gate * s))\n",
        "          + x_masked\n",
        "      )\n",
        "      log_det_inv += gate * tf.reduce_sum(s, axis = 1)\n",
        "    return x , log_det_inv\n",
        "\n",
        "  def log_loss(self, x):\n",
        "    y , logdet = self(x)\n",
        "    log_likelihood = self.distribution.log_prob(y) + logdet\n",
        "    return -tf.reduce_mean(log_likelihood)\n",
        "\n",
        "  def train_step(self, data):\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss = self.log_loss(data)\n",
        "    g = tape.gradient(loss , self.trainable_variables)\n",
        "    self.optimizer.apply_gradients(zip(g, self.trainable_variables))\n",
        "    self.loss_tracker.update_state(loss)\n",
        "    return { \"loss\" : self.loss_tracker.result()}\n",
        "\n",
        "  def test_step(self, data):\n",
        "    loss = self.log_loss(data)\n",
        "    self.loss_tracker.update_state(loss)\n",
        "    return {\"loss\": self.loss_tracker.result()}\n",
        "\n",
        "model = RealNVP(\n",
        "    input_dim = INPUT_DIM,\n",
        "    coupling_layers = COUPLING_LAYERS,\n",
        "    coupling_dim = COUPLING_DIM ,\n",
        "    regularization = REGULARIZATION,\n",
        ")"
      ],
      "metadata": {
        "id": "q3zZijdneymz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}