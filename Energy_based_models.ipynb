{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOm8uZ4f7yzl/tpktRqN5ss",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahtesham519/Genrative_Deep_learning_v2_2023/blob/main/Energy_based_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import (\n",
        "    datasets,\n",
        "    layers,\n",
        "    models,\n",
        "    optimizers,\n",
        "    activations,\n",
        "    metrics,\n",
        "    callbacks\n",
        ")\n",
        "\n",
        "from notebooks.utils import display , sample_batch\n",
        "import random\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "wIE3uI3Ew7nG",
        "outputId": "345fb49e-c89d-4eee-d375-f28e40495a53"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'notebooks'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-7a655c8001e7>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnotebooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msample_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'notebooks'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0. Parameters"
      ],
      "metadata": {
        "id": "R3DM5FzExSn5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ggHM517Mw3Iy"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 32\n",
        "CHANNELS = 1\n",
        "STEP_SIZE = 60\n",
        "STEPS = 60\n",
        "NOISE = 0.005\n",
        "ALPHA = 0.1\n",
        "GRADIENT_CLIP = 0.03\n",
        "BATCH_SIZE = 128\n",
        "BUFFER_SIZE = 8192\n",
        "LEARNING_RATE = 0.0001\n",
        "EPOCHS = 60\n",
        "LOAD_MODEL = False\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load the data\n",
        "(x_train , _) , (x_test, _) = datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez1a4gIHxsww",
        "outputId": "331e2069-9b0e-4613-9ede-aa832d564011"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess the data\n",
        "\n",
        "def preprocess(imgs):\n",
        "  \"\"\"\n",
        "  Normalize and reshape the images\n",
        "  \"\"\"\n",
        "  imgs = (imgs.astype(\"float32\") - 127.5) / 127.5\n",
        "  imgs = np.pad(imgs, ((0,0) , (2,2)  , (2,2)), contant_values = -1.0)\n",
        "  imgs = np.expand_dims(imgs , -1)\n",
        "  return imgs\n",
        "\n",
        "  x_train = preprocess(x_train)\n",
        "  x_test = preprocess(x_test)"
      ],
      "metadata": {
        "id": "HZJV6wh0xy3o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = tf.data.Dataset.from_tensor_slices(x_train).batch(BATCH_SIZE)\n",
        "x_test = tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "zimZJ0QIySft"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show some items of clothings from the training set\n",
        "\n",
        "train_sample = sample_batch(x_train)\n",
        "display(train_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "ZNjyH_w1yjQ7",
        "outputId": "b9283d60-98a6-4f45-f7f7-a6a7b2a59f71"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'sample_batch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-44e73c3de8d0>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Show some items of clothings from the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sample_batch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Bulid the EBM network"
      ],
      "metadata": {
        "id": "rcvumviuyyk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ebm_input = layers.Input(shape = (IMAGE_SIZE , IMAGE_SIZE , CHANNELS))\n",
        "x = layers.Conv2D(\n",
        "    16, kernel_size = 5, strides = 2, padding = \"same\" , activation = activations.swish\n",
        "    )(ebm_input)\n",
        "x = layers.Conv2D(\n",
        "    32, kernel_size = 3, strides = 2, padding = \"same\", activation = activations.swish\n",
        ")(x)\n",
        "x = layers.Conv2D(\n",
        "    64, kernel_size = 3, strides = 2, padding = \"same\" , activation = activations.swish\n",
        ")(x)\n",
        "x = layers.Conv2D(\n",
        "    64, kernel_size = 3, strides = 2, padding = \"same\", activation = activations.swish\n",
        ")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(64, activation = activations.swish)(x)\n",
        "ebm_output = layers.Dense(1)(x)\n",
        "model = models.Model(ebm_input , ebm_output)\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LszPRakhyxXS",
        "outputId": "03d5c0d3-8e8a-4f25-accd-656754510448"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 16, 16, 16)        416       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 8, 8, 32)          4640      \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 64)          18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 2, 2, 64)          36928     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 76993 (300.75 KB)\n",
            "Trainable params: 76993 (300.75 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if LOAD_MODEL:\n",
        "  model.load_weights(\"./models/model.h5\")"
      ],
      "metadata": {
        "id": "J2_psYki0XRF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Set up a Langevin samples finction"
      ],
      "metadata": {
        "id": "_iAZ5_8w0dra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#function to generate samples using Langevin Dynamics\n",
        "\n",
        "def generate_samples(\n",
        "    model , inp_imgs , steps , step_size , noise , return_img_per_step = False\n",
        "):\n",
        "    imgs_per_step = []\n",
        "    for _ in range(steps):\n",
        "      inp_imgs += tf.random.normal(inp_imgs.shape, mean = 0 , stddev = noise)\n",
        "      inp_imgs = tf.clip_by_value(inp_imgs , -1.0 , 1.0)\n",
        "      with tf.GradientTape() as tape:\n",
        "        tape.watch(inp_imgs)\n",
        "        out_score = model(inp_imgs)\n",
        "      grads = tape.gradient(out_score , inp_imgs)\n",
        "      grads = tf.clip_by_value(grads , -GRADIENT_CLIP, GRADIENT_CLIP)\n",
        "      inp_imgs += step_size * grads\n",
        "      inp_imgs = tf.clip_by_value(inp_imgs , -1.0 , 1.0)\n",
        "      if return_img_per_step:\n",
        "        imgs_per_step.append(inp_imgs)\n",
        "    if return_img_per_step:\n",
        "      return tf.stack(imgs_per_step, axis = 0)\n",
        "    else:\n",
        "      return inp_imgs"
      ],
      "metadata": {
        "id": "bzFVmCn10dBi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. set up a buffer to store examples"
      ],
      "metadata": {
        "id": "CxIiOU_r1u-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Buffer:\n",
        "  def __init__(self, model):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "    self.examples = [\n",
        "        tf.random.uniform(shape = (1, IMAGE_SIZE  , IMAGE_SIZE , CHANNELS)) * 2\n",
        "        -1\n",
        "        for _ in range(BATCH_SIZE)\n",
        "    ]\n",
        "\n",
        "  def sample_new_exmps(self, step_size , noise):\n",
        "    n_new = np.random.binomial(BATCH_SIZE , 0.05)\n",
        "    rand_imgs = (\n",
        "        tf.random.uniform((n_new , IMAGE_SIZE , IMAGE_SIZE  , CHANNELS)) * 2 - 1\n",
        "    )\n",
        "    old_imgs = tf.concat(\n",
        "        random.choices(self.examples, k = BATCH_SIZE  - n_new) , axis = 0\n",
        "    )\n",
        "    inp_imgs = tf.concat([rand_imgs , old_imgs] , axis = 0)\n",
        "    inp_imgs = generate_samples(\n",
        "        self.model, inp_imgs , steps = steps , step_size = step_size , noise = noise\n",
        "    )\n",
        "    self.examples = tf.split(inp_imgs , BATCH_SIZE , axis = 0) + self.examples\n",
        "    self.examples = self.examples[:BUFFER_SIZE]\n",
        "    return inp_imgs\n",
        ""
      ],
      "metadata": {
        "id": "rBvUnis21uDT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EBM(models.Model):\n",
        "  def __init__(self):\n",
        "    super(EBM , self).__init__()\n",
        "    self.model = model\n",
        "    self.buffer = Buffer(self.model)\n",
        "    self.alpha = ALPHA\n",
        "    self.loss_metric = metrics.Mean(name = \"loss\")\n",
        "    self.reg_loss_metric = metrics.Mean(name = \"reg\")\n",
        "    self.cdiv_loss_metric = metrics.Mean(name = \"cdiv\")\n",
        "    self.real_out_metric = metrics.Mean(name = \"real\")\n",
        "    self.fake_out_metric = metrics.Mean(name = \"fake\")\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    retunr[\n",
        "        self.loss_metric,\n",
        "        self.reg_loss_metric,\n",
        "        self.cdiv_loss_metric,\n",
        "        self.real_out_metric,\n",
        "        self.fake_out_metric,\n",
        "    ]\n",
        "\n",
        "  def train_step(self , real_imgs):\n",
        "    real_imgs += tf.random.normal(\n",
        "        shape = tf.shape(real_imgs), mean= 0, stddev = NOISE\n",
        "    )\n",
        "    real_imgs = tf.clip_by_value(real_imgs , -1.0, 1.0)\n",
        "    fake_imgs = self.buffer.sample_new_exmps(\n",
        "        steps = STEPS, step_size = STEP_SIZE , noise = NOISE\n",
        "    )\n",
        "    inp_imgs = tf.concat([real_imgs , fake_imgs] , axis = 0)\n",
        "    with tf.GradientTape() as training_tape:\n",
        "      real_out , fake_out = tf.split(self.model(inp_imgs), 2 , axis = 0)\n",
        "      cdiv_loss = tf.reduce_mean(fake_out , axis = 0) - tf.reduce_mean(\n",
        "          real_out , axis = 0\n",
        "      )\n",
        "      reg_loss = self.alpha * tf.reduce_mean(\n",
        "          real_out ** 2 + fake_out** 2 , axis = 0\n",
        "      )\n",
        "      loss = cdiv_loss + reg_loss\n",
        "    grads = training_tape.gradient(loss , self.model.trainable_variables)\n",
        "    self.optimizer.apply_gradients(\n",
        "        zip(grads , self.model.trainable_variables)\n",
        "    )\n",
        "    self.loss_metric.update_state(loss)\n",
        "    self.reg_loss_metric.update_state(reg_loss)\n",
        "    self.cdiv_loss_metric.update_state(cdiv_loss)\n",
        "    self.real_out_metric.update_state(tf.reduce_mean(real_out, axis = 0))\n",
        "    self.fake_out_metric.update_state(tf.reduce_mean(fake_out , axis = 0))\n",
        "    return {m.name : m.result() for m in self.metrics}\n",
        "\n",
        "  def test_step(self, real_imgs):\n",
        "    batch_size = real_imgs.shape[0]\n",
        "    fake_imgs = (\n",
        "        tf.random.uniform((batch_size , IMAGE_SIZE , IMAGE_SIZEm CHANNELS))\n",
        "        * 2\n",
        "        - 1\n",
        "    )\n",
        "    inp_imgs = tf.concat([real_imgs , fake_imgs ] , axis = 0)\n",
        "    real_out, fake_out = tf.split(self.model(inp_imgs ), 2 , axis = 0)\n",
        "    cdiv = tf.reduce_mean(fake_out, axis = 0) - tf.reduce_mean(\n",
        "        real_out, axis = 0\n",
        "    )\n",
        "    self.cdiv_loss_metric.update_state(cdiv)\n",
        "    self.real_out_metric.update_state(tf.reduce_mean(real_out, axis = 0))\n",
        "    self.fake_out_metric.update_state(tf.raduece_mean(fake_out , axis = 0))\n",
        "    return {m.name : m.result() for m in self.metrics[2: ]}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "taHCzwGB264G",
        "outputId": "47849652-c50e-4991-b1f8-5b856e0afbed"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax. Perhaps you forgot a comma? (<ipython-input-12-295cf73e4c46>, line 55)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-295cf73e4c46>\"\u001b[0;36m, line \u001b[0;32m55\u001b[0m\n\u001b[0;31m    tf.random.uniform((batch_size , IMAGE_SIZE , IMAGE_SIZEm CHANNELS))\u001b[0m\n\u001b[0m                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ebm - EBM()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "yFDf0o3s6Kpn",
        "outputId": "0bee792e-b488-411c-e346-4a4959e70202"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ebm' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-dec7f9675afa>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mebm\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mEBM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ebm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Train the EBM network"
      ],
      "metadata": {
        "id": "V0u3CXaE6Nwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#compile and train the model\n",
        "ebm.compile(\n",
        "    optimizer = optimizers.Adam(learning_rate = LEARNING_RATE) , run_eagerly = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "EAcQ194R6L9e",
        "outputId": "e15309ce-ad93-4c28-c901-72f897fe7169"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ebm' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-5154e494beb8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#compile and train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m ebm.compile(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mrun_eagerly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ebm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard_callback = callbacks.TensorBoard(log_dir = \"./logs\")\n",
        "\n",
        "class ImageGenerator(callbacks.Callback):\n",
        "  def __init__(self, num_img):\n",
        "    self.num_img = num_img\n",
        "\n",
        "  def on_epoch_end(self, epoch , logs = None):\n",
        "    start_imgs = (\n",
        "        np.random.uniform(\n",
        "            size = (self.num_img , IMAGE_SIZE , IMAGE_SIZE , CHANNELS)\n",
        "        )\n",
        "        * 2\n",
        "        - 1\n",
        "    )\n",
        "    generated_images = generate_samples(\n",
        "        ebm.model,\n",
        "        start_imgs ,\n",
        "        steps = 1000,\n",
        "        step_size = STEP_SIZE ,\n",
        "        noise = NOISE ,\n",
        "        return_img_per_step = False,\n",
        "    )\n",
        "    generated_images = generated_images.numpy()\n",
        "    display(\n",
        "        generated_images,\n",
        "        save_to = \"./output/generated_img_%03d.png\" % (epoch),\n",
        "    )\n",
        "\n",
        "    example_images = tf.concat(\n",
        "        random.choices(ebm.buffer.examples, k = 10) , axis = 0\n",
        "    )\n",
        "    example_images = example_images.numpy()\n",
        "    display(\n",
        "        example_images, save_to = \"./output/example_img_%03d.png\" % (epoch)\n",
        "    )\n",
        "\n",
        "image_generator_callbacks = ImageGenerator(num_img = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "t1zEWWBl6aG5",
        "outputId": "6629871e-9a00-4f74-9c91-050c536d65ed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'callbacks' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-78acb1114cad>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensorboard_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./logs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mImageGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'callbacks' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SaveModel(callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch , logs = None):\n",
        "    model.save_weights(\"./models/model.h5\")\n",
        "\n",
        "save_model_callback = SaveModel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "OPBEIvKbAbG_",
        "outputId": "e3c9395c-dad3-4e40-fa06-c9968090e74d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'callbacks' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2ea0e40a991f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSaveModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./models/model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msave_model_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'callbacks' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ebm.fit(\n",
        "    x_train,\n",
        "    shuffle = True,\n",
        "    epochs = 60,\n",
        "    validation_data = x_test,\n",
        "    callbacks = [\n",
        "        save_model_callback ,\n",
        "        tensorboard_callback,\n",
        "        image_generator_callback,\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "gblln9aVAqz2",
        "outputId": "e3b79e8a-fd17-4446-a366-d8f49d1e0626"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ebm' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-343b284fc15a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m ebm.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ebm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Generator images"
      ],
      "metadata": {
        "id": "XbTAapKKA6J8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_imgs = (\n",
        "    np.random.uniform(size = (10 , IMAGE_SIZE , IMAGE_SIZE, CHANNELS)) * 2 -1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "4J1LIyUgA4yh",
        "outputId": "112ae532-2026-42cf-ac4d-06c702f3a9fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6b527ca6e124>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m start_imgs = (\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHANNELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(start_imgs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "4BByLYLfBFGl",
        "outputId": "498a637f-bc8d-4a33-c225-8168f78cd318"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'start_imgs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a4c5d00cee73>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'start_imgs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_img = generate_samples(\n",
        "    ebm.model,\n",
        "    start_imgs,\n",
        "    steps = 1000,\n",
        "    step_size = STEP_SIZE,\n",
        "    noise = NOISE,\n",
        "    return_img_per_step = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "7WkiNWAnBGz4",
        "outputId": "a1bbccc9-be83-4404-f7b5-02d16af6dd03"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'generate_samples' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-52e6b1a23f78>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m gen_img = generate_samples(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mebm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mstart_imgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSTEP_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'generate_samples' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(gen_img[-1].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "aGj4wMs-BS8X",
        "outputId": "f3ac32c6-dd85-4429-a1e3-2f71f8bca401"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'gen_img' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-9a4b4a91bcef>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'gen_img' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imgs = []\n",
        "for i in [0, 1,3, 5,10,30,50,100,300,999]:\n",
        "  imgs.append(gen_img[i].numpy()[6])\n",
        "\n",
        "display(np.arange(imgs))"
      ],
      "metadata": {
        "id": "HhMUrR48BWE4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}