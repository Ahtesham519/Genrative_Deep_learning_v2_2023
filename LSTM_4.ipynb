{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObwNUJzknjCnWfZdoyXvMR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahtesham519/Genrative_Deep_learning_v2_2023/blob/main/LSTM_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVlwr3bTOSiH"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks , losses"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0. Parameters"
      ],
      "metadata": {
        "id": "BUVH0hO-OpFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 10000\n",
        "MAX_LEN = 200\n",
        "EMBEDDING_DIM = 100\n",
        "N_UNITS = 128\n",
        "VALIDATION_SPLIT = 0.2\n",
        "SEED = 42\n",
        "LOAD_MODEL = False\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS  = 25\n"
      ],
      "metadata": {
        "id": "jFp1BGfMOoR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Load the Data"
      ],
      "metadata": {
        "id": "7R4VTGAQPAoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the full dataset\n",
        "with open(\"./app/data/epirecipes/full_format_rcipes.json\") as json_data:\n",
        "  recipe_data = json.load(json_data)"
      ],
      "metadata": {
        "id": "De6rVJqHO_pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filter the dataset\n",
        "filtered_data = [\n",
        "    \"Recipe for \" + x[\"title\"] + \"|\" + \" \".join(x[\"directions\"])\n",
        "    for x in recipe_data\n",
        "    if \"title\" in x\n",
        "    and x[\"title\"] is not None\n",
        "    and \"directions\" in x\n",
        "    and x[\"directions\"] is not None\n",
        "]\n"
      ],
      "metadata": {
        "id": "4pQqiLdvPQO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#count the recipes\n",
        "n_recipes = len(filtered_data)\n",
        "print(f\"{n_recipes} recipes loaded\")"
      ],
      "metadata": {
        "id": "Xj_H_aqcPSXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = filtered_data[9]\n",
        "print(example)"
      ],
      "metadata": {
        "id": "NwdA-8T3PxDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Tokenise the data"
      ],
      "metadata": {
        "id": "WfFECT0eP1du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pad the punctuation , to treat them as seperate 'words'\n",
        "def pad_puntuation(s):\n",
        "  s = re.sub(f\"([{string.punctuation}])\" , r\" \\1\" , s)\n",
        "  s = re.sub(\" + \", \" \" , s)\n",
        "  return s\n",
        "\n",
        "text_data = [pad_punctuation(x) for x in filtered_data]"
      ],
      "metadata": {
        "id": "gYXtgoKNP0Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#display an example of a recipe\n",
        "example_data = text_data[9]\n",
        "example_data"
      ],
      "metadata": {
        "id": "A_QBPW7LQQfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert to a Tensorflow Dataset\n",
        "text_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(text_data)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .shuffle(1000)\n",
        ")"
      ],
      "metadata": {
        "id": "3pFtbJUfQWpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a vectorisation layer\n",
        "vectorize_layer = layers.TextVectorization(\n",
        "    standardize = \"lower\",\n",
        "    max_tokens = VOCAB_SIZE,\n",
        "    output_mode = \"int\",\n",
        "    output_sequence_length = MAX_LEN + 1,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "BIerSg8OQjpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adapt the layer to the training set\n",
        "vectorize_layer.adapt(text_ds)\n",
        "vocab = vectorize_layer.get_vocabulary()"
      ],
      "metadata": {
        "id": "HFkU2zyvQ1W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display some token:word mappings\n",
        "for i , word in enumerate(vocab[:10]):\n",
        "  print(f\"{i} : {word}\")"
      ],
      "metadata": {
        "id": "0g8Pmf2XQ-NV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the same example converted_to ints\n",
        "example_tokenised = vectorize_layer(example_data)\n",
        "print(example_tokenised.numpy())"
      ],
      "metadata": {
        "id": "9guYKLLgRIca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Create the training set"
      ],
      "metadata": {
        "id": "hoQ_Q1wGRScL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the training set of recipes and the same text shiftedby one word\n",
        "def prepare_iputs(text):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  tokenized_sentences = vectorize_layer(text)\n",
        "  x = tokenized_sentences[: , : -1]\n",
        "  y = tokenized_sentences[:, 1:]\n",
        "  return x , y\n",
        "\n",
        "train_ds = text_ds.map(prepare_inputs)\n"
      ],
      "metadata": {
        "id": "BSTvu1hyRRaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Build the LSTM"
      ],
      "metadata": {
        "id": "e0my8k_FRxvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape = (None,), dtype = \"int32\")\n",
        "x = layers.Embedding(VOCAB_SIZE , EMBEDDING_DIM)(inputs)\n",
        "x = layers.LSTM(N_UNITS, return_sequences=  True)(x)\n",
        "outputs = layers.Dense(VOCAB_SIZE , activation = \"softmax\")(x)\n",
        "lstm = models.Model(inputs , outputs)\n",
        "lstm.summary()"
      ],
      "metadata": {
        "id": "zubjJMhKRwqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if LOAD_MODEL:\n",
        "  #model.load_weights(\"./models/model\")\n",
        "  lstm = models.load_model(\"./models/lstm\" , compile = False)"
      ],
      "metadata": {
        "id": "OYB1a3SrSZfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Train the LSTM"
      ],
      "metadata": {
        "id": "E0jNdcvFSkaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = losses.SparseCategoricalCrossentropy()\n",
        "lstm.compile(\"adam\" , loss_fn)"
      ],
      "metadata": {
        "id": "cTACwXkBSjjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a TextGenerator checkpoint\n",
        "class TextGenerator(callbacks.Callback):\n",
        "  def __init__(self, index_to_word , top_k = 10):\n",
        "    self.index_to_word = index_to_word\n",
        "    self.word_to_index = {\n",
        "        word: index for index, word in enumerate(index_to_word)\n",
        "    }\n",
        "\n",
        "  def sample_from(self, probs , temperature):\n",
        "    probs = probs ** (1 / temperature)\n",
        "    probs = probs / np.sum(probs)\n",
        "    return np.random.choice(len(probs) , p = probs), probs\n",
        "\n",
        "  def generate(self, start_prompt, max_tokens , temperature):\n",
        "    start_tokens = [\n",
        "        self.word_to_index.get(x, 1) for x in start_prompt.split()\n",
        "    ]\n",
        "    sample_token = None\n",
        "    info = []\n",
        "    while len(start_tokens) < max_tokens and sample_token != 0 :\n",
        "      x = np.array([start_tokens])\n",
        "      y = self.model.predict(x, verbose = 0)\n",
        "      sample_token, probs =self.sample_from(y[0][-1] , temperature)\n",
        "      info.append({\"prompt\" : start_prompt, \"word_probs\":probs})\n",
        "      start_tokens.append(sample_token)\n",
        "      start_prompt = start_prompt + \" \" + self.index_to_word[sample_token]\n",
        "    print(f\"\\ngenerated text:\\n{start_prompt}\")\n",
        "    return info\n",
        "\n",
        "  def on_epoch_end(self, epoch , logs = None):\n",
        "    self.generate(\"recipe for\" , max_tokens = 100, temperature = 1.0)\n",
        "\n"
      ],
      "metadata": {
        "id": "GBzoUZ-uStLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a model save chekpoint\n",
        "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
        "    filepath = \"./checkpoint.checkpoint.ckpt\",\n",
        "    save_weights_only = True,\n",
        "    save_freq = \"epoch\",\n",
        "    verbose = 0,\n",
        ")\n",
        "\n",
        "tensorboard_callback = callbacks.TensorBoard(log_dir = \"./logs\")\n",
        "\n",
        "text_generator = TextGenerator(vocab)"
      ],
      "metadata": {
        "id": "qsutphlDUiw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm.fit(\n",
        "    train_ds,\n",
        "    epochs = EPOCHS,\n",
        "    callbacks = [model_checkpoint_callback , tensorboard_callback, text_generator ],\n",
        ")"
      ],
      "metadata": {
        "id": "eE7678umU8nQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save the final model\n",
        "lstm.save(\"./models/lstm\")"
      ],
      "metadata": {
        "id": "Y0wsRFH-VL53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Generate text using the LSTM\n"
      ],
      "metadata": {
        "id": "Tp602R-KVRRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_probs(info , vocab , top_k = 5):\n",
        "  for i in info:\n",
        "    print(f\"\\nPROMPT: {i['prompt']}\")\n",
        "    word_probs = i[\"word_probs\"]\n",
        "    p_sorted = np.sort(word_probs)[::-1][:top_k]\n",
        "    i_sorted = np.argsort(word_probs)[::-1][:top_k]\n",
        "    for p, i in zip(p_sorted, i_sorted):\n",
        "      print(f\"{vocab[i]}:   \\t{np.round(100*p, 2)}%\")\n",
        "    print(\"----------\\n\")"
      ],
      "metadata": {
        "id": "_kD9sdGGVQjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "    \"recipe for roasted vegetables | chop 1/\" , max_tokens = 10, temperature = 1.0\n",
        ")"
      ],
      "metadata": {
        "id": "yCJ5uMeMV8kY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_probs(info, vocab)"
      ],
      "metadata": {
        "id": "17VGnsEkWH-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "    \"recipe for roasted vegetables  | chop 1/\" , max_tokens = 10 , temperature = 0.2\n",
        ")"
      ],
      "metadata": {
        "id": "Pdv1LPQTWLPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_probs(info , vocab)"
      ],
      "metadata": {
        "id": "iazxCsgjWWEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "    \"recipe for chocolate oce cream |\", max_tokens = 7, temperature = 1.0\n",
        ")\n",
        "print_probs(info , vocab)"
      ],
      "metadata": {
        "id": "MGK-2eM4WZDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info = text_generator.generate(\n",
        "    \"recipe for chocolate ice cream | \", max_tokens = 7 , temperature = 0.2\n",
        ")\n",
        "print_probs(info , vocab)"
      ],
      "metadata": {
        "id": "vINhHXkfWklP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}