{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMh+y/KnrC2TPxnMiKKn058",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahtesham519/Genrative_Deep_learning_v2_2023/blob/main/Music_generation_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4Ovxphyt-GW"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers,models, losses,callbacks\n",
        "\n",
        "import music21"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0. Parameters"
      ],
      "metadata": {
        "id": "kQOORsqWuYZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PARSE_MIDI_FILES = True\n",
        "PARSED_DATA_PATH = \"/app/notebooks/11_music/01_transformer/parsed_data/\"\n",
        "DATASET_REPETITIONS = 1\n",
        "\n",
        "SEQ_LEN = 50\n",
        "EMBEDDING_DIM = 50\n",
        "KEY_DIM = 256\n",
        "N_HEADS = 5\n",
        "DROPOUT_RATE = 0.3\n",
        "FEED_FORWARD_DIM = 256\n",
        "LOAD_MODEL = False\n",
        "\n",
        "#optimization\n",
        "EPOCHS = 50000\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "GENERATE_LEN = 50"
      ],
      "metadata": {
        "id": "_lbQRCt4uXrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Prepare the data"
      ],
      "metadata": {
        "id": "GlBOrHgIvBpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data\n",
        "file_list = glob.glob(\"/app/data/bach-cello/*.mid\")\n",
        "print(f\"Found {len(file_list)} midi files\")"
      ],
      "metadata": {
        "id": "IalYTVo3vA29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = music21.converter"
      ],
      "metadata": {
        "id": "EB1fOy5lvTsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_score = (\n",
        "    music21.converter.parse(file_path[1]).splitAtQuarterLength(12)[0].chordify()\n",
        ")"
      ],
      "metadata": {
        "id": "kbviorkUvXBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_score.show()"
      ],
      "metadata": {
        "id": "Qa8MwJpQvihe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sxample_score.show(\"text\")"
      ],
      "metadata": {
        "id": "vu5vIkHpvkfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if PARSE_MIDI_FILES:\n",
        "  notes, durations = parse_midi_files(\n",
        "      file_list, parser, SEQ_LEN + 1 , PARSED_DATA_PATH\n",
        "  )\n",
        "else:\n",
        "  notes, durations = load_parsed_files()\n",
        ""
      ],
      "metadata": {
        "id": "5H0jQ9bGvm6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_notes = notes[658]\n",
        "example_durations = durations[658]\n",
        "print(\"\\nNotes string\\n\",example_notes,\"...\")\n",
        "print(\"\\nDuration string\\n\" , example_durations,\"...\")"
      ],
      "metadata": {
        "id": "fxOx95Rhv3ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Tokenize the Data"
      ],
      "metadata": {
        "id": "DZ7fIXpYwMF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(elements):\n",
        "  ds = (\n",
        "      tf.data.Dataset.from_tensor_slices(elements)\n",
        "      .batch(BATCH_SIZE, drop_remainder = True)\n",
        "      .shuffle(1000)\n",
        "  )\n",
        "  vectorizer_layer = layers.TextVectorization(\n",
        "      standardize = None , output_mode = \"int\"\n",
        "  )\n",
        "  vectorizer_layer.adapt(ds)\n",
        "  vocab = vectorize.get_vocabulary()\n",
        "  return ds, vectorizer_layer, vocab\n",
        "\n",
        "notes_seq_ds, notes_vectorize_layer, notes_vocab = create_dataset(notes)\n",
        "durations_seq_ds , durations_vectorize_layer, durations_vocab = create_dataset(\n",
        "    durations\n",
        ")\n",
        "seq_ds = tf.data.Dataset.zip((notes_seq_ds , durations_seq_ds))\n"
      ],
      "metadata": {
        "id": "62TwHLpUwKSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the same example notes and durations converted to ints\n",
        "example_tokenised_notes = notes_vectorize_layer(example_notes)\n",
        "example_tokenised_durations = durations_vectorize_layer(example_durations)\n",
        "print(\"{:10} {:10}\".format(\"note token\", \"duration token\"))\n",
        "for i , (note_int, duration_int) in enumerate(\n",
        "    zip(\n",
        "        example_tokenised_notes.numpy()[:11],\n",
        "        example_tokenised_durations.numpy()[:11],\n",
        "    )\n",
        "):\n",
        "    print(f\"{note_int:10}{duration_int:10}\")"
      ],
      "metadata": {
        "id": "tgzY5QwdxIW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notes_vocab_size = len(notes_vocab)\n",
        "durations_vocab_size = len(durations_vocab)\n",
        "\n",
        "#Display some token:note mappings\n",
        "print(f\"\\nNOTES_VOCAB :length = {len(notes_vocab)}\")\n",
        "for i , note in enumerate(notes_vocab[:10]):\n",
        "  print(f\"{i}: {note}\")\n",
        "\n",
        "print(f\"\\nDURATIONS_VOCAB: length = {len(durations_vocab)}\")\n",
        "#Display some token:duration mappings\n",
        "for i , note in enumerate(durations_vocab[:10]):\n",
        "  print(f\"{i}:{note}\")"
      ],
      "metadata": {
        "id": "vizxWb_kx1lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Create the training Set"
      ],
      "metadata": {
        "id": "4SmrzwwVykjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the training set of sequences and the same sequences shifted by one note\n",
        "def prepare_inputs(notes, durations):\n",
        "  notes = tf.expand_dims(notes , -1)\n",
        "  durations = tf.expand_dims(durations , -1)\n",
        "  tokenized_notes = notes_vectorize_layer(notes)\n",
        "  tokenized_durations = durations_vectorize_layer(durations)\n",
        "  x = (tokenized_notes[:, : -1], tokenized_durations[:, :-1])\n",
        "  y = (tokenized_notes[:, 1:], tokenised_durations[:, 1:])\n",
        "  return x , y\n",
        "\n",
        "ds = seq_ds.map(prepare_inputs).repeat(DATASET_REPETITIONS)"
      ],
      "metadata": {
        "id": "KyXhuXq6yikA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_input_output = ds.take(1).get_single_element()\n",
        "print(example_input_output)"
      ],
      "metadata": {
        "id": "V78mFmLjzc3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r8TWZxBAzkUT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}