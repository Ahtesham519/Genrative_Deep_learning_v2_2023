{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZNQXzf9cuMAx9w0qGbJLZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahtesham519/Genrative_Deep_learning_v2_2023/blob/main/RealNVP_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFCzYntbtKKz"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import (\n",
        "    layers,\n",
        "    models,\n",
        "    regularizers,\n",
        "    metrics,\n",
        "    optimizers,\n",
        "    callbacks,\n",
        ")\n",
        "\n",
        "import tensorflow_probability as tfp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0. Parameters"
      ],
      "metadata": {
        "id": "kPNbfEWotv_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COUPLING_DIN = 256\n",
        "COUPLING_LAYERS = 2\n",
        "INPUT_DIM = 2\n",
        "REGULARIZATION = 0.01\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 300"
      ],
      "metadata": {
        "id": "nTwYaPfEtuox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data\n",
        "data = datasets.make_moons(30000, noise = 0.05)[0].astype(\"float32\")\n",
        "norm = layers.Normalization()\n",
        "norm.adapt(data)\n",
        "normalized_data = norm(data)\n",
        "plt.scatter(\n",
        "    normalized_data.numpy()[:, 0], normalized_data.numpy()[:, 1], c = \"green\"\n",
        ")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fb4999AmuEsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Build the REALNVP network"
      ],
      "metadata": {
        "id": "Heq-HZ9LuimS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Coupling(input_dim , coupling_dim , reg):\n",
        "  input_layer = layers.Input(shape= input_dim)\n",
        "\n",
        "  s_layer_1 = layers.Dense(\n",
        "      coupling_dim , activation = \"relu\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(input_layer)\n",
        "  s_layer_2 = layers.Dense(\n",
        "      coupling_dim , activation =\"relu\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(s_layer_1)\n",
        "  s_layer_3 = layers.Dense(\n",
        "      coupling_dim , activation = \"relu\", kernel_regularizer = regularizers.l2(reg)\n",
        "  )(s_layer_2)\n",
        "  s_layer_4 = layers.Dense(\n",
        "      coupling_dim , activation = \"relu\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(s_layer_3)\n",
        "  s_layer_5 = layers.Dense(\n",
        "      input_dim , activation = \"tanh\" , kernel_regularizer =regularizers.l2(reg)\n",
        "  )(s_layer_4)\n",
        "\n",
        "  t_layer_1 = layers.Dense(\n",
        "      coupling_dim , activation = \"relu\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(input_layer)\n",
        "  t_layer_2 = layers.Dense(\n",
        "      coupling_dim, activation = \"relu\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(t_layer_1)\n",
        "  t_layer_3 = layers.Dense(\n",
        "      coupling_dim , activation = \"relu\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(t_layer_2)\n",
        "  t_layer_4 = layers.Dense(\n",
        "      coupling_dim , activation =\"relu\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(t_layer_3)\n",
        "  t_layer_5 = layers.Dense(\n",
        "      input_dim, activation = \"linear\" , kernel_regularizer = regularizers.l2(reg)\n",
        "  )(t_layer_4)\n",
        "  return models.Model(inputs = input_layer, output= [s_layer_5, t_layer_5])"
      ],
      "metadata": {
        "id": "7ySA0pRIuhaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RealNVP(models.Model):\n",
        "  def __init__(\n",
        "      self, input_dim , coupling_layers, coupling_dim , regularization\n",
        "  ):\n",
        "  super(RealNVP, self).__init__()\n",
        "  self.coupling_layers = coupling_layers\n",
        "  self.distribution = tfp.sidtributions.MultivariateNormalDiag(\n",
        "      loc = [0.0 , 0.0], scale_diag = [1.0, 1.0]\n",
        "  )\n",
        "  self.masks - np.array(\n",
        "      [[0,1] , [1,0]] * (coupling_layers // 2), dtype = \"float32\"\n",
        "  )\n",
        "  self.loss_tracker = metrics.Mean(name = \"loss\")\n",
        "  self.layers_list = [\n",
        "      Coupling(input_dim , coupling_dim, regularization)\n",
        "      for i in range(coupling_layers)\n",
        "  ]\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return [ self.loss_tracker]\n",
        "\n",
        "  def call(self, x, training = True):\n",
        "    log_det_inv = 0\n",
        "    direction = 1\n",
        "    if training:\n",
        "      direction = -1\n",
        "    for i in range(self.coupling_layers)[::direction]:\n",
        "      x_masked = x * self.masks[i]\n",
        "      reversed_mask = 1- self.masks[i]\n",
        "      s,t = self.layers_list[i](x_masked)\n",
        "      s *= reversed_mask\n",
        "      s *= reversed_mask\n",
        "      gate = (direction - 1)/2\n",
        "      x = (\n",
        "          reversed_mask\n",
        "          * (x * tf.exp(direction * s) + direction * t * tf.exp(gate * s))\n",
        "          + x_masked\n",
        "      )\n",
        "      log_det_inv  += gate * tf.reduce_sum(s, axis = 1)\n",
        "    return x , log_det_inv\n",
        "\n",
        "  def log_loss(self, x):\n",
        "    y , logdet = self(x)\n",
        "    log_likelihood = self.distribution.log_prob(y) + logdet\n",
        "    return -tf.reduce_mean(log_likelihood)\n",
        "\n",
        "  def train_step(self, data):\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss = self.log_loss(data)\n",
        "    g = tape.gradient(loss, self.trainable_variables)\n",
        "    self.optimizer.apply_gradients(zip(g, self.trainable_variables))\n",
        "    self.loss_tracker.update_state(loss)\n",
        "    return {\"loss\" : self.loss_tracker.result()}\n",
        "\n",
        "  def test_step(self, data):\n",
        "    loss = self.log_loss(data)\n",
        "    self.loss_tracker.update_state(loss)\n",
        "    return {\"loss\" :self.loss_tracker.result()}\n",
        "\n",
        "model = RealNVP(\n",
        "    input_dim = INPUT_DIM,\n",
        "    coupling_layers = COUPLING_LAYERS,\n",
        "    coupling_dim = COUPLING_DIM,\n",
        "    regularization = REGULARIZATION,\n",
        ")"
      ],
      "metadata": {
        "id": "Ymo4LelRAavg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train the RealNVP network"
      ],
      "metadata": {
        "id": "D_nT64xJhzRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#compile and train the model\n",
        "model.compile(optimizer= optimizers.Adam(learning_rate = 0.0001))"
      ],
      "metadata": {
        "id": "lSYr99UIhx9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard_callback = callbacks.TensorBoard(log_dir = \"./logs\")\n",
        "\n",
        "\n",
        "class ImageGenerator(callbacks.Callback):\n",
        "  def __init__(self, num_samples):\n",
        "    self.num_samples = num_samples\n",
        "\n",
        "  def generate(self):\n",
        "    #From the data latent space.\n",
        "    z, _ = model(normalized_data)\n",
        "\n",
        "    #From latent space to data\n",
        "    samples = model.distribution.sample(self.num_samples)\n",
        "    x, _ = model.predict(samples, verbose = 0)\n",
        "\n",
        "    return x , z ,samples\n",
        "\n",
        "  def display(self, x , z, samples , save_to = None):\n",
        "    f, axes = plt.subplots(2,2)\n",
        "    f.set_size_inches(8,5)\n",
        "\n",
        "    axes[0,0].scatter(\n",
        "        normalized_data[:, 0 ], normalized_data[:, 1], color = \"r\" , s = 1\n",
        "    )\n",
        "    axes[0,0].set(title = \"Data space X\" , xlabel = \"x_1\", ylabel = \"x_2\" )\n",
        "    axes[0,0].set_xlim([-2,2])\n",
        "    axes[0,0].set_ylim([-2,2])\n",
        "    axes[0,1].scatter(z[:,0], z[:,1], color = \"r\", s = 1)\n",
        "    axes[0,1].set(title=\"f(X)\",xlabel = \"z_1\" , y_label=\"z_2\")\n",
        "    axes[0,1].set_xlim([-2, 2])\n",
        "    axes[0,1].set_ylim([-2, 2])\n",
        "    axes[1,0].scatter(samples[:, 0], samples[:, 1], color = \"g\" , s = 1)\n",
        "    axes[1,0].set(title = \"Latent space Z\" , xlabel = \"z_1\" , ylabel = \"z_2\")\n",
        "    axes[1,0].set_xlim([-2, 2])\n",
        "    axes[1,0].set_ylim([-2,2])\n",
        "    axes[1,1].scatter(x[:,0], x[:, 1], color=\"g\", s = 1)\n",
        "    axes[1,1].set(title=\"g(Z)\", xlabel=\"x_1\", y_label=\"x_2\")\n",
        "    axes[1,1].set_xlim([-2,2])\n",
        "    axes[1,1].set_ylim([-2,2])\n",
        "\n",
        "    plt.subplots_adjust(wspace=0.3, hspace=0.6)\n",
        "    if save_to:\n",
        "      plt.savefig(save_to)\n",
        "      print(f\"\\nSaved to {save_to}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "  def on_epoch_end(self, epoch , logs =None):\n",
        "    if epoch % 10 == 0:\n",
        "      x, z , samples = self.generate()\n",
        "      self.display(\n",
        "          x,\n",
        "          z,\n",
        "          samples,\n",
        "          save_to = \"./output/generated_img%03d.png\"% (epoch),\n",
        "      )\n",
        "\n",
        "img_generator_callback = ImageGenerator(num_samples = 3000)"
      ],
      "metadata": {
        "id": "QmB4o3Cah-Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    normalised_data,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    epochs = EPOCHS,\n",
        "    callbacks = [tensorboard_callback, img_generator_callback]\n",
        ")"
      ],
      "metadata": {
        "id": "5ipzOMe5pQ6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.Generate Images"
      ],
      "metadata": {
        "id": "D4eyQyF0pi7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, z,samples = img_generator_callback.generate()"
      ],
      "metadata": {
        "id": "-DZmeWZSphmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_generator_callback_display(x, z , samples)"
      ],
      "metadata": {
        "id": "Itw4fkKypqXT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}