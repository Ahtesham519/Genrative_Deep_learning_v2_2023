{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGpNybWZTDvyQtNqtU18q4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahtesham519/Genrative_Deep_learning_v2_2023/blob/main/Transformer_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models , losses , callbacks\n",
        "\n",
        "import music21\n",
        "\n",
        "from transformer_utils import(\n",
        "    parse_midi_files,\n",
        "    load_parsed_files ,\n",
        "    get_midi_note,\n",
        "    SinePositionEncoding,\n",
        ")"
      ],
      "metadata": {
        "id": "-fjuapkgdmCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0. Parameters"
      ],
      "metadata": {
        "id": "8lmBAlCqeCXy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EkirauCdhjm"
      },
      "outputs": [],
      "source": [
        "PARSE_MIDI_FILES = True\n",
        "PARSED_DATA_PATH = \"/app/notebooks/11_music/01_transformer/parsed_data/\"\n",
        "DATASET_REPETITIONS = 1\n",
        "\n",
        "SEQ_LEN = 50\n",
        "EMBEDDING_DIM = 256\n",
        "KEY_DIM = 256\n",
        "N_HEADS = 5\n",
        "DROPOUT_RATE = 0.3\n",
        "FEED_FORWARD_DIM = 256\n",
        "LOAD_MODEL = False\n",
        "\n",
        "#optimization\n",
        "EPOCHS = 5000\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "GENERATE_LEN = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Prepare the Data"
      ],
      "metadata": {
        "id": "ljwbl5KiekUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data\n",
        "file_path = glob.glob(\"/app/data/bach-cello/*.mid\")\n",
        "print(f\"Found {len(file_list)} midi files\")"
      ],
      "metadata": {
        "id": "pJkYCVrMejn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = music21.converter\n"
      ],
      "metadata": {
        "id": "r1XcZ7XJeyL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_score = (\n",
        "    music21.converter.parse(file_list[1]).splitAtQuarterLength(12)[0].chordify()\n",
        ")"
      ],
      "metadata": {
        "id": "vrv32Jrge0WV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_score.show()"
      ],
      "metadata": {
        "id": "lnntdnEme_fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_score.show(\"text\")"
      ],
      "metadata": {
        "id": "vQ8QaFedfBof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if PARSE_MIDI_FILES:\n",
        "  notes, durations = parse_midi_files(\n",
        "      file_list, parser, SEQ_LEN + 1, PARSED_DATA_PATH\n",
        "  )\n",
        "else:\n",
        "  notes, durations = load_parsed_files()\n",
        ""
      ],
      "metadata": {
        "id": "wOwLR82pfD8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_notes = notes[658]\n",
        "example_durations = durations[658]\n",
        "print(\"\\nNotes string\\n\" , example_notes, \"...\")\n",
        "print(\"\\nDuration string\\n\", example_durations , \"...\")"
      ],
      "metadata": {
        "id": "3smBmtsxfSX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Tokenize the data"
      ],
      "metadata": {
        "id": "SgmImss8fkV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(elements):\n",
        "  ds = (\n",
        "      tf.data.Dataset.from_tensor_slices(elements)\n",
        "      .batch(BATCH_SIZE , drop_remainder = True)\n",
        "      .shuffle(1000)\n",
        "  )\n",
        "  vectorize_layer = layers.TextVectorization(\n",
        "      standardize = None, output_mode = \"int\"\n",
        "  )\n",
        "  vectorize_layer.adapt(ds)\n",
        "  vocab = vectorize_layer.get_vocabulary()\n",
        "  return ds , vectorize_layer, vocab\n",
        "\n",
        "notes_seq_ds,  notes_vectorize_layer, notes_vocab = create_dataset(notes)\n",
        "durations_seq_ds , durations_vectorize_layer , durations_vocab = create_dataset(\n",
        "    durations\n",
        ")\n",
        "seq_ds = tf.data.Dataset.zip((notes_seq_ds, durations_seq_ds))"
      ],
      "metadata": {
        "id": "YX3ijnaEfjpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the same example notes and durations converted to ints\n",
        "example_tokenised_notes = notes_vectorize_layer(example_notes)\n",
        "example_tokenised_durations = durations_vectorize_layer(example_durations)\n",
        "print(\"{:10} {:10}\".format(\"note token\" , \"duration token\"))\n",
        "for i , (note_int , duration_int) in enumerate(\n",
        "    zip(\n",
        "        example_tokenised_notes.numpy()[:11],\n",
        "        example_tokenised_durations.numpy()[:11]\n",
        "    )\n",
        "):\n",
        "    print(f\"{note_int:10}{duration_int:10}\")"
      ],
      "metadata": {
        "id": "lKrXxpoQgYdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notes_vocab_size = len(notes_vocab)\n",
        "durations_vocab_size = len(durations_vocab)\n",
        "\n",
        "#Display some token:note mappings\n",
        "print(f\"\\nNOTES_VOCAB:length = {len(notes_vocab)}\")\n",
        "for i , note in enumerate(notes_vocab[:10]):\n",
        "  print(f\"{i}: {note}\")\n",
        "\n",
        "print(f\"\\nDURATIONS_VOCAb:length = {len(durations_vocab)}\")\n",
        "#Disaply some token:duration mappings\n",
        "for i , note in enumerate(durations_vocab[:10]):\n",
        "  print(f\"{i}: {note}\")\n",
        ""
      ],
      "metadata": {
        "id": "Jkw7rCPIhDtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Create the Training set"
      ],
      "metadata": {
        "id": "Ve4LYz7YhoJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the training set of sequences and the samesequences shifted by one note\n",
        "\n",
        "def prepare_inputs(notes, durations):\n",
        "  notes = tf.expand_dims(notes, -1)\n",
        "  durations = tf.expand_dims(durations , -1)\n",
        "  tokenized_notes = notes_vectorize_layer(notes)\n",
        "  tokenized_durations = durations_vectorize_layer(durations)\n",
        "  x = (tokenized_notes[:,:-1] , tokenized_durations[:, : -1])\n",
        "  y = (tokenized_notes[:, 1:], tokenized_durations[:, 1:])\n",
        "  return x , y\n",
        "\n",
        "ds = seq_ds.map(prepare_inputs).repeat(DATASET_REPETITIONS)"
      ],
      "metadata": {
        "id": "yAb5vqvMhncK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_input_output = ds.take(1).get_single_element()\n",
        "print(example_input_output)"
      ],
      "metadata": {
        "id": "oQHokAWGiZQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Create the casual attention mask function"
      ],
      "metadata": {
        "id": "cbwJ-xOdiiYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def casual_attention_mask(batch_size , n_dest,  n_src , dtype):\n",
        "  i = tf.range(n_dest)[:, None]\n",
        "  j = tf.range(n_src)\n",
        "  m = i >= j - n_src + n_dest\n",
        "  mask = tf.cast(m, dtype)\n",
        "  mask = tf.reshape(mask , [1, n_dest , n_src])\n",
        "  mult = tf.concat(\n",
        "      [tf.expand_dims(batch_size , -1), tf.constant([1,1], dtype= tf.int32)], 0\n",
        "  )\n",
        "  return tf.title(mask, mult)\n",
        "\n",
        "np.transpose(casual_attention_mask(1, 10, 10, dtype = tf.int32)[0])"
      ],
      "metadata": {
        "id": "wNxr4XT4ihqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Create a Trandformer Block layer"
      ],
      "metadata": {
        "id": "bGfywN8VjOPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "  def __init__(\n",
        "      self,\n",
        "      num_heads,\n",
        "      key_dim,\n",
        "      embed_dim ,\n",
        "      ff_dim,\n",
        "      name,\n",
        "      dropout_rate = DROPOUT_RATE,\n",
        "\n",
        "  ):\n",
        "  super(TransformerBlock, self).__init__(name = name)\n",
        "  self.num_heads = num_heads\n",
        "  self.key_dim = key_dim\n",
        "  self.embed_dim = embed_dim\n",
        "  self.ff_dim = ff_dim\n",
        "  self.dropout_rate = dropout_rate"
      ],
      "metadata": {
        "id": "-8q4RnfcjM4Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}