{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMos8C/c0Op0GHTRu46UJw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahtesham519/Genrative_Deep_learning_v2_2023/blob/main/Varational_autoencoder_45.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJbaR5B_Lf0t"
      },
      "outputs": [],
      "source": [
        "%load_ext = autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import (\n",
        "    layers,\n",
        "    models,\n",
        "    callbacks,\n",
        "    utils ,\n",
        "    metrics,\n",
        "    losses,\n",
        "    optimizers,\n",
        ")\n",
        "\n",
        "from scipy.stats import norm\n",
        "import pandas as pd\n",
        "\n",
        "from vae_utils import get_vector_from_label , add_vector_to_images , morph_faces"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0. Parameters"
      ],
      "metadata": {
        "id": "Xj0XgUZVMXO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 32\n",
        "CHANNELS = 3\n",
        "BATCH_SIZE = 128\n",
        "NUM_FEATURES = 128\n",
        "Z_DIM = 200\n",
        "LEARNING_RATE = 0.0005\n",
        "EPOCHS = 10\n",
        "BETA = 2000\n",
        "LOAD_MODEL = False"
      ],
      "metadata": {
        "id": "9kKtn_UeMVsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Prepare the data\n"
      ],
      "metadata": {
        "id": "WFzvOBJpMnpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data\n",
        "train_data = utils.image_dataset_from_directory(\n",
        "    \"/app/data/celebs-dataset/img_align_celba/img_align_celeba\",\n",
        "    labels = None,\n",
        "    color_mode = \"rgb\",\n",
        "    image_size = (IMAGE_SIZE , IMAGE_SIZE),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = True,\n",
        "    seed = 42,\n",
        "    interpolation = \"bilinear\",\n",
        ")"
      ],
      "metadata": {
        "id": "qcjB1PWvMmvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocess the data\n",
        "def preprocess(img):\n",
        "  img = tf.cast(img , \"float32\") / 255.0\n",
        "  return img\n",
        "\n",
        "train= train_data.map(lambda x: preprocess(x))"
      ],
      "metadata": {
        "id": "-4mxYgwKNHaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trian_sample = sample_batch(train)"
      ],
      "metadata": {
        "id": "tC_wQ2tnNTA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(train_sample , cmap = None)"
      ],
      "metadata": {
        "id": "sNGBAJH4NVQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Bulid the variational autoencoder\n"
      ],
      "metadata": {
        "id": "2y89WIafNbGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(layers.Layer):\n",
        "  def call(self, inputs):\n",
        "    z_mean = z_log_var = inputs\n",
        "    batch = tf.shape(z_mean)[0]\n",
        "    dim = tf.shape(z_mean)[1]\n",
        "    epsilon = K.random_normal(shape = (batch, dim))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "0tzWx7-WNYpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoder\n",
        "encoder_input = layers.Input(\n",
        "    shape = (IMAGE_SIZE , IMAGE_SIZE , CHANNELS) , name = \"encoder_input\"\n",
        ")\n",
        "x = layers.Conv2D(NUM_FEATURES , kernel_size = 3, strides = 2, padding = \"same\")(\n",
        "    encoder_input\n",
        ")\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(NUM_FEATURES, kernel_size = 3, strides = 2, padding = \"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(NUM_FEATURES, kernel_size = 3, strides = 2, padding = \"same\")(X)\\\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "shape_before_flattening = K.int_shape(x)[1:] # the decoder will need this !\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "z_mean = layers.Dense(Z_DIM , name = \"z_mean\")(x)\n",
        "z_log_var = layers.Dense(Z_DIM, name  = \"z_log_var\")(x)\n",
        "z = Sampling()([z_mean , z_log_var])\n",
        "\n",
        "encoder = models.Model(encoder_input , [z_mean , z_log_var, z] , name = \"encoder\")\n",
        "encoder.summary()\n"
      ],
      "metadata": {
        "id": "FRhC4O3dN2A0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#decoder\n",
        "decoder_input = layers.Input(shape = (Z_DIM, ) name = \"decoder_input\")\n",
        "x = layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Reshape(shape_before_flattening)(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    NUM_FEATURES, kernel_size = 3, strides = 2, padding = \"same\"\n",
        ")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    NUM_FEATURES , kernel_size = 3, strides  = 2, padding = \"same\"\n",
        ")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    NUM_FEATURES , kernel_size  = 3, strides = 2, padding = \"same\"\n",
        ")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    NUM_FEATURES , kernel_size = 3 , strides = 2, padding = \"same\"\n",
        ")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "decoder_output = layers.Conv2DTranspose(\n",
        "    CHANNELS , kernel_size = 3, strides = 1, activation = \"sigmoid\" , padding = \"same\"\n",
        ")\n",
        "decoder - models.Model(decoder_input , decoder_output)\n",
        "decoder.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "_FwYZQiwW-39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(models.Model):\n",
        "  def __init__(self, encoder, decoder, **kwargs):\n",
        "    super(VAE, self).__init__(**kwargs)\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.total_loss_tracker = metrics.Mean(name = \"total_loss\")\n",
        "    self.reconstruction_loss_tracker = metrics.Mean(\n",
        "        name = \"reconstruction_loss\"\n",
        "    )\n",
        "    self.kl_loss_tracker = metrics.Mean(name = \"kl_loss\")\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return [\n",
        "        self.total_loss_tracker,\n",
        "        self.reconstruction_loss_tracker,\n",
        "        self.kl_loss_tracker,\n",
        "    ]\n",
        "\n",
        "  def call(self, inputs):\n",
        "    \"\"\"Call the model on a particular input\"\"\".\n",
        "    z_mean , z_log_var , z = encoder(inputs)\n",
        "    reconstruction = decoder(z)\n",
        "    return z_mean , z_log_var , reconstruction\n",
        "\n",
        "  def train_step(self, data):\n",
        "    \"\"\"Step run during training\"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "      z_mean , z_log_var , reconstruction = self(data , training = True)\n",
        "      reconstruction_loss = tf.reduce_mean(\n",
        "          BETA * losses.mean_squared_error(data , recontruction )\n",
        "      )\n",
        "      kl_loss  = tf.reduce_mean(\n",
        "          tf.reduce_sum(\n",
        "              -0.5\n",
        "              * ( 1+ z_log_var - tf.square(z_mean) - tf.exp(z_log_var)),\n",
        "              axis = 1,\n",
        "          )\n",
        "      )\n",
        "      total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "    grads = tape.gradient(total_loss , self, traininable_weights)\n",
        "    self.optimizer.apply_gradints(zip(grads , self.trainable_weights))\n",
        "\n",
        "    self.total_loss_tracker.update_state(total_loss)\n",
        "    self.reconstruction_loss_tracker.update_state(kl_loss)\n",
        "\n",
        "\n",
        "    return {\n",
        "        \"loss\" : self.total_loss_tracker.result(),\n",
        "        \"reconstruction_loss\" : self.reconstruction_loss_tracker.result(),\n",
        "        \"kl_loss\":self.kl_loss_tracker.result(),\n",
        "    }\n",
        "\n",
        "  def test_step(self, data):\n",
        "    \"\"\"Step run during validation\"\"\"\n",
        "    if isinstance(data, tuple):\n",
        "      data = data[0]\n",
        "\n",
        "    z_mean , z_log_var , reconstruction = self(data)\n",
        "    reconstruction_loss = tf.reduce_mean(\n",
        "        BETA * losses.mean_squared_error(data, reconstruction)\n",
        "    )\n",
        "    kl_loss  = tf.reduce_mean(\n",
        "        tf.reduce_sum(\n",
        "            -0.5 * ( 1+ z_log_var - tf.square(z_mean) - tf.exp(z_log_var)),\n",
        "            axis = 1,\n",
        "        )\n",
        "    )\n",
        "    total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "    return{\n",
        "        \"loss\": total_loss,\n",
        "        \"reconstruction\" : reconstruction_loss,\n",
        "        \"kl_loss\" : kl_loss,\n",
        "    }"
      ],
      "metadata": {
        "id": "vcb8pDvxYz7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a varational autoencoder\n",
        "vae = VAE(encoder , decoder)"
      ],
      "metadata": {
        "id": "WBoj-9Ahb0Wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Train the varational autoencoder"
      ],
      "metadata": {
        "id": "tndYqvi7b6hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the varational autoencode\n",
        "optimizer = optimizers.Adam(learning_rate = LEARNING_RATE)\n",
        "vae.compile(optimizer = optimizer)\n"
      ],
      "metadata": {
        "id": "rd1xtye6b5cQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a model save checkpoint\n",
        "model_checkpoint_callbacks = callbacks.ModelCheckpoint(\n",
        "    filepath = \"./checkpoint\",\n",
        "    save_weights_only = False,\n",
        "    save_freq = \"epoch\",\n",
        "    monitor = \"loss\",\n",
        "    mode = \"min\",\n",
        "    save_best_only = True,\n",
        "    verbose = 0,\n",
        ")\n",
        "\n",
        "tensorboard_callback = callbacks.Tensorboard(log_dir = \"./logs\")\n",
        "\n",
        "\n",
        "class ImageGenerator(callbacks.Callback):\n",
        "  def __init__(selff, num_img , latent_dim):\n",
        "    self.num_img = num_img\n",
        "    self.latent_dim = latent_dim\n",
        "\n",
        "  def on_epoch_end(self, epoch , logs = None):\n",
        "    random_latent_vectors = tf.random.normal(\n",
        "        shape = (self.num_img , self.latent_dim)\n",
        "    )\n",
        "    generated_images = self.model.decoder(random_latent_vectors)\n",
        "    generated_images *= 255\n",
        "    generated_images.numpy()\n",
        "    for i in range(self.num_img):\n",
        "      img = utils.array_to_img(generated_images[i])\n",
        "      img.save(\"./output/generated_img_%03d_%d.png\" % (epoch , i))\n"
      ],
      "metadata": {
        "id": "4JqByV3NcJGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load old weights if required\n",
        "if LOAD_MODE:\n",
        "  vae.load_weights(\"./models.vae\")\n",
        "  tmp = vae.predict(train.take(1))\n",
        ""
      ],
      "metadata": {
        "id": "gNjpTFlZdQXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.fit(\n",
        "    train,\n",
        "    epochs = EPOCHS,\n",
        "    callbacks  = [\n",
        "        model_checkpoint_callbacks,\n",
        "        tensorboard_callback,\n",
        "        ImageGenerator(num_img = 10 , latent_dim = Z_DIM),\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "70sxaVWpdag0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save the final models.\n",
        "vae.save(\"./models/vae\")\n",
        "encoder.save(\"./models/encoder\")\n",
        "decoder.save(\"./models.decoder\")"
      ],
      "metadata": {
        "id": "4N73A9tidrmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Reconstruction using the variational autoencoder"
      ],
      "metadata": {
        "id": "ilOYFTKNd2UZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Select a subset of the test set\n",
        "batches_to_predict = 1\n",
        "example_images = np.array(\n",
        "    list(train.take(batches_to_predict).get_single_element())\n",
        ")"
      ],
      "metadata": {
        "id": "cwtihaxyd1Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create autoencoder predictions and display\n",
        "z_mean , z_log_var , reconstructions = vae.predict(exmpale_images)\n",
        "print(\"example real faces\")\n",
        "display(exmaple_images)\n",
        "print(\"reconstructions\")\n",
        "display(reocnstructions)\n"
      ],
      "metadata": {
        "id": "WONjZSOOeGm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. latent space distribution"
      ],
      "metadata": {
        "id": "Nti3lpSieeFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, _, z = vae.encoder.predict(example_images)\n",
        "\n",
        "x = np.linspace(-3, 3, 100)\n",
        "\n",
        "fig = plt.figure(figsize = (20, 5))\n",
        "fig.subplots_adjust(hspace = 0.6 , wspace = 0.4)\n",
        "\n",
        "for i in range(50):\n",
        "  ax = fig.add_subplot(5, 10, i + 1)\n",
        "  ax.hist(z[:, i ] ,  density = True , bins = 20)\n",
        "  ax.axis(\"off\")\n",
        "  ax.text(\n",
        "      0.5 , -0.35, str(i) , fontsize = 10 , ha = \"center\" , transform = ax.transAxes\n",
        "  )\n",
        "  ax.plot(x, norm.pdf(x))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Clo0nfPjecpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Generate new faces"
      ],
      "metadata": {
        "id": "seOnRzWrfNq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample some points in the latent space , from the standard normal distribution\n",
        "grid_width , grid_height = (10 , 3)\n",
        "z_sample = np.random.normal(size = (grid_width * grid_height , Z_DIM ))"
      ],
      "metadata": {
        "id": "TEGUtMQgfM5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decoder the samples points\n",
        "reconstructions = decoder.predict(z_sample)"
      ],
      "metadata": {
        "id": "apidNfNDfxXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Draw a plot of decoder images\n",
        "fig = plt.figure(figsize = (18, 5))\n",
        "fig.subplots_adjust(hspace= 0.4, wspace= 0.4)\n",
        "\n",
        "#output the grid of faces\n",
        "for i in range(grid_width * grid_height):\n",
        "  ax = fig.add_subplot(grid_height , grid_width , i + 1)\n",
        "  ax.axis(\"off\")\n",
        "  ax.imshow(reconstructions[i, :, :])"
      ],
      "metadata": {
        "id": "6Brfh95Wf1mT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Manipulate the images"
      ],
      "metadata": {
        "id": "wGqcLbrwgR-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the label dataset\n",
        "attributes = pd.read_csv(\"./app/data/celeba-dataset/list_attr_celeba.csv\")\n",
        "print(attributes.columns)\n",
        "attributes.head()"
      ],
      "metadata": {
        "id": "KK4t2Sc7gQVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the face data with label attached\n",
        "LABEL = \"Blond Hair\"\n",
        "labelled_test = utils.image_dataset_from_directory(\n",
        "    \"/app/data/celeba-dataset/img_align_celeba\",\n",
        "    labels = attributes[LABEL].tolist(),\n",
        "    color_mode= \"rgb\",\n",
        "    image_size = (IMAGE_SIZE , IMAGE_SIZE),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = True,\n",
        "    seed = 42 ,\n",
        "    validation_split = 0.2 ,\n",
        "    subset = \"validation\",\n",
        "    interpolation = \"bilinear\",\n",
        ")\n",
        "\n",
        "labelled = labelled_test.map(lambda x, y: (preprocess(x), y))"
      ],
      "metadata": {
        "id": "wm23NfWUggSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the atributes vector\n",
        "attributes_vec = get_vector_from_label(labebled , vae , Z_DIM , LABEL)\n",
        "\n"
      ],
      "metadata": {
        "id": "rsdgNYQXhTN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add vector to images\n",
        "add_vector_to_images(labelled , vae , attribute_vec)"
      ],
      "metadata": {
        "id": "z3YuwU82hbto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "morph_faces(labelled, vae)"
      ],
      "metadata": {
        "id": "kYimPkTGhkfi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}