{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP93oK8H9m6hAqiQFmwkKXS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahtesham519/Genrative_Deep_learning_v2_2023/blob/main/Variational_Auto_encoder_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LJZ9EB0gmz5F"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import (\n",
        "    layers,\n",
        "    models,\n",
        "    datasets,\n",
        "    callbacks,\n",
        "    losses,\n",
        "    optimizers,\n",
        "    metrics,\n",
        ")\n",
        "\n",
        "from scipy.stats import norm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0. Parameters"
      ],
      "metadata": {
        "id": "X2S1N8L4nUBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 32\n",
        "BATCH_SIZE = 100\n",
        "VALIDATION_SPLIT = 0.2\n",
        "EMBEDDING_DIM = 2\n",
        "EPOCHS = 5\n",
        "BETA = 500"
      ],
      "metadata": {
        "id": "Qch2LPn0nTIu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare the data"
      ],
      "metadata": {
        "id": "S54yB8VpniHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data\n",
        "(x_train , y_train), (x_test , y_test) = datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A_P5u6kng9r",
        "outputId": "690a91c3-76bc-4549-f953-f672354df842"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess the data\n",
        "def preprocess(imgs):\n",
        "  \"\"\"\n",
        "  normalize and reshape the image\n",
        "  \"\"\"\n",
        "  imgs = imgs.astype(\"float32\")\n",
        "  imgs = np.pad(imgs, ((0,0) , (2,2), (2,2)), constant_values = 0.0)\n",
        "  imgs = np.expand_dims(imgs, -1)\n",
        "  return imgs\n",
        "\n",
        "x_train = preprocess(x_train)\n",
        "x_test = preprocess(x_test)"
      ],
      "metadata": {
        "id": "ssBuhcFTnsKe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show some items of clothings from the training set\n",
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u55zqKvvoP9K",
        "outputId": "56ed378a-046c-4668-ec0e-e015afce26ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]],\n",
              "\n",
              "\n",
              "       [[[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]],\n",
              "\n",
              "        [[0.],\n",
              "         [0.],\n",
              "         [0.],\n",
              "         ...,\n",
              "         [0.],\n",
              "         [0.],\n",
              "         [0.]]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Build the variational autoencoder"
      ],
      "metadata": {
        "id": "2tYYI2P9ANsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling (layers.Layer):\n",
        "  def call(self, inputs):\n",
        "    z_mean, z_log_var = inputs\n",
        "    batch = tf.shape(z_mean)[0]\n",
        "    dim = tf.shape(z_mean)[1]\n",
        "    epsilon = K.random_normal(shape = (batch, dim))\n",
        "    return z_mean +tf.exp(0.5 * z_log_var) * epsilon\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "jls2kzgGobQ8",
        "outputId": "a2e311bd-7d6b-495e-b37a-c7919eeef408"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b5d24760d83f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSampling\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mz_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_log_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'layers' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoder\n",
        "encoder_input = layers.Input(\n",
        "    shape = (IMAGE_SIZE , IMAGE_SIZE, 1), name = \"encoder_input\"\n",
        ")\n",
        "x = layers.Conv2D(32,(3,3), strides = 2, activation = \"relu\" , padding = \"same\")(\n",
        "    encoder_input\n",
        ")\n",
        "x = layers.Conv2D(64, (3,3), srides = 2, activation = \"relu\", padding = \"same\")(x)\n",
        "x = layers.Conv2D(128, (3,3), strides = 2,activation = \"relu\" , padding = \"same\")(x)\n",
        "shape_before_flattening = K.int_shape(x)[1:]\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "z_mean = layers.Dense(EMBEDDING_DIM , name = \"z_mean\")(x)\n",
        "z_log_var = layers.Dense(EMBEDDING_DIM, name = \"z_log_var\")(x)\n",
        "z = Sampling()([z_mean , z_log_var])\n",
        "\n",
        "encoder = models.Model(encoder_input, [z_mean , z_log_var, z] , name = \"encoder\")\n",
        "encoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "G-rXOWX4Au0W",
        "outputId": "34a42244-f670-449d-cd6b-2eea3c1f78fb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8adf1bf50ed9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m encoder_input = layers.Input(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"encoder_input\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m x = layers.Conv2D(32,(3,3), strides = 2, activation = \"relu\" , padding = \"same\")(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'layers' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Decoder\n",
        "decoder_input = layers.Input(shape = (EMBEDDING_DIM,) , name = \"decoder_input\")\n",
        "x = layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
        "x = layers.Reshape(shape_before_flattening)(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    128, (3,3), strides = 2, activation = \"relu\" , padding = \"same\"\n",
        ")(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    64, (3,3) , strides= 2, activation = \"relu\" , padding = \"same\"\n",
        ")(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    32, (3,3) , strides = 2, activation = \"relu\" , padding = \"same\"\n",
        ")(x)\n",
        "decoder_output = layers.Conv2D(\n",
        "    1,\n",
        "    strides = 1,\n",
        "    activation = \"sigmoid\",\n",
        "    padding = \"same\",\n",
        "    name = \"decoder_output\",\n",
        ")(x)\n",
        "\n",
        "decoder = models.Model(decoder_input, decoder_output)\n",
        "decoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "eTorBNULB2a2",
        "outputId": "269ea9ff-a075-4c31-bada-0f143af1799c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-065da6f48de9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"decoder_input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_before_flattening\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_before_flattening\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m x = layers.Conv2DTranspose(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'layers' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(models.Model):\n",
        "  def __init__(self,encoder,decoder , **kwargs):\n",
        "    super(VAE, self).__init__(**kwargs)\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.total_loss_tracker = metrics.Mean(name = \"total_loss\")\n",
        "    self.reconstruction_loss_tracker = metrics.Mean(\n",
        "        name = \"reconstruction_loss\"\n",
        "    )\n",
        "    self.kl_loss_tracker = metrics.Mean(name = \"kl_loss\")\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return[\n",
        "        self.total_loss_tracker,\n",
        "        self.reconstruction_loss_tracker,\n",
        "        self.kl_loss_tracker,\n",
        "    ]\n",
        "\n",
        "  def call(self, inputs):\n",
        "    \"\"\" Call the model on a particular input\"\"\"\n",
        "    z_mean , z_log_var , z = encoder(inputs)\n",
        "    reconstruction = decoder(z)\n",
        "    return z_mean , z_log_var, reconstruction\n",
        "\n",
        "  def train_step(self, data):\n",
        "    \"\"\"Step run during training \"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "      z_mean , z_log_var, reconstruction = self(data)\n",
        "      reconstruction_loss = tf.reduce_mean(\n",
        "          BETA\n",
        "          * losses.binary_crossentropy(\n",
        "              data, reconstruction, axis = (1,2,3)\n",
        "          )\n",
        "      )\n",
        "      kl_loss = tf.reduce_mean(\n",
        "          tf.reduce_sum(\n",
        "              -0.5\n",
        "              * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)),\n",
        "              axis = 1,\n",
        "          )\n",
        "      )\n",
        "      total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "    grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "    self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "\n",
        "    self.total_loss_tracker.update_state(total_loss)\n",
        "    self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "    self.kl_loss_tracker.update_state(kl_loss)\n",
        "\n",
        "    return {m.name : m.result() for m in self.metrics}\n",
        "\n",
        "  def test_step(self, data):\n",
        "    \"\"\"Step run during validation\"\"\"\n",
        "    if isinstance(data, tuple):\n",
        "      data = data[0]\n",
        "\n",
        "    z_mean , z_log_var , reconstruction = self(data)\n",
        "    reconstruction_loss = tf.reduce_mean(\n",
        "        BETA,\n",
        "\n",
        "    )"
      ],
      "metadata": {
        "id": "ySUXWlbkDMzP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}