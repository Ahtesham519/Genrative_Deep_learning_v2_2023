{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxigh8Z0v3Sx1RLIjb/990",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahtesham519/Genrative_Deep_learning_v2_2023/blob/main/Variational_Auto_encoder_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJZ9EB0gmz5F"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import (\n",
        "    layers,\n",
        "    models,\n",
        "    datasets,\n",
        "    callbacks,\n",
        "    losses,\n",
        "    optimizers,\n",
        "    metrics,\n",
        ")\n",
        "\n",
        "from scipy.stats import norm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0. Parameters"
      ],
      "metadata": {
        "id": "X2S1N8L4nUBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 32\n",
        "BATCH_SIZE = 100\n",
        "VALIDATION_SPLIT = 0.2\n",
        "EMBEDDING_DIM = 2\n",
        "EPOCHS = 5\n",
        "BETA = 500"
      ],
      "metadata": {
        "id": "Qch2LPn0nTIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare the data"
      ],
      "metadata": {
        "id": "S54yB8VpniHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data\n",
        "(x_train , y_train), (x_test , y_test) = datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "1A_P5u6kng9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess the data\n",
        "def preprocess(imgs):\n",
        "  \"\"\"\n",
        "  normalize and reshape the image\n",
        "  \"\"\"\n",
        "  imgs = imgs.astype(\"float32\")\n",
        "  imgs = np.pad(imgs, ((0,0) , (2,2), (2,2)), constant_values = 0.0)\n",
        "  imgs = np.expand_dims(imgs, -1)\n",
        "  return imgs\n",
        "\n",
        "x_train = preprocess(x_train)\n",
        "x_test = preprocess(x_test)"
      ],
      "metadata": {
        "id": "ssBuhcFTnsKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show some items of clothings from the training set\n",
        "x_train"
      ],
      "metadata": {
        "id": "u55zqKvvoP9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Build the variational autoencoder"
      ],
      "metadata": {
        "id": "2tYYI2P9ANsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling (layers.Layer):\n",
        "  def call(self, inputs):\n",
        "    z_mean, z_log_var = inputs\n",
        "    batch = tf.shape(z_mean)[0]\n",
        "    dim = tf.shape(z_mean)[1]\n",
        "    epsilon = K.random_normal(shape = (batch, dim))\n",
        "    return z_mean +tf.exp(0.5 * z_log_var) * epsilon\n",
        ""
      ],
      "metadata": {
        "id": "jls2kzgGobQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoder\n",
        "encoder_input = layers.Input(\n",
        "    shape = (IMAGE_SIZE , IMAGE_SIZE, 1), name = \"encoder_input\"\n",
        ")\n",
        "x = layers.Conv2D(32,(3,3), strides = 2, activation = \"relu\" , padding = \"same\")(\n",
        "    encoder_input\n",
        ")\n",
        "x = layers.Conv2D(64, (3,3), srides = 2, activation = \"relu\", padding = \"same\")(x)\n",
        "x = layers.Conv2D(128, (3,3), strides = 2,activation = \"relu\" , padding = \"same\")(x)\n",
        "shape_before_flattening = K.int_shape(x)[1:]\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "z_mean = layers.Dense(EMBEDDING_DIM , name = \"z_mean\")(x)\n",
        "z_log_var = layers.Dense(EMBEDDING_DIM, name = \"z_log_var\")(x)\n",
        "z = Sampling()([z_mean , z_log_var])\n",
        "\n",
        "encoder = models.Model(encoder_input, [z_mean , z_log_var, z] , name = \"encoder\")\n",
        "encoder.summary()"
      ],
      "metadata": {
        "id": "G-rXOWX4Au0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decoder\n",
        "decoder_input = layers.Input(shape = (EMBEDDING_DIM,) , name = \"decoder_input\")\n",
        "x = layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
        "x = layers.Reshape(shape_before_flattening)(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    128, (3,3), strides = 2, activation = \"relu\" , padding = \"same\"\n",
        ")(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    64, (3,3) , strides= 2, activation = \"relu\" , padding = \"same\"\n",
        ")(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    32, (3,3) , strides = 2, activation = \"relu\" , padding = \"same\"\n",
        ")(x)\n",
        "decoder_output = layers.Conv2D(\n",
        "    1,\n",
        "    strides = 1,\n",
        "    activation = \"sigmoid\",\n",
        "    padding = \"same\",\n",
        "    name = \"decoder_output\",\n",
        ")(x)\n",
        "\n",
        "decoder = models.Model(decoder_input, decoder_output)\n",
        "decoder.summary()"
      ],
      "metadata": {
        "id": "eTorBNULB2a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(models.Model):\n",
        "  def __init__(self,encoder,decoder , **kwargs):\n",
        "    super(VAE, self).__init__(**kwargs)\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.total_loss_tracker = metrics.Mean(name = \"total_loss\")\n",
        "    self.reconstruction_loss_tracker = metrics.Mean(\n",
        "        name = \"reconstruction_loss\"\n",
        "    )\n",
        "    self.kl_loss_tracker = metrics.Mean(name = \"kl_loss\")\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return[\n",
        "        self.total_loss_tracker,\n",
        "        self.reconstruction_loss_tracker,\n",
        "        self.kl_loss_tracker,\n",
        "    ]\n",
        "\n",
        "  def call(self, inputs):\n",
        "    \"\"\" Call the model on a particular input\"\"\"\n",
        "    z_mean , z_log_var , z = encoder(inputs)\n",
        "    reconstruction = decoder(z)\n",
        "    return z_mean , z_log_var, reconstruction\n",
        "\n",
        "  def train_step(self, data):\n",
        "    \"\"\"Step run during training \"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "      z_mean , z_log_var, reconstruction = self(data)\n",
        "      reconstruction_loss = tf.reduce_mean(\n",
        "          BETA\n",
        "          * losses.binary_crossentropy(\n",
        "              data, reconstruction, axis = (1,2,3)\n",
        "          )\n",
        "      )\n",
        "      kl_loss = tf.reduce_mean(\n",
        "          tf.reduce_sum(\n",
        "              -0.5\n",
        "              * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)),\n",
        "              axis = 1,\n",
        "          )\n",
        "      )\n",
        "      total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "    grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "    self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "\n",
        "    self.total_loss_tracker.update_state(total_loss)\n",
        "    self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "    self.kl_loss_tracker.update_state(kl_loss)\n",
        "\n",
        "    return {m.name : m.result() for m in self.metrics}\n",
        "\n",
        "  def test_step(self, data):\n",
        "    \"\"\"Step run during validation\"\"\"\n",
        "    if isinstance(data, tuple):\n",
        "      data = data[0]\n",
        "\n",
        "    z_mean , z_log_var , reconstruction = self(data)\n",
        "    reconstruction_loss = tf.reduce_mean(\n",
        "        BETA\n",
        "        * losses.binary_crossentropy(data, reconstruction, axis = (1,2,3))\n",
        "    )\n",
        "    kl_loss = tf.reduce_mean(\n",
        "        tf.reduce_sum(\n",
        "            -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)),\n",
        "            axis = 1,\n",
        "        )\n",
        "    )\n",
        "    total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "    return{\n",
        "        \"loss\" : total_loss,\n",
        "        \"reconstruction_loss\" : reconstruction_loss,\n",
        "        \"kl_loss\" : kl_loss,\n",
        "    }"
      ],
      "metadata": {
        "id": "ySUXWlbkDMzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a variational autoencoder\n",
        "vae = VAE(encoder, decoder)"
      ],
      "metadata": {
        "id": "USNzP0RhbyGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train the variational autoencoder"
      ],
      "metadata": {
        "id": "i7zemXKpb5uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the variational autoencoder\n",
        "\n",
        "optimizers = optimizers.Adam(learning_rate = 0.0005)\n",
        "vae.compile(optimizer = optimizer)"
      ],
      "metadata": {
        "id": "uZbmeCh8b34Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a model save checkpoint\n",
        "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
        "    filepath = \"./checkpoint\",\n",
        "    save_weights_only = False,\n",
        "    save_freq = \"epoch\",\n",
        "    monitor = \"loss\",\n",
        "    mode = \"min\",\n",
        "    save_best_only = True,\n",
        "    verbose = 0,\n",
        "\n",
        ")\n",
        "tensorboard_callback = callbacks.TensorBoard(log_dir = \"./logs\")\n"
      ],
      "metadata": {
        "id": "Spm25L3-cJxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.fit(\n",
        "    x_train,\n",
        "    epochs = EPOCHS,\n",
        "    batch_size = BATCH_SIZE ,\n",
        "    shuffle = True,\n",
        "    validation_data = (x_test , x_test),\n",
        "    callbacks = [model_checkpoint_callback, tensorboard_callback],\n",
        ")"
      ],
      "metadata": {
        "id": "Td-8Lg4Ycp59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save the final models\n",
        "vae.save(\"./models/vae\")\n",
        "encoder.save(\"./models/encoder\")\n",
        "decoder.save(\"./models/decoder\")"
      ],
      "metadata": {
        "id": "ad7EnV14c8Ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Reconstruct using the variational autoencoder"
      ],
      "metadata": {
        "id": "YVF8PFEjdK6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Select a subset of the test set\n",
        "n_to_predict = 5000\n",
        "example_images = x_test[:n_to_predict]\n",
        "example_labels = y_test[:n_to_predict]\n"
      ],
      "metadata": {
        "id": "Gj3w9V_ddKKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create autoencoder predictions and dispaly\n",
        "z_mean, z_log_var, reconstructions = vae.predict(example_images)\n",
        "print(\"Example real clothing items\")\n"
      ],
      "metadata": {
        "id": "oN6HoNhYdhtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8u82bnRfd1l-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}