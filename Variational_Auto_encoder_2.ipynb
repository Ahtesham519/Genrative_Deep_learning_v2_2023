{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2efm5y2yPGPw3+rXeOvEa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahtesham519/Genrative_Deep_learning_v2_2023/blob/main/Variational_Auto_encoder_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJZ9EB0gmz5F"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import (\n",
        "    layers,\n",
        "    models,\n",
        "    datasets,\n",
        "    callbacks,\n",
        "    losses,\n",
        "    optimizers,\n",
        "    metrics,\n",
        ")\n",
        "\n",
        "from scipy.stats import norm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0. Parameters"
      ],
      "metadata": {
        "id": "X2S1N8L4nUBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 32\n",
        "BATCH_SIZE = 100\n",
        "VALIDATION_SPLIT = 0.2\n",
        "EMBEDDING_DIM = 2\n",
        "EPOCHS = 5\n",
        "BETA = 500"
      ],
      "metadata": {
        "id": "Qch2LPn0nTIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare the data"
      ],
      "metadata": {
        "id": "S54yB8VpniHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data\n",
        "(x_train , y_train), (x_test , y_test) = datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "1A_P5u6kng9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess the data\n",
        "def preprocess(imgs):\n",
        "  \"\"\"\n",
        "  normalize and reshape the image\n",
        "  \"\"\"\n",
        "  imgs = imgs.astype(\"float32\")\n",
        "  imgs = np.pad(imgs, ((0,0) , (2,2), (2,2)), constant_values = 0.0)\n",
        "  imgs = np.expand_dims(imgs, -1)\n",
        "  return imgs\n",
        "\n",
        "x_train = preprocess(x_train)\n",
        "x_test = preprocess(x_test)"
      ],
      "metadata": {
        "id": "ssBuhcFTnsKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show some items of clothings from the training set\n",
        "x_train"
      ],
      "metadata": {
        "id": "u55zqKvvoP9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Build the variational autoencoder"
      ],
      "metadata": {
        "id": "2tYYI2P9ANsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling (layers.Layer):\n",
        "  def call(self, inputs):\n",
        "    z_mean, z_log_var = inputs\n",
        "    batch = tf.shape(z_mean)[0]\n",
        "    dim = tf.shape(z_mean)[1]\n",
        "    epsilon = K.random_normal(shape = (batch, dim))\n",
        "    return z_mean +tf.exp(0.5 * z_log_var) * epsilon\n"
      ],
      "metadata": {
        "id": "jls2kzgGobQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoder\n",
        "encoder_input = layers.Input(\n",
        "    shape = (IMAGE_SIZE , IMAGE_SIZE, 1), name = \"encoder_input\"\n",
        ")\n",
        "x = layers.Conv2D(32,(3,3), strides = 2, activation = \"relu\" , padding = \"same\")(\n",
        "    encoder_input\n",
        ")\n",
        "x = layers.Conv2D(64, (3,3), srides = 2, activation = \"relu\", padding = \"same\")(x)\n",
        "x = layers.Conv2D(128, (3,3), strides = 2,activation = \"relu\" , padding = \"same\")(x)\n",
        "shape_before_flattening = K.int_shape(x)[1:]\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "z_mean = layers.Dense(EMBEDDING_DIM , name = \"z_mean\")(x)\n",
        "z_log_var = layers.Dense(EMBEDDING_DIM, name = \"z_log_var\")(x)\n",
        "z = Sampling()([z_mean , z_log_var])\n",
        "\n",
        "encoder = models.Model(encoder_input, [z_mean , z_log_var, z] , name = \"encoder\")\n",
        "encoder.summary()"
      ],
      "metadata": {
        "id": "G-rXOWX4Au0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decoder\n",
        "decoder_input = layers.Input(shape = (EMBEDDING_DIM,) , name = \"decoder_input\")\n",
        "x = layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
        "x = layers.Reshape(shape_before_flattening)(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    128, (3,3), strides = 2, activation = \"relu\" , padding = \"same\"\n",
        ")(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    64, (3,3) , strides= 2, activation = \"relu\" , padding = \"same\"\n",
        ")(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    32, (3,3) , strides = 2, activation = \"relu\" , padding = \"same\"\n",
        ")(x)\n",
        "decoder_output = layers.Conv2D(\n",
        "    1,\n",
        "    strides = 1,\n",
        "    activation = \"sigmoid\",\n",
        "    padding = \"same\",\n",
        "    name = \"decoder_output\",\n",
        ")(x)\n",
        "\n",
        "decoder = models.Model(decoder_input, decoder_output)\n",
        "decoder.summary()"
      ],
      "metadata": {
        "id": "eTorBNULB2a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(models.Model):\n",
        "  def __init__(self,encoder,decoder , **kwargs):\n",
        "    super(VAE, self).__init__(**kwargs)\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.total_loss_tracker = metrics.Mean(name = \"total_loss\")\n",
        "    self.reconstruction_loss_tracker = metrics.Mean(\n",
        "        name = \"reconstruction_loss\"\n",
        "    )\n",
        "    self.kl_loss_tracker = metrics.Mean(name = \"kl_loss\")\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return[\n",
        "        self.total_loss_tracker,\n",
        "        self.reconstruction_loss_tracker,\n",
        "        self.kl_loss_tracker,\n",
        "    ]\n",
        "\n",
        "  def call(self, inputs):\n",
        "    \"\"\" Call the model on a particular input\"\"\"\n",
        "    z_mean , z_log_var , z = encoder(inputs)\n",
        "    reconstruction = decoder(z)\n",
        "    return z_mean , z_log_var, reconstruction\n",
        "\n",
        "  def train_step(self, data):\n",
        "    \"\"\"Step run during training \"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "      z_mean , z_log_var, reconstruction = self(data)\n",
        "      reconstruction_loss = tf.reduce_mean(\n",
        "          BETA\n",
        "          * losses.binary_crossentropy(\n",
        "              data, reconstruction, axis = (1,2,3)\n",
        "          )\n",
        "      )\n",
        "      kl_loss = tf.reduce_mean(\n",
        "          tf.reduce_sum(\n",
        "              -0.5\n",
        "              * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)),\n",
        "              axis = 1,\n",
        "          )\n",
        "      )\n",
        "      total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "    grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "    self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "\n",
        "    self.total_loss_tracker.update_state(total_loss)\n",
        "    self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "    self.kl_loss_tracker.update_state(kl_loss)\n",
        "\n",
        "    return {m.name : m.result() for m in self.metrics}\n",
        "\n",
        "  def test_step(self, data):\n",
        "    \"\"\"Step run during validation\"\"\"\n",
        "    if isinstance(data, tuple):\n",
        "      data = data[0]\n",
        "\n",
        "    z_mean , z_log_var , reconstruction = self(data)\n",
        "    reconstruction_loss = tf.reduce_mean(\n",
        "        BETA\n",
        "        * losses.binary_crossentropy(data, reconstruction, axis = (1,2,3))\n",
        "    )\n",
        "    kl_loss = tf.reduce_mean(\n",
        "        tf.reduce_sum(\n",
        "            -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)),\n",
        "            axis = 1,\n",
        "        )\n",
        "    )\n",
        "    total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "    return{\n",
        "        \"loss\" : total_loss,\n",
        "        \"reconstruction_loss\" : reconstruction_loss,\n",
        "        \"kl_loss\" : kl_loss,\n",
        "    }"
      ],
      "metadata": {
        "id": "ySUXWlbkDMzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a variational autoencoder\n",
        "vae = VAE(encoder, decoder)"
      ],
      "metadata": {
        "id": "USNzP0RhbyGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train the variational autoencoder"
      ],
      "metadata": {
        "id": "i7zemXKpb5uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the variational autoencoder\n",
        "\n",
        "optimizers = optimizers.Adam(learning_rate = 0.0005)\n",
        "vae.compile(optimizer = optimizer)"
      ],
      "metadata": {
        "id": "uZbmeCh8b34Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a model save checkpoint\n",
        "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
        "    filepath = \"./checkpoint\",\n",
        "    save_weights_only = False,\n",
        "    save_freq = \"epoch\",\n",
        "    monitor = \"loss\",\n",
        "    mode = \"min\",\n",
        "    save_best_only = True,\n",
        "    verbose = 0,\n",
        "\n",
        ")\n",
        "tensorboard_callback = callbacks.TensorBoard(log_dir = \"./logs\")\n"
      ],
      "metadata": {
        "id": "Spm25L3-cJxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.fit(\n",
        "    x_train,\n",
        "    epochs = EPOCHS,\n",
        "    batch_size = BATCH_SIZE ,\n",
        "    shuffle = True,\n",
        "    validation_data = (x_test , x_test),\n",
        "    callbacks = [model_checkpoint_callback, tensorboard_callback],\n",
        ")"
      ],
      "metadata": {
        "id": "Td-8Lg4Ycp59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save the final models\n",
        "vae.save(\"./models/vae\")\n",
        "encoder.save(\"./models/encoder\")\n",
        "decoder.save(\"./models/decoder\")"
      ],
      "metadata": {
        "id": "ad7EnV14c8Ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Reconstruct using the variational autoencoder"
      ],
      "metadata": {
        "id": "YVF8PFEjdK6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Select a subset of the test set\n",
        "n_to_predict = 5000\n",
        "example_images = x_test[:n_to_predict]\n",
        "example_labels = y_test[:n_to_predict]\n"
      ],
      "metadata": {
        "id": "Gj3w9V_ddKKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create autoencoder predictions and dispaly\n",
        "z_mean, z_log_var, reconstructions = vae.predict(example_images)\n",
        "print(\"Example real clothing items\")\n"
      ],
      "metadata": {
        "id": "oN6HoNhYdhtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Embed using the encoder"
      ],
      "metadata": {
        "id": "6KN_Zv3wjKx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Encode the example images\n",
        "z_mean, z_var , z = encoder.predict(example_images)\n"
      ],
      "metadata": {
        "id": "8u82bnRfd1l-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Some examples of the embeddings\n",
        "print(z[:10])"
      ],
      "metadata": {
        "id": "tT9JwlpRjUlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show the encoded points in the 2D space\n",
        "figsize = 8\n",
        "\n",
        "plt.figure(figsize=(figsize, figsize))\n",
        "plt.scatter(z[:, 0], z[:,1] , c = \"black\" , alpha = 0.5 , s = 3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ubdgGP4wjYxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5.Genereate using the decoder"
      ],
      "metadata": {
        "id": "YGbW2Qj6jsyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample some points in the latent space, from the standrad normal distributation\n",
        "grid_width, grid_height = (6,3)\n",
        "z_sample = np.random.normal(size = (grid_width * grid_height, 2))\n"
      ],
      "metadata": {
        "id": "eFesxMDVjsfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decode the sampled points\n",
        "reconstructions = decoder.predict(z_sample)"
      ],
      "metadata": {
        "id": "e-lYgOshjrbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert orignal embeddings and sampled embeddings to p-values\n",
        "p = norm.cdf(z)\n",
        "p_sample = norm.cdf(z_sample)\n"
      ],
      "metadata": {
        "id": "mYYyyhVxkHWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Draw a plot of\n",
        "figsize = 8\n",
        "plt.figure(figsize =(figsize, figsize))\n",
        "\n",
        "#... the orignal embeddings....\n",
        "plt.scatter(z_sample[:, 0] , z_sample[:, 1] , c= \"#00B0F0\" , alpha = 1 ,s = 40)\n",
        "plt.show()\n",
        "\n",
        "#add second deoced images underneath the grid\n",
        "fig = plt.figure(figsize= (figsize, grid_height * 2))\n",
        "fig.subplots_adjust(hspace = 0.4, wspace=0.4)\n",
        "\n",
        "for i in range(grid_width * grid_height):\n",
        "  ax = fig.add_subplot(grid_height, grid_width, i + 1)\n",
        "  ax.axis(\"off\")\n",
        "  ax.text(\n",
        "      0.5,\n",
        "      -0.35,\n",
        "      str(np.round(z_sample[i, :], 1)),\n",
        "      fontsize = 10,\n",
        "      ha = \"center\",\n",
        "      transform = ax.transAxes,\n",
        "\n",
        "  )\n",
        "  ax.imshow(reconstructions[i, : , :], cmap = \"Greys\")"
      ],
      "metadata": {
        "id": "pM-xSzVmkedS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Explore the latent space"
      ],
      "metadata": {
        "id": "2ptPiCZylmyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#color the embeddings by their label (Clothing type - see table)\n",
        "\n",
        "figsize = 8\n",
        "fig = plt.figure(figsize= (figsize * 2 , figsize))\n",
        "ax = fig.add_subplot(1,2,1)\n",
        "plot_1 = ax.scatter(\n",
        "    z[:,0] , z[:,1] ,cmap = \"rainbow\" , c = example_labels , alpha = 0.8 , s = 3\n",
        ")\n",
        "plt.colorbar(plot_1)\n",
        "ax = fig.add_subplot(1,2,2)\n",
        "plot_2 = ax.scatter(\n",
        "    p[:,0], p[:, 1],cmap = \"rainbow\", c == example_labelsz, alpha=0.8 , s = 3\n",
        ")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wZ_k51dBk02_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "b282db2b-3428-424c-809a-0e7c2383ce43"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-960413941043>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    )\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#color the embeddings by their label (Clothings type - see Table)\n",
        "figsize = 12\n",
        "grid_size = 15\n",
        "plt.figure(figsize = (figsize , figsize))\n",
        "plt.scatter(\n",
        "    p[:,0] , p[:,1], cmap = \"rainbow\" , c = example_labels, alpha = 0.8 , s = 300\n",
        ")\n",
        "plt.colorbar()\n",
        "\n",
        "x = norm.ppf(np.linspace(0,1 , grid_size))\n",
        "y = norm.ppf(np.linspace(1,0, grid_size))\n",
        "xv, yv = np.meshgrid(x, y)\n",
        "xv = xv.flatten()\n",
        "yv = yv.flatten()\n",
        "grid = np.array(list(zip(xv, yv)))\n",
        "\n",
        "reconstructions = decoder.predit(grid)\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure(figsize = (figsize, figsize))\n",
        "fig.subplots_adjust(hspace = 0.4 , wspace = 0.4)\n",
        "for i in range(grid_size ** 2):\n",
        "  ax = fig.add_subplot(grid_size , grid_size , i+ 1)\n",
        "  ax.axis(\"off\")\n",
        "  ax.imshow(reconstructions[i, : , :] , cmap = \"Greys\")\n",
        ""
      ],
      "metadata": {
        "id": "wmYkS8FYnq08"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}