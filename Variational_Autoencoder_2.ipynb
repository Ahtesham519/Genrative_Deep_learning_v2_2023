{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlKPJBSheNZiOyrr2pU7R5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahtesham519/Genrative_Deep_learning_v2_2023/blob/main/Variational_Autoencoder_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "variational Autoencoder 2"
      ],
      "metadata": {
        "id": "oAG9PUQZozqc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dH2UbsXQosGD"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import (\n",
        "    layers,\n",
        "    models,\n",
        "    callbacks,\n",
        "    utils ,\n",
        "    metrics,\n",
        "    losses,\n",
        "    optimizers,\n",
        ")\n",
        "from scipy.stats import norm\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vae_utils_2 import get_vector_from_label ,add_vector_to_images, morph_faces"
      ],
      "metadata": {
        "id": "imr8lhRYpUsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.Parameters"
      ],
      "metadata": {
        "id": "jxuCMdjBpp8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 64\n",
        "CHANNELS = 3\n",
        "BATCH_SIZE = 128\n",
        "NUM_FEATURES = 64\n",
        "Z_DIM = 200\n",
        "LEARNING_RATE = 0.0005\n",
        "EPOCHS = 10\n",
        "BETA = 2000\n",
        "LOAD_MODEL = False"
      ],
      "metadata": {
        "id": "y0UpWa0lpm2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Prepare the data"
      ],
      "metadata": {
        "id": "gmb7b1kzp-Cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data\n",
        "train_data = utils.image_dataset_from_directory(\n",
        "    \"/app/data/celeba-dataset/img_align_celeba/img_align_celeba\",\n",
        "    labels = None,\n",
        "    color_mode = \"rgb\",\n",
        "    image_size = (IMAGE_SIZE , IMAGE_SIZE),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = True,\n",
        "    seed = 42,\n",
        "    interpolation = \"bilinear\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "L5mEgDZ-p8AX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess the data\n",
        "\n",
        "def preprocess(img):\n",
        "  img = tf.cast(img, \"float32\")/ 255.0\n",
        "  return img\n",
        "\n",
        "train = train_data.map(lambda x : preprocess(x))"
      ],
      "metadata": {
        "id": "AipW7hz9qd_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sample = sample_batch(train)\n"
      ],
      "metadata": {
        "id": "hCOk5nx3rBxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_Sampel = sample_batch(train)"
      ],
      "metadata": {
        "id": "s9PiPeD2rGJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Build the variational autoencoder"
      ],
      "metadata": {
        "id": "IHVOqTNhrK3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(layers.Layer):\n",
        "  def call(self, inputs):\n",
        "    z_mean , z_log_var = inputs\n",
        "    batch = tf.shape(z_mean)[0]\n",
        "    dim = tf.shape(z_mean)[1]\n",
        "    epsilon = K.random_normal(shape = (batch, dim))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "ferOFXN7rJaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoder\n",
        "encoder_input = layers.Input(\n",
        "    shape= (IMAGE_SIZE , IMAGE_SIZE , CHANNELS) , name = \"encoder_input\"\n",
        ")\n",
        "x = layers.Conv2D(NUM_FEATURES , kernel_size = 3, strides = 2, padding = \"same\")(\n",
        "    encoder_input\n",
        ")\n",
        "\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(NUM_FEATURES, kernel_size = 3, strides = 2, padding = \"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(NUM_FEATURES, kernel_size = 3, strides = 2 , padding = \"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(NUM_FEATURES , kernel_size = 3, strides = 2, padding = \"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(NUM_FEATURES, kernel_size = 3, strides = 2 , padding = \"same\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "shape_before_flattening = K.int_shape(x)[1:]\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "z_mean = layers.Dense(Z_DIM , name = \"z_mean\")(x)\n",
        "z_log_var = layers.Dense(Z_DIM , name= \"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "\n",
        "encoder = models.Model(encoder_input, [z_mean, z_log_var, z] , name= \"encoder\")\n",
        "encoder.summary()"
      ],
      "metadata": {
        "id": "Ukk0D8lirorx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decoder\n",
        "decoder_input = layers.Input(shape=(Z_DIM,) , name = \"decoder_input\")\n",
        "x = layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyRelu()(x)\n",
        "x = layers.Reshape(shape_before_flattening)(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    NUM_FEATURES, kernel_size = 3, strides = 2, padding = \"same\"\n",
        ")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    NUM_FEATURES, kernel_size = 3, strides = 2, padding = \"same\"\n",
        ")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    NUM_FEATURES, kernel_size = 3, strides = 2 , padding = \"same\"\n",
        ")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    NUM_FEATURES, kernel_size = 3, strides = 2, padding = \"same\"\n",
        ")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    NUM_FEATURES, kernel_size = 3, strides = 2 , padding = \"same\"\n",
        ")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "decoder_output = layers.Conv2DTranspose(\n",
        "    CHANNELS, kernel_size = 3, strides = 1, activation = \"sigmoid\", padding = \"same\"\n",
        ")(x)\n",
        "decoder = models.Model(decoder_input, decoder_output)\n",
        "decoder.summary()"
      ],
      "metadata": {
        "id": "N3uxSnI-0Baj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(models.Model):\n",
        "  def __init__(self, encoder, decoder, **kwargs):\n",
        "    super(VAE, self).__init__(**kwargs)\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.total_loss_tracker = metrics.Mean(name= \"total_loss\")\n",
        "    self.reconstruction_loss_tracker = metrics.Mean(\n",
        "        name = \"reconstruction_loss\"\n",
        "    )\n",
        "    self.kl_loss_tracker = metrics.Mean(name= \"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "      return[\n",
        "          self.total_loss_tracker,\n",
        "          self.reconstruction_loss_tracker,\n",
        "          self.kl_loss_tracker,\n",
        "      ]\n",
        "\n",
        "    def call(self, inputs):\n",
        "      \"\"\" Call the model on a particular input\"\"\"\n",
        "      z_mean , z_log_var , z = encoder(inputs)\n",
        "      reconstruction = decoder(z)\n",
        "      return z_mean , z_log_var , reconstruction\n",
        "\n",
        "    def train_step(self, data):\n",
        "      \"\"\" Step run during training\"\"\"\n",
        "      with tf.GradientTape() as tape:\n",
        "        z_mean,  z_log_var , recontruction = self(data , training = True)\n",
        "        reconstruction_loss = tf.reduce_mean(\n",
        "            BETA * losses.mean_squared_error(data, reconstruction)\n",
        "        )\n",
        "        kl_loss = tf.reduce_mean(\n",
        "            tf.reduce_sum(\n",
        "                -0.5\n",
        "                * (1 +z_log_var - tf.square(z_mean) - tf.exp(z_log_var)),\n",
        "                axis = 1,\n",
        "            )\n",
        "        )\n",
        "        total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "      grads = tape.gradient(total_loss , self.trainable_weights)\n",
        "      self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "\n",
        "      self.total_loss_tracker.update_state(total_loss)\n",
        "      self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "      self.kl_loss_tracker.update_state(kl_loss)\n",
        "\n",
        "      return{\n",
        "          \"loss\": self.total_loss_tracker.result(),\n",
        "          \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "          \"kl_loss\" :self.kl_loss_tracker.result(),\n",
        "      }\n",
        "\n",
        "\n",
        "    def test_Step(self, data):\n",
        "      \"\"\" Step run during validation.\"\"\"\n",
        "      if isinstance(data, tuple):\n",
        "        data = data[0]\n",
        "\n",
        "      z_mean, z_log_var, reconstruction = self(data)\n",
        "      reconstruction_loss = tf.reduce_mean(\n",
        "          BETA * losses.mean_squared_error(data, reconstruction)\n",
        "      )\n",
        "      kl_loss = tf.reduce_mean(\n",
        "          tf.reduce_sum(\n",
        "              -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)),\n",
        "              axis = 1,\n",
        "          )\n",
        "      )\n",
        "      total_loss = reconstruction_loss + kl_loss\n",
        "\n",
        "      return{\n",
        "          \"loss\" : total_loss,\n",
        "          \"reconstruction_loss\" : reconstruction_loss,\n",
        "          \"kl_loss\" : kl_loss,\n",
        "      }\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "hQpuDxwtFGrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a variational autoencoder\n",
        "vae = VAE(encoder, decoder)"
      ],
      "metadata": {
        "id": "RigxmUuPnNrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Train the variational autoencoder"
      ],
      "metadata": {
        "id": "flOQ3lJNnU-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the variational autoencoder\n",
        "optimizer = optimizers.Adam(learning_rate = LEARNING_RATE)\n",
        "vae.compile(optimizer = optimizer)"
      ],
      "metadata": {
        "id": "OX-YX84rnUKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a model save chekpoint\n",
        "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
        "    filepath=\"./checkpoint\",\n",
        "    save_weights_only = False,\n",
        "    save_freq = \"epoch\",\n",
        "    monitor = \"loss\",\n",
        "    mode = \"min\",\n",
        "    save_best_only = True,\n",
        "    verbose = 0,\n",
        ")\n",
        "tensorboard_callback = callbacks.TensorBoard(log_dir = \"./logs\")\n",
        "\n",
        "class ImageGenerator(callbacks.Callback):\n",
        "  def __init__(self, num_img , latent_dim):\n",
        "    self.num_img = num_img\n",
        "    self.latent_dim = latent_dim\n",
        "\n",
        "  def on_epoch_end(self, epoch , logs = None):\n",
        "    random_latent_vectors = tf.random.normal(\n",
        "        shape= (self.num_img, self.latent_dim)\n",
        "    )\n",
        "    generated_images = self.model.decoder(random_latent_vectors)\n",
        "    generated_images *= 255\n",
        "    generated_images.numpy()\n",
        "    for i in range(self.num_img):\n",
        "      img = utils.array_to_img(generated_images[i])\n",
        "      img.save(\"./output/generated_img_%03d_%d.png\" % (epoch , i))\n",
        ""
      ],
      "metadata": {
        "id": "mimSgpCBnq0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load old weights if required\n",
        "if LOAD_MODEL:\n",
        "  vae.load_weight(\"./models/vae\")\n",
        "  tmp = vae.predict(train.take(1))"
      ],
      "metadata": {
        "id": "sjVN6HycpKll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.fit(\n",
        "    train,\n",
        "    epochs = EPOCHS,\n",
        "    callbacks = [\n",
        "        model_checkpoint_callback,\n",
        "        tensornoard_callback,\n",
        "        ImageGenerator(num_img = 10 , latent_dim=Z_DIM),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "zLslC80epVKB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}