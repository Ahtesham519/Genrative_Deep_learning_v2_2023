{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNP2u3DXzDLUGUrE2PE3C+i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahtesham519/Genrative_Deep_learning_v2_2023/blob/main/ddm_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1j2N_TdkzVvJ"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8-colorblind\")\n",
        "\n",
        "import math\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import (\n",
        "    layers,\n",
        "    models,\n",
        "    optimizers,\n",
        "    utils,\n",
        "    callbacks,\n",
        "    metrics,\n",
        "    losses,\n",
        "    activations,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0. Parameters"
      ],
      "metadata": {
        "id": "kFvIjqWdz05C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 64\n",
        "BATCH_SIZE = 64\n",
        "DATASET_REPETITIONS = 5\n",
        "LOAD_MODEL = False\n",
        "\n",
        "NOISE_EMbEDDING_SIZE = 32\n",
        "PLOT_DIFFUSION_STEPS = 20\n",
        "\n",
        "#oprtimization\n",
        "EMA = 0.999\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "EPOCHS = 50\n",
        "\n"
      ],
      "metadata": {
        "id": "OpZnQC8UzzgB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Prepare the data"
      ],
      "metadata": {
        "id": "fgphuDz00KOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load the data\n",
        "train_data = utils.image_dataset_from_directory(\n",
        "    \"/app/data/pytorch-challenge-flower-dataset/dataset\",\n",
        "    labels = None,\n",
        "    image_size = (IMAGE_SIZE , IMAGE_SIZE),\n",
        "    batch_size = None,\n",
        "    shuffle = True,\n",
        "    seed = 42,\n",
        "    interpolation = \"bilinear\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "OuQs70IR0JsZ",
        "outputId": "94c6273f-5edb-4301-8c22-4b9284929aad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 files belonging to 1 classes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No images found in directory /app/data/pytorch-challenge-flower-dataset/dataset. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d4fed7658446>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_data = utils.image_dataset_from_directory(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"/app/data/pytorch-challenge-flower-dataset/dataset\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m         )\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    304\u001b[0m                 \u001b[0;34mf\"No images found in directory {directory}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;34mf\"Allowed formats: {ALLOWLIST_FORMATS}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No images found in directory /app/data/pytorch-challenge-flower-dataset/dataset. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocess the data\n",
        "\n",
        "def preprocess(img):\n",
        "  img = tf.cast(img, \"float32\") / 255.0\n",
        "  return img\n",
        "\n",
        "train = train_data.map(lambda x: preprocess(x))\n",
        "train = train.repeat(DATASET_REPETITIONS)\n",
        "train = train.batch(BATCH_SIZE , drop_remainder = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "uao1uNo80dVH",
        "outputId": "310ba159-cbf0-4a0f-8f61-f350ad99a88d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-12329f55827c>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_REPETITIONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Show some items of clothing from training set\n",
        "train_sample = sample_batch(train)\n",
        "display(train_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "VkdnHbDG0wL2",
        "outputId": "991150bc-aa20-4548-8e07-bfaf9db93426"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'sample_batch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-21525b7fb633>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Show some items of clothing from training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sample_batch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.1 Diffusion Schedules"
      ],
      "metadata": {
        "id": "Yt_za_aF05Qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_diffusion_schedule(diffusion_times):\n",
        "  min_rate = 0.0001\n",
        "  max_rate = 0.02\n",
        "  betas = min_rate + diffusion_times * (max_rate - min_rate)\n",
        "  alphas = 1 - betas\n",
        "  alpha_bars = tf.math.cumprod(alphas)\n",
        "  signal_rates = tf.sqrt(alpha_bars)\n",
        "  noise_rates = tf.sqrt(1- alpha_bars)\n",
        "  return noise_rates , signal_rates"
      ],
      "metadata": {
        "id": "CcgCQmUO04Zc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_diffusion_schedule(diffusion_times):\n",
        "  signal_rates = tf.cos(diffusion_times * math.pi / 2)\n",
        "  noise_rates = tf.sin(diffusion_times * math.pi / 2)\n",
        "  return noise_rates , signal_rates"
      ],
      "metadata": {
        "id": "GFl64-ew1UWG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def offset_cosine_diffusion_schedule(diffusion_times):\n",
        "  min_signal_rate = 0.02\n",
        "  max_signal_rate = 0.95\n",
        "  start_angle = tf.acos(max_signal_rate)\n",
        "  end_angle = tf.acos(min_signal_rate)\n",
        "\n",
        "  diffusion_angles = start_angle + diffusion_times * (end_angle - start_angle)\n",
        "\n",
        "  signal_rates = tf.cos(diffusion_angles)\n",
        "  noise_rates = tf.sin(diffusion_angles)\n",
        "\n",
        "  return noise_rates , signal_rates"
      ],
      "metadata": {
        "id": "bC8JJJh01jO8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T = 1000\n",
        "diffusion_times = tf.conver_to_tensor([x/ T for x in range(T)])\n",
        "linear_noise_rates , linear_signal_rates = linear_diffusion_schedule(\n",
        "    diffusion_times\n",
        ")\n",
        "cosine_noise_rates , cosine_signal_rates = cosine_diffusion_schedule(\n",
        "    diffusion_times\n",
        ")\n",
        "(\n",
        "    offset_cosine_noise_rates,\n",
        "    offset_cosine_signal_rates,\n",
        " ) = offset_cosine_diffusion_schedule(diffusion_times)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "pYHewSnD2AKS",
        "outputId": "97476fd8-98e4-48b4-ffca-d3c219b81b66"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'tensorflow' has no attribute 'conver_to_tensor'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-511ec1516297>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdiffusion_times\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconver_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0mT\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m linear_noise_rates , linear_signal_rates = linear_diffusion_schedule(\n\u001b[1;32m      4\u001b[0m     \u001b[0mdiffusion_times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'conver_to_tensor'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(\n",
        "    diffusion_times, linear_signal_rates ** 2, linewidth = 1.5, label = \"linear\"\n",
        ")\n",
        "plt.plot(\n",
        "    diffusion_times , cosine_signal_rates ** 2 , linewidth  = 1.5 , label = \"cosine\"\n",
        ")\n",
        "plt.plot(\n",
        "    diffusion_times ,\n",
        "    offset_cosine_signal_rates ** 2,\n",
        "    linewidth = 1.5,\n",
        "    label = \"offset_cosine\",\n",
        ")\n",
        "\n",
        "plt.xlabel(\"t/T\" , fontsize = 12)\n",
        "plt.ylabel(r\"$\\bar{\\alpha_t}$ (signal)\" , fontsize = 12)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "cpThJX8o2ki5",
        "outputId": "09f541e2-e5b4-49bb-ea6b-d04acc1de073"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'diffusion_times' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-397b4baedd9b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m plt.plot(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdiffusion_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_signal_rates\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m plt.plot(\n\u001b[1;32m      5\u001b[0m     \u001b[0mdiffusion_times\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcosine_signal_rates\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;36m1.5\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cosine\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'diffusion_times' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(diffusion_times , linear_noise_rates ** 2, linewidth = 1.5 , label = \"linear\")\n",
        "plt.plot(diffusion_times , cosine_noise_rates ** 2, linewidth = 1.5 , label = \"cosine\")\n",
        "plt.plot(\n",
        "    diffusion_times,\n",
        "    offset_cosine_noise_rates ** 2,\n",
        "    linewidth = 1.5,\n",
        "    label = \"offset_cosine\",\n",
        ")\n",
        "\n",
        "plt.xlabel(\"t/T\" , fontsize = 12)\n",
        "plt.ylabel(r\"$1-\\bar{alpha_t}$ (noise)\", fontsize = 12)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "Rw5aP39D3IF3",
        "outputId": "88a24424-b440-41ad-f7df-2a559eb73d50"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'diffusion_times' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-d538829dba05>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiffusion_times\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlinear_noise_rates\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.5\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiffusion_times\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcosine_noise_rates\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.5\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cosine\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m plt.plot(\n\u001b[1;32m      4\u001b[0m     \u001b[0mdiffusion_times\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moffset_cosine_noise_rates\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'diffusion_times' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Bulid the model"
      ],
      "metadata": {
        "id": "fG9VwAwg3tl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sinusoidal_embedding(x):\n",
        "  frequencies = tf.exp(\n",
        "      tf.linspace(\n",
        "          tf.math.log(1.0),\n",
        "          tf.math.log(1000.0),\n",
        "          NOISE_EMBEDDING_SIZE // 2,\n",
        "      )\n",
        "  )\n",
        "  angular_speeds = 2.0 * math.pi * frequencies\n",
        "  embeddings = tf.concat(\n",
        "      [tf.sin(angular_speeds * x) , tf.cos(angular_speeds * x)], axis = 3\n",
        "  )\n",
        "  return embeddings\n",
        ""
      ],
      "metadata": {
        "id": "TPo82Wdz3sn5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_list = []\n",
        "for y in np.arange(0, 1, 0.01):\n",
        "  embedding_list.append(sinusoidal_embedding(np.array([[[[y]]]]))[0][0][0])\n",
        "embedding_array = np.array(np.transpose(embedding_list))\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_xticks(\n",
        "    np.arange(0, 100, 10), labels = np.round(np.arange(0.0, 1.0, 0.1) , 1)\n",
        ")\n",
        "ax.set_ylabel(\"embedding dimension\" , fontsize = 8)\n",
        "ax.set_xlabel(\"noise variance\" , fontsize = 8)\n",
        "plt.pcolor(embedding_array , cmap = \"coolwarm\")\n",
        "plt.colorbar(orientation = \"horizontal\" , label = \"embedding value\")\n",
        "ax.imshow(embedding_array , interpolation= \"nearest\" , origin = \"lower\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "r3DGUs0h4Lku",
        "outputId": "a84587e3-b24e-476c-e949-5df6d1810b4f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'NOISE_EMBEDDING_SIZE' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-adb7bdb58fec>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0membedding_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0membedding_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msinusoidal_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0membedding_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-c326ac240298>\u001b[0m in \u001b[0;36msinusoidal_embedding\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           \u001b[0mNOISE_EMBEDDING_SIZE\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m       )\n\u001b[1;32m      8\u001b[0m   )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'NOISE_EMBEDDING_SIZE' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ResidualBlock(width):\n",
        "  def apply(x):\n",
        "    input_width = x.shape[3]\n",
        "    if input_width == width:\n",
        "      residual = x\n",
        "    else:\n",
        "      residual = layers.Conv2D(width , kernel_size = 1)(x)\n",
        "    x = layers.BatchNormalization(center = False, scale = False)(x)\n",
        "    x = layers.Conv2D(\n",
        "        width , kernel_size = 3, padding = \"same\", activation = activations.swish\n",
        "    )(x)\n",
        "    x = layers.Conv2D(width , kernel_size = 3 , padding = \"same\")(x)\n",
        "    x = layers.Add()([x, residual])\n",
        "    return x\n",
        "\n",
        "  return apply\n",
        "\n",
        "def DownBlock(width , block_depth):\n",
        "  def apply(x):\n",
        "    x , skips = x\n",
        "    for _ in range(block_depth):\n",
        "      x = ResidualBlock(width)(x)\n",
        "      skips.append(x)\n",
        "    x = layers.AveragePooling2D(pool_size = 2)(x)\n",
        "    return x\n",
        "\n",
        "  return apply\n",
        "\n",
        "def UpBlock(width , block_depth):\n",
        "  def apply(x):\n",
        "    x, skips = x\n",
        "    x = layers.UpSampling2D(size = 2, interpolation = \"bilinear\")(x)\n",
        "    for _ in range(block_depth):\n",
        "      x = layers.Concatenate()([x, skips.pop()])\n",
        "      x = ResidualBlock(width)(x)\n",
        "    return x\n",
        "  return apply"
      ],
      "metadata": {
        "id": "q4g5_Rxe5EQe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bulid the U-net\n",
        "noisy_images = layers.Input(shape = (IMAGE_SIZE , IMAGE_SIZE , 3))\n",
        "x = layers.Conv2D(32, kernel_size = 1)(noise_images)\n",
        "\n",
        "noise_variances = layers.Input(shape = (1,1,1))\n",
        "noise_embedding = layers.Lambda(sinusoidal_embedding)(noise_variances)\n",
        "noise_embedding = layers.UpSampling2D(size = IMAGE_SIZE ,interpolation = \"nearest\")(\n",
        "    noise_embedding\n",
        ")\n",
        "\n",
        "x = layers.Concatenate()([x , noise_embedding])\n",
        "\n",
        "skips = []\n",
        "\n",
        "x = DownBlock(32, block_depth = 2)([x , skips])\n",
        "x = DownBlock(64, block_depth = 2)([x, skips])\n",
        "x = DownBlock(96, block_depth = 2)([x, skips])\n",
        "\n",
        "x = ResidualBlock(128)(x)\n",
        "x = ResidualBlock(128)(x)\n",
        "\n",
        "x = UpBlock(96 , block_depth = 2)([x, skips])\n",
        "x = UpBlock(64, block_depth = 2)([x, skips])\n",
        "x = UpBlock(32, block_depth = 2)([x, skips])\n",
        "\n",
        "x = layers.Conv2D(3, kernel_size = 1, kernel_initializer = \"zeros\")(x)\n",
        "\n",
        "unet = models.Model([noisy_imagesm noise_variances] , x, name = \"unet\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "2lfdM2WW6Rm3",
        "outputId": "2862a93f-8e09-4135-f448-c58ccb59b951"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax. Perhaps you forgot a comma? (<ipython-input-15-921b4f614876>, line 28)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-921b4f614876>\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    unet = models.Model([noisy_imagesm noise_variances] , x, name = \"unet\")\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DiffusionModel(models.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.normalizer= layers.Normalization()\n",
        "    self.network = unet\n",
        "    self.ema_network = models.clone_model(self.network)\n",
        "    self.diffusion_schedule = offset_cosine_diffusion_schedule\n",
        "\n",
        "  def compile(self, **kwargs):\n",
        "    super().compile(**kwargs)\n",
        "    self.noise_loss_tracker  = metrics.Mean(name = \"n_loss\")\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return [ self.noise_loss_tracker]\n",
        "\n",
        "\n",
        "  def denormalize(self, images):\n",
        "    images = self.normalizer.mean + images * self.normalizer.variance ** 0.5\n",
        "    return tf.clip_by_value(images , 0.0, 1.0)\n",
        "\n",
        "  def denoise(self, noisy_images , noise_rates ,signal_rates , training ):\n",
        "    if training :\n",
        "      network = self.network\n",
        "    else:\n",
        "      network = self.ema_network\n",
        "    pred_noises = network(\n",
        "        [noisy_images , noise_rates ** 2], training = training\n",
        "    )\n",
        "    pred_images = (noisy_images - noise_rates * pred_noises) / signal_rates\n",
        "\n",
        "    return pred_noises, pred_images\n",
        "\n",
        "  def reverse_diffusion(self, initial_noise, diffusion_steps):\n",
        "    num_images = initial_noise.shape[0]\n",
        "    step_size = 1.0 / diffusion_steps\n",
        "    current_images = initial_noise\n",
        "    for step in range(diffusion_steps):\n",
        "      diffusion_times = tf.ones((num_images , 1,1 ,1)) - step * step_size\n",
        "      noise_rates , signal_rates = self.diffusion_schedule(diffusion_times)\n",
        "      pred_noises, pred_images = self.denoise(\n",
        "          current_images , noise_rates , signal_rates , training = False\n",
        "      )\n",
        "      next_diffusion_times = diffusion_times - step_size\n",
        "      next_noise_rates , next_signal_rates = self.diffusion_schedule(\n",
        "          next_diffusion_times\n",
        "      )\n",
        "      current_images = (\n",
        "          next_signal_rates * pred_images + next_noise * pred_noises\n",
        "      )\n",
        "    return pred_images"
      ],
      "metadata": {
        "id": "B0u3cWNO7g0g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}