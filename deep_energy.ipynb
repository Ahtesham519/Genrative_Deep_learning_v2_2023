{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvDEGQL76kI2V1dmuPS4U9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahtesham519/Genrative_Deep_learning_v2_2023/blob/main/deep_energy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RODgy_pUaaZc"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import (\n",
        "    datasets,\n",
        "    layers,\n",
        "    models,\n",
        "    optimizers,\n",
        "    activations,\n",
        "    metrics,\n",
        "    callbacks,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0. Parameters"
      ],
      "metadata": {
        "id": "3_UVUJ-CaxPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 32\n",
        "CHANNELS = 1\n",
        "STEP_SIZE = 10\n",
        "STEPS = 60\n",
        "NOISE = 0.005\n",
        "ALPHA = 0.1\n",
        "GRADIENT_CLIP = 0.03\n",
        "BATCH_SIZE = 128\n",
        "BUFFER_SIZE = 8192\n",
        "LEARNING_RATE = 0.0001\n",
        "EPOCHS = 60\n",
        "LOAD_MODEL = False\n"
      ],
      "metadata": {
        "id": "K6lms5leavax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data\n",
        "(x_train, _) , (x_test, _) = datasets.mnist.load_data()\n"
      ],
      "metadata": {
        "id": "MjkyomVVbHA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare the data\n",
        "\n",
        "def preprocess(imgs):\n",
        "  \"\"\"\n",
        "  Normalize and reshape the images\n",
        "  \"\"\"\n",
        "  imgs = (imgs.astype(\"float32\") - 127.5) / 127.5\n",
        "  imgs = np.pad(imgs , ((0,0) , ( 2,2) , ( 2,2 )) , constant_values = -1.0)\n",
        "  imgs = np.expand_dims(imgs , -1)\n",
        "  return imgs\n",
        "\n",
        "x_train = preprocess(x_train)\n",
        "x_test = preprocess(x_test)"
      ],
      "metadata": {
        "id": "PaXSYX-NbNgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = tf.data.Dataset.from_tensor_slices(x_train).batch(BATCH_SIZE)\n",
        "x_test = tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "IiLS-dyibs5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show some items of clothings from the training set\n",
        "train_sample = sample_batch(x_train)\n",
        "display(train_sample)"
      ],
      "metadata": {
        "id": "OKhJzYgDcD34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Build the EBM network"
      ],
      "metadata": {
        "id": "75ww35MwcQeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ebm_input = layers.Input(shape = (IMAGE_SIZE , IMAGE_SIZE , CHANNELS))\n",
        "x =layers.Conv2D(\n",
        "    16, kernel_size = 5, strides = 2, padding = \"same\" , activation = activations.swish\n",
        ")(ebm_input)\n",
        "x = layers.Conv2D(\n",
        "    32, kernel_size = 3, strides = 2, padding = \"same\", activation = activations.swish\n",
        ")(x)\n",
        "x = layers.Conv2D(\n",
        "    64, kernel_size = 3, strides = 2, padding = \"same\", activation = activations.swish\n",
        ")(x)\n",
        "x = layers.Conv2D(\n",
        "    64, kernel_size = 3, strides = 2, padding = \"same\", activation = activations.swish\n",
        ")(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(64, activation= activations.swish)(x)\n",
        "ebm_output = layers.Dense(1)(x)\n",
        "model = models.Model(ebm_input , ebm_output)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Cx5tGh3scL51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if LOAD_MODEL:\n",
        "  model.load_weights(\"./models/model.h5\")"
      ],
      "metadata": {
        "id": "6CyPCROLdT0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Set up a Langevin Sampler function"
      ],
      "metadata": {
        "id": "8AUexyxTdbqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to generate samples using Langevin Dynamics\n",
        "\n",
        "def generate_samples(\n",
        "    model, inp_imgs , steps , step_size , noise, return_img_per_step = False\n",
        "):\n",
        "    imgs_per_step = []\n",
        "    for _ in range(steps):\n",
        "      inp_imgs += tf.random.normal(inp_imgs.shape, mean = 0 , stddev = noise)\n",
        "      inp_imgs = tf.clip_by_value(inp_imgs  , -1.0 , 1.0)\n",
        "      with tf.GradientTape() as tape:\n",
        "        tape.watch(inp_imgs)\n",
        "        out_score = model(inp_imgs)\n",
        "      grads = tape.gradient(out_score, inp_imgs)\n",
        "      grads = tf.clip_by_value(grads , -GRADIENT_CLIP , GRADIENT_CLIP)\n",
        "      inp_imgs += step_size * grads\n",
        "      inp_imgs = tf.clip_by_value(inp_imgs , -1.0 , 1.0)\n",
        "      if return_img_per_step:\n",
        "        imgs_per_step.append(inp_imgs)\n",
        "    if return_img_per_stop:\n",
        "      return tf.stack(imgs_per_step , axis = 0)\n",
        "    else:\n",
        "      return inp_imgs\n"
      ],
      "metadata": {
        "id": "9w-wQiVTdacy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Set up a Buffer to store examples"
      ],
      "metadata": {
        "id": "8S8M4ISYezws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Buffer:\n",
        "  def __init__(self, model):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "    self.examples = [\n",
        "        tf.random.uniform(shape = (1 , IMAGE_SIZE , IMAGE_SIZE , CHANNELS)) * 2\n",
        "        -1\n",
        "        for _ in range(BATCH_SIZE)\n",
        "    ]\n",
        "\n",
        "  def sample_new_exmps(self, step, step_size , noise):\n",
        "    n_new = np.random.binomial(BATCH_SIZE , 0.05)\n",
        "    rand_imgs = (\n",
        "        tf.random.uniform((n_new, IMAGE_SIZE , IMAGE_SIZE, CHANNELS)) * 2 - 1\n",
        "    )\n",
        "    old_imgs = tf.concat(\n",
        "        random.choices(self.examples, k = BATCH_SIZE - n_new) , axis = 0\n",
        "    )\n",
        "    inp_imgs = tf.concat([rand_imgs  , old_imgs] , axis = 0)\n",
        "    inp_imgs = generate_samples(\n",
        "        self.model, inp_imgs , steps = steps, step_size = step_size , noise = noise\n",
        "    )\n",
        "    self.examples = tf.split(inp_imgs , BATCH_SIZE , axis = 0) + self.examples\n",
        "    self.examples = self.examples[:BUFFER_SIZE]\n",
        "    return inp_imgs"
      ],
      "metadata": {
        "id": "TI8UdTsney54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EBM(models.Model):\n",
        "  def __init__(self):\n",
        "    super(EBM , self).__init__()\n",
        "    self.model = model\n",
        "    self.buffer = Buffer(self.model)\n",
        "    self.alpha = ALPHA\n",
        "    self.loss_metric = metrics.Mean(name = \"loss\")\n",
        "    self.reg_loss_metric = metrics.Mean(name = \"reg\")\n",
        "    self.cdiv_loss_metric = metrics.Mean(name = \"cdiv\")\n",
        "    self.real_out_metric = metrics.Mean(name = \"real\")\n",
        "    self.fake_out_metric = metrics.MEan(name = \"fake\")\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return [\n",
        "        self.loss_metric,\n",
        "        self.reg_loss_metric,\n",
        "        self.cdiv_loss_metric,\n",
        "        self.real_out_metric,\n",
        "        self.fake_out_metric,\n",
        "\n",
        "    ]\n",
        "  def train_step(self, real_imgs):\n",
        "    real_imgs += tf.random.normal(\n",
        "        shape = tf.shape(real_imgs), mean = 0 , stddev = NOISE\n",
        "    )\n",
        "    real_imgs = tf.clip_by_value(real_imgs , -1.0 , 1.0)\n",
        "    fake_imgs = self.buffer.sample_new_exmps(\n",
        "        steps = STEPS, step_size = STEP_SIZE , noise = NOISE\n",
        "    )\n",
        "    inp_imgs = tf.concat([real_imgs , fake_imgs], axis = 0)\n",
        "    with tf.GradientTape() as training_tape:\n",
        "      real_out , fake_out  = tf.split(self.model(inp_imgs), 2 , axis = 0)\n",
        "      cdiv_loss = tf.reduce_mean(fake_out , axis = 0) - tf.reduce_mean(\n",
        "          real_out , axis = 0\n",
        "      )\n",
        "      reg_loss = self.alpha * tf.reduce_mean(\n",
        "          real_out** 2 + fake_out** 2 , axis = 0\n",
        "      )\n",
        "      loss = cdiv_loss + reg_loss\n",
        "    grads = training_tape.gradient(loss, self.model.trainable_variables)\n",
        "    self.optimizer.apply_gradients(\n",
        "        zip(grads, self.model.trainable_variables)\n",
        "    )\n",
        "    self.loss_metric.update_state(loss)\n",
        "    self.reg_loss_metric.update_state(reg_loss)\n",
        "    self.cdiv_loss_metric.update_state(cdiv_loss)\n",
        "    self.real_out_metric.update_state(tf.reduce_mean(real_out , axis = 0))\n",
        "    self.fake_out_metric.update_state(tf.reduce_mean(fake_out , axis = 0))\n",
        "    return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "  def test_step(self, real_imgs):\n",
        "    batch_size = real_imgs.shape[0]\n",
        "    fake_imgs = (\n",
        "        tf.random.uniform((batch_size , IMAGE_SIZE , IMAGE_SIZE, CHANNELS))\n",
        "        * 2\n",
        "        -1\n",
        "    )\n",
        "    inp_imgs = tf.concat([real_imgs , fake_imgs], axis = 0)\n",
        "    real_out, fake_out = tf.split(self.model(inp_imgs), 2 , axis = 0)\n",
        "    cdiv = tf.reduce_mean(fake_out , axis = 0) - tf.reduce.mean(\n",
        "        real_out, axis = 0\n",
        "    )\n",
        "    self.cdiv_loss_metric.update_state(cdiv)\n",
        "    self.real_out_metric.update_state(tf.reduce_mean(real_out, axis = 0))\n",
        "    self.fake_out_metric.update_state(tf.reduce_mean(fake_out , axis = 0))\n",
        "    return {m.name: m.result() for m in self.metrics[2: ]}\n",
        ""
      ],
      "metadata": {
        "id": "GsniJywxgILZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ebm = EBM()"
      ],
      "metadata": {
        "id": "Yhw3915ikCZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Train the EBM network"
      ],
      "metadata": {
        "id": "BqMVlZyUkG77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#compile and train the model\n",
        "ebm.compile(\n",
        "    optimizer = optimizers.Adam(learning_rate = LEARNING_RATE) , run_eagerly = True\n",
        ")"
      ],
      "metadata": {
        "id": "UWjvmymRkEcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard_callback = callbacks.TensorBoard(log_dir = \"./logs\")\n",
        "\n",
        "\n",
        "class ImageGenerator(callbacks.Callback):\n",
        "  def __init__(self, num_img):\n",
        "    self.num_img = num_img\n",
        "\n",
        "  def on_epoch_end(self, epoch , logs = None):\n",
        "    start_imgs = (\n",
        "        np.random.uniform(\n",
        "            size = (self.num_img , IMAGE_SIZE , IMAGE_SIZE , CHANNELS)\n",
        "        )\n",
        "        * 2\n",
        "        - 1\n",
        "    )\n",
        "    generated_images = generate_samples(\n",
        "        ebm.model,\n",
        "        start_imgs,\n",
        "        steps = 1000,\n",
        "        step_size = STEP_SIZE,\n",
        "        noise = NOISE,\n",
        "        return_img_per_step = False,\n",
        "    )\n",
        "    generated_images = generated_images.numpy()\n",
        "    display(\n",
        "        generated_images ,\n",
        "        save_to =\"./output/generated_img_%03d.png\" % (epoch),\n",
        "    )\n",
        "\n",
        "    example_images = tf.concat(\n",
        "        random.choices(ebm.buffer.examples, k = 10) , axis = 0\n",
        "    )\n",
        "    example_images = example_images.numpy()\n",
        "    display(\n",
        "        example_images, save_to = \"./output/example_img%03d.png\" % (epoch)\n",
        "    )\n",
        "\n",
        "image_generator_callback = ImageGenerator(num_img = 10)"
      ],
      "metadata": {
        "id": "o_yDcmTgkZT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SaveModel(callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch , logs = None):\n",
        "    model.save_weights(\"./models/model.h5\")\n",
        "\n",
        "save_model_callback = SaveModel()"
      ],
      "metadata": {
        "id": "7G1Uw92hmA2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ebm.fit(\n",
        "    x_train,\n",
        "    shuffle  = True,\n",
        "    epochs = 60,\n",
        "    validation_data = x_test,\n",
        "    callbacks = [\n",
        "        save_model_callback,\n",
        "        tensorboard_callback,\n",
        "        image_generator_callback,\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "Ox1-ZvvxmPpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Generate images"
      ],
      "metadata": {
        "id": "OsiRBhkCmhU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_imgs = (\n",
        "    np.random.uniform(size = (10, IMAGE_SIZE , IMAGE_SIZE , CHANNELS)) * 2 - 1\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "wWRhfMY0mf99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(start_imgs)"
      ],
      "metadata": {
        "id": "3zwleOhoms6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_img = generate_samples(\n",
        "    ebm.model,\n",
        "    start_imgs ,\n",
        "    steps = 1000,\n",
        "    step_size = STEP_SIZE,\n",
        "    noise = NOISE,\n",
        "    return_img_per_stop = True,\n",
        ")"
      ],
      "metadata": {
        "id": "Bu1OwA3EmuuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(gen_img[-1].numpy())"
      ],
      "metadata": {
        "id": "TTyNYkBam6H6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs = []\n",
        "for i in [0,1,3,5,10, 30,100,300,999]:\n",
        "  imgs.append(gen_img[i].numpy()[6])\n",
        "\n",
        "display(np.array(imgs))"
      ],
      "metadata": {
        "id": "lm5Id7N4m9bB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h3JgppwOnJHk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}